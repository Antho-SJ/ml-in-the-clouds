2024-05-30 16:17:57,844:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-30 16:17:57,844:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-30 16:17:57,844:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-30 16:17:57,844:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-30 16:38:38,325:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-30 16:38:38,326:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-30 16:38:38,326:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-30 16:38:38,326:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-30 16:39:08,575:INFO:PyCaret ClassificationExperiment
2024-05-30 16:39:08,575:INFO:Logging name: clf-default-name
2024-05-30 16:39:08,576:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-30 16:39:08,576:INFO:version 3.3.2
2024-05-30 16:39:08,576:INFO:Initializing setup()
2024-05-30 16:39:08,576:INFO:self.USI: 3003
2024-05-30 16:39:08,577:INFO:self._variable_keys: {'idx', 'USI', 'target_param', 'fold_shuffle_param', 'pipeline', 'gpu_n_jobs_param', 'memory', 'X', 'exp_id', '_ml_usecase', 'fold_groups_param', '_available_plots', 'y', 'y_train', 'X_train', 'fix_imbalance', 'exp_name_log', 'y_test', 'logging_param', 'X_test', 'gpu_param', 'seed', 'is_multiclass', 'data', 'n_jobs_param', 'html_param', 'fold_generator', 'log_plots_param'}
2024-05-30 16:39:08,577:INFO:Checking environment
2024-05-30 16:39:08,577:INFO:python_version: 3.10.0
2024-05-30 16:39:08,577:INFO:python_build: ('default', 'May 30 2024 16:31:14')
2024-05-30 16:39:08,577:INFO:machine: x86_64
2024-05-30 16:39:08,577:INFO:platform: Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31
2024-05-30 16:39:08,577:INFO:Memory: svmem(total=8181506048, available=5524836352, percent=32.5, used=2348683264, free=785596416, active=936599552, inactive=5699629056, buffers=461094912, cached=4586131456, shared=69632, slab=615649280)
2024-05-30 16:39:08,581:INFO:Physical Core: 4
2024-05-30 16:39:08,582:INFO:Logical Core: 8
2024-05-30 16:39:08,583:INFO:Checking libraries
2024-05-30 16:39:08,583:INFO:System:
2024-05-30 16:39:08,583:INFO:    python: 3.10.0 (default, May 30 2024, 16:31:14) [GCC 9.3.0]
2024-05-30 16:39:08,583:INFO:executable: /home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/bin/python
2024-05-30 16:39:08,583:INFO:   machine: Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31
2024-05-30 16:39:08,583:INFO:PyCaret required dependencies:
2024-05-30 16:39:08,614:INFO:                 pip: 21.2.3
2024-05-30 16:39:08,614:INFO:          setuptools: 57.4.0
2024-05-30 16:39:08,614:INFO:             pycaret: 3.3.2
2024-05-30 16:39:08,614:INFO:             IPython: 8.24.0
2024-05-30 16:39:08,614:INFO:          ipywidgets: 8.1.3
2024-05-30 16:39:08,614:INFO:                tqdm: 4.66.4
2024-05-30 16:39:08,614:INFO:               numpy: 1.26.4
2024-05-30 16:39:08,614:INFO:              pandas: 2.1.4
2024-05-30 16:39:08,614:INFO:              jinja2: 3.1.4
2024-05-30 16:39:08,614:INFO:               scipy: 1.11.4
2024-05-30 16:39:08,614:INFO:              joblib: 1.3.2
2024-05-30 16:39:08,614:INFO:             sklearn: 1.4.2
2024-05-30 16:39:08,614:INFO:                pyod: 1.1.3
2024-05-30 16:39:08,614:INFO:            imblearn: 0.12.3
2024-05-30 16:39:08,615:INFO:   category_encoders: 2.6.3
2024-05-30 16:39:08,615:INFO:            lightgbm: 4.3.0
2024-05-30 16:39:08,615:INFO:               numba: 0.59.1
2024-05-30 16:39:08,615:INFO:            requests: 2.32.3
2024-05-30 16:39:08,615:INFO:          matplotlib: 3.7.5
2024-05-30 16:39:08,615:INFO:          scikitplot: 0.3.7
2024-05-30 16:39:08,615:INFO:         yellowbrick: 1.5
2024-05-30 16:39:08,615:INFO:              plotly: 5.22.0
2024-05-30 16:39:08,615:INFO:    plotly-resampler: Not installed
2024-05-30 16:39:08,615:INFO:             kaleido: 0.2.1
2024-05-30 16:39:08,615:INFO:           schemdraw: 0.15
2024-05-30 16:39:08,615:INFO:         statsmodels: 0.14.2
2024-05-30 16:39:08,615:INFO:              sktime: 0.26.0
2024-05-30 16:39:08,615:INFO:               tbats: 1.1.3
2024-05-30 16:39:08,616:INFO:            pmdarima: 2.0.4
2024-05-30 16:39:08,616:INFO:              psutil: 5.9.8
2024-05-30 16:39:08,616:INFO:          markupsafe: 2.1.5
2024-05-30 16:39:08,616:INFO:             pickle5: Not installed
2024-05-30 16:39:08,616:INFO:         cloudpickle: 3.0.0
2024-05-30 16:39:08,616:INFO:         deprecation: 2.1.0
2024-05-30 16:39:08,616:INFO:              xxhash: 3.4.1
2024-05-30 16:39:08,616:INFO:           wurlitzer: 3.1.0
2024-05-30 16:39:08,616:INFO:PyCaret optional dependencies:
2024-05-30 16:39:08,641:INFO:                shap: Not installed
2024-05-30 16:39:08,641:INFO:           interpret: Not installed
2024-05-30 16:39:08,641:INFO:                umap: Not installed
2024-05-30 16:39:08,641:INFO:     ydata_profiling: Not installed
2024-05-30 16:39:08,641:INFO:  explainerdashboard: Not installed
2024-05-30 16:39:08,641:INFO:             autoviz: Not installed
2024-05-30 16:39:08,641:INFO:           fairlearn: Not installed
2024-05-30 16:39:08,641:INFO:          deepchecks: Not installed
2024-05-30 16:39:08,641:INFO:             xgboost: Not installed
2024-05-30 16:39:08,641:INFO:            catboost: Not installed
2024-05-30 16:39:08,641:INFO:              kmodes: Not installed
2024-05-30 16:39:08,641:INFO:             mlxtend: Not installed
2024-05-30 16:39:08,641:INFO:       statsforecast: Not installed
2024-05-30 16:39:08,641:INFO:        tune_sklearn: Not installed
2024-05-30 16:39:08,641:INFO:                 ray: Not installed
2024-05-30 16:39:08,641:INFO:            hyperopt: Not installed
2024-05-30 16:39:08,641:INFO:              optuna: Not installed
2024-05-30 16:39:08,641:INFO:               skopt: Not installed
2024-05-30 16:39:08,641:INFO:              mlflow: Not installed
2024-05-30 16:39:08,641:INFO:              gradio: Not installed
2024-05-30 16:39:08,641:INFO:             fastapi: Not installed
2024-05-30 16:39:08,641:INFO:             uvicorn: Not installed
2024-05-30 16:39:08,641:INFO:              m2cgen: Not installed
2024-05-30 16:39:08,642:INFO:           evidently: Not installed
2024-05-30 16:39:08,642:INFO:               fugue: Not installed
2024-05-30 16:39:08,642:INFO:           streamlit: Not installed
2024-05-30 16:39:08,642:INFO:             prophet: Not installed
2024-05-30 16:39:08,642:INFO:None
2024-05-30 16:39:08,642:INFO:Set up data.
2024-05-30 16:39:08,669:INFO:Set up folding strategy.
2024-05-30 16:39:08,670:INFO:Set up train/test split.
2024-05-30 16:39:08,692:INFO:Set up index.
2024-05-30 16:39:08,693:INFO:Assigning column types.
2024-05-30 16:39:08,695:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-30 16:39:08,726:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-30 16:39:08,728:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-30 16:39:08,748:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 16:39:08,750:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 16:39:08,779:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-30 16:39:08,779:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-30 16:39:08,797:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 16:39:08,797:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 16:39:08,797:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-30 16:39:08,827:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-30 16:39:08,845:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 16:39:08,845:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 16:39:08,874:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-30 16:39:08,892:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 16:39:08,892:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 16:39:08,893:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-30 16:39:08,940:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 16:39:08,940:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 16:39:08,987:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 16:39:08,988:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 16:39:08,989:INFO:Preparing preprocessing pipeline...
2024-05-30 16:39:08,990:INFO:Set up label encoding.
2024-05-30 16:39:08,990:INFO:Set up simple imputation.
2024-05-30 16:39:08,992:INFO:Set up encoding of categorical features.
2024-05-30 16:39:09,134:INFO:Finished creating preprocessing pipeline.
2024-05-30 16:39:09,141:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='...
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['Text'],
                                    transformer=TargetEncoder(cols=['Text'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-05-30 16:39:09,141:INFO:Creating final display dataframe.
2024-05-30 16:39:09,569:INFO:Setup _display_container:                     Description  \
0                    Session id   
1                        Target   
2                   Target type   
3                Target mapping   
4           Original data shape   
5        Transformed data shape   
6   Transformed train set shape   
7    Transformed test set shape   
8          Categorical features   
9                    Preprocess   
10              Imputation type   
11           Numeric imputation   
12       Categorical imputation   
13     Maximum one-hot encoding   
14              Encoding method   
15               Fold Generator   
16                  Fold Number   
17                     CPU Jobs   
18                      Use GPU   
19               Log Experiment   
20              Experiment Name   
21                          USI   

                                                Value  
0                                                 123  
1                                             Emotion  
2                                          Multiclass  
3   anger: 0, fear: 1, joy: 2, love: 3, sadness: 4...  
4                                          (21459, 2)  
5                                          (21459, 2)  
6                                          (15021, 2)  
7                                           (6438, 2)  
8                                                   1  
9                                                True  
10                                             simple  
11                                               mean  
12                                               mode  
13                                                 25  
14                                               None  
15                                    StratifiedKFold  
16                                                 10  
17                                                 -1  
18                                              False  
19                                              False  
20                                   clf-default-name  
21                                               3003  
2024-05-30 16:39:09,640:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 16:39:09,641:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 16:39:09,692:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 16:39:09,692:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 16:39:09,693:INFO:setup() successfully completed in 1.12s...............
2024-05-30 16:42:00,968:INFO:PyCaret ClassificationExperiment
2024-05-30 16:42:00,968:INFO:Logging name: clf-default-name
2024-05-30 16:42:00,968:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-30 16:42:00,968:INFO:version 3.3.2
2024-05-30 16:42:00,968:INFO:Initializing setup()
2024-05-30 16:42:00,968:INFO:self.USI: f5c8
2024-05-30 16:42:00,968:INFO:self._variable_keys: {'idx', 'USI', 'target_param', 'fold_shuffle_param', 'pipeline', 'gpu_n_jobs_param', 'memory', 'X', 'exp_id', '_ml_usecase', 'fold_groups_param', '_available_plots', 'y', 'y_train', 'X_train', 'fix_imbalance', 'exp_name_log', 'y_test', 'logging_param', 'X_test', 'gpu_param', 'seed', 'is_multiclass', 'data', 'n_jobs_param', 'html_param', 'fold_generator', 'log_plots_param'}
2024-05-30 16:42:00,968:INFO:Checking environment
2024-05-30 16:42:00,968:INFO:python_version: 3.10.0
2024-05-30 16:42:00,968:INFO:python_build: ('default', 'May 30 2024 16:31:14')
2024-05-30 16:42:00,968:INFO:machine: x86_64
2024-05-30 16:42:00,968:INFO:platform: Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31
2024-05-30 16:42:00,969:INFO:Memory: svmem(total=8181506048, available=5303439360, percent=35.2, used=2570072064, free=563507200, active=936919040, inactive=5914886144, buffers=461414400, cached=4586512384, shared=69632, slab=615997440)
2024-05-30 16:42:00,969:INFO:Physical Core: 4
2024-05-30 16:42:00,969:INFO:Logical Core: 8
2024-05-30 16:42:00,971:INFO:Checking libraries
2024-05-30 16:42:00,971:INFO:System:
2024-05-30 16:42:00,971:INFO:    python: 3.10.0 (default, May 30 2024, 16:31:14) [GCC 9.3.0]
2024-05-30 16:42:00,971:INFO:executable: /home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/bin/python
2024-05-30 16:42:00,971:INFO:   machine: Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31
2024-05-30 16:42:00,971:INFO:PyCaret required dependencies:
2024-05-30 16:42:00,971:INFO:                 pip: 21.2.3
2024-05-30 16:42:00,972:INFO:          setuptools: 57.4.0
2024-05-30 16:42:00,972:INFO:             pycaret: 3.3.2
2024-05-30 16:42:00,972:INFO:             IPython: 8.24.0
2024-05-30 16:42:00,972:INFO:          ipywidgets: 8.1.3
2024-05-30 16:42:00,972:INFO:                tqdm: 4.66.4
2024-05-30 16:42:00,972:INFO:               numpy: 1.26.4
2024-05-30 16:42:00,972:INFO:              pandas: 2.1.4
2024-05-30 16:42:00,972:INFO:              jinja2: 3.1.4
2024-05-30 16:42:00,972:INFO:               scipy: 1.11.4
2024-05-30 16:42:00,972:INFO:              joblib: 1.3.2
2024-05-30 16:42:00,972:INFO:             sklearn: 1.4.2
2024-05-30 16:42:00,972:INFO:                pyod: 1.1.3
2024-05-30 16:42:00,972:INFO:            imblearn: 0.12.3
2024-05-30 16:42:00,972:INFO:   category_encoders: 2.6.3
2024-05-30 16:42:00,972:INFO:            lightgbm: 4.3.0
2024-05-30 16:42:00,972:INFO:               numba: 0.59.1
2024-05-30 16:42:00,972:INFO:            requests: 2.32.3
2024-05-30 16:42:00,972:INFO:          matplotlib: 3.7.5
2024-05-30 16:42:00,972:INFO:          scikitplot: 0.3.7
2024-05-30 16:42:00,972:INFO:         yellowbrick: 1.5
2024-05-30 16:42:00,972:INFO:              plotly: 5.22.0
2024-05-30 16:42:00,972:INFO:    plotly-resampler: Not installed
2024-05-30 16:42:00,972:INFO:             kaleido: 0.2.1
2024-05-30 16:42:00,972:INFO:           schemdraw: 0.15
2024-05-30 16:42:00,972:INFO:         statsmodels: 0.14.2
2024-05-30 16:42:00,972:INFO:              sktime: 0.26.0
2024-05-30 16:42:00,972:INFO:               tbats: 1.1.3
2024-05-30 16:42:00,972:INFO:            pmdarima: 2.0.4
2024-05-30 16:42:00,972:INFO:              psutil: 5.9.8
2024-05-30 16:42:00,972:INFO:          markupsafe: 2.1.5
2024-05-30 16:42:00,972:INFO:             pickle5: Not installed
2024-05-30 16:42:00,972:INFO:         cloudpickle: 3.0.0
2024-05-30 16:42:00,972:INFO:         deprecation: 2.1.0
2024-05-30 16:42:00,972:INFO:              xxhash: 3.4.1
2024-05-30 16:42:00,972:INFO:           wurlitzer: 3.1.0
2024-05-30 16:42:00,972:INFO:PyCaret optional dependencies:
2024-05-30 16:42:00,972:INFO:                shap: Not installed
2024-05-30 16:42:00,973:INFO:           interpret: Not installed
2024-05-30 16:42:00,973:INFO:                umap: Not installed
2024-05-30 16:42:00,973:INFO:     ydata_profiling: Not installed
2024-05-30 16:42:00,973:INFO:  explainerdashboard: Not installed
2024-05-30 16:42:00,973:INFO:             autoviz: Not installed
2024-05-30 16:42:00,973:INFO:           fairlearn: Not installed
2024-05-30 16:42:00,973:INFO:          deepchecks: Not installed
2024-05-30 16:42:00,973:INFO:             xgboost: Not installed
2024-05-30 16:42:00,973:INFO:            catboost: Not installed
2024-05-30 16:42:00,973:INFO:              kmodes: Not installed
2024-05-30 16:42:00,973:INFO:             mlxtend: Not installed
2024-05-30 16:42:00,973:INFO:       statsforecast: Not installed
2024-05-30 16:42:00,973:INFO:        tune_sklearn: Not installed
2024-05-30 16:42:00,973:INFO:                 ray: Not installed
2024-05-30 16:42:00,973:INFO:            hyperopt: Not installed
2024-05-30 16:42:00,973:INFO:              optuna: Not installed
2024-05-30 16:42:00,973:INFO:               skopt: Not installed
2024-05-30 16:42:00,973:INFO:              mlflow: Not installed
2024-05-30 16:42:00,973:INFO:              gradio: Not installed
2024-05-30 16:42:00,973:INFO:             fastapi: Not installed
2024-05-30 16:42:00,973:INFO:             uvicorn: Not installed
2024-05-30 16:42:00,973:INFO:              m2cgen: Not installed
2024-05-30 16:42:00,973:INFO:           evidently: Not installed
2024-05-30 16:42:00,973:INFO:               fugue: Not installed
2024-05-30 16:42:00,973:INFO:           streamlit: Not installed
2024-05-30 16:42:00,973:INFO:             prophet: Not installed
2024-05-30 16:42:00,973:INFO:None
2024-05-30 16:42:00,973:INFO:Set up data.
2024-05-30 16:42:01,004:INFO:Set up folding strategy.
2024-05-30 16:42:01,004:INFO:Set up train/test split.
2024-05-30 16:42:01,033:INFO:Set up index.
2024-05-30 16:42:01,034:INFO:Assigning column types.
2024-05-30 16:42:01,036:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-30 16:42:01,068:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-30 16:42:01,069:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-30 16:42:01,090:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 16:42:01,091:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 16:42:01,122:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-30 16:42:01,123:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-30 16:42:01,141:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 16:42:01,141:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 16:42:01,142:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-30 16:42:01,170:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-30 16:42:01,190:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 16:42:01,190:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 16:42:01,221:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-30 16:42:01,239:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 16:42:01,240:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 16:42:01,240:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-30 16:42:01,289:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 16:42:01,289:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 16:42:01,338:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 16:42:01,338:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 16:42:01,339:INFO:Preparing preprocessing pipeline...
2024-05-30 16:42:01,340:INFO:Set up label encoding.
2024-05-30 16:42:01,340:INFO:Set up simple imputation.
2024-05-30 16:42:01,342:INFO:Set up encoding of categorical features.
2024-05-30 16:42:01,481:INFO:Finished creating preprocessing pipeline.
2024-05-30 16:42:01,485:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='...
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['Text'],
                                    transformer=TargetEncoder(cols=['Text'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-05-30 16:42:01,486:INFO:Creating final display dataframe.
2024-05-30 16:42:01,913:INFO:Setup _display_container:                     Description  \
0                    Session id   
1                        Target   
2                   Target type   
3                Target mapping   
4           Original data shape   
5        Transformed data shape   
6   Transformed train set shape   
7    Transformed test set shape   
8          Categorical features   
9                    Preprocess   
10              Imputation type   
11           Numeric imputation   
12       Categorical imputation   
13     Maximum one-hot encoding   
14              Encoding method   
15               Fold Generator   
16                  Fold Number   
17                     CPU Jobs   
18                      Use GPU   
19               Log Experiment   
20              Experiment Name   
21                          USI   

                                                Value  
0                                                 123  
1                                             Emotion  
2                                          Multiclass  
3   anger: 0, fear: 1, joy: 2, love: 3, sadness: 4...  
4                                          (21459, 2)  
5                                          (21459, 2)  
6                                          (15021, 2)  
7                                           (6438, 2)  
8                                                   1  
9                                                True  
10                                             simple  
11                                               mean  
12                                               mode  
13                                                 25  
14                                               None  
15                                    StratifiedKFold  
16                                                 10  
17                                                 -1  
18                                              False  
19                                              False  
20                                   clf-default-name  
21                                               f5c8  
2024-05-30 16:42:01,983:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 16:42:01,985:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 16:42:02,053:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 16:42:02,054:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 16:42:02,055:INFO:setup() successfully completed in 1.09s...............
2024-05-30 16:42:03,825:INFO:PyCaret ClassificationExperiment
2024-05-30 16:42:03,826:INFO:Logging name: clf-default-name
2024-05-30 16:42:03,826:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-30 16:42:03,826:INFO:version 3.3.2
2024-05-30 16:42:03,826:INFO:Initializing setup()
2024-05-30 16:42:03,826:INFO:self.USI: 0a10
2024-05-30 16:42:03,826:INFO:self._variable_keys: {'idx', 'USI', 'target_param', 'fold_shuffle_param', 'pipeline', 'gpu_n_jobs_param', 'memory', 'X', 'exp_id', '_ml_usecase', 'fold_groups_param', '_available_plots', 'y', 'y_train', 'X_train', 'fix_imbalance', 'exp_name_log', 'y_test', 'logging_param', 'X_test', 'gpu_param', 'seed', 'is_multiclass', 'data', 'n_jobs_param', 'html_param', 'fold_generator', 'log_plots_param'}
2024-05-30 16:42:03,826:INFO:Checking environment
2024-05-30 16:42:03,826:INFO:python_version: 3.10.0
2024-05-30 16:42:03,826:INFO:python_build: ('default', 'May 30 2024 16:31:14')
2024-05-30 16:42:03,826:INFO:machine: x86_64
2024-05-30 16:42:03,826:INFO:platform: Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31
2024-05-30 16:42:03,826:INFO:Memory: svmem(total=8181506048, available=5306314752, percent=35.1, used=2567208960, free=566329344, active=936935424, inactive=5910929408, buffers=461430784, cached=4586536960, shared=69632, slab=615993344)
2024-05-30 16:42:03,827:INFO:Physical Core: 4
2024-05-30 16:42:03,827:INFO:Logical Core: 8
2024-05-30 16:42:03,827:INFO:Checking libraries
2024-05-30 16:42:03,827:INFO:System:
2024-05-30 16:42:03,827:INFO:    python: 3.10.0 (default, May 30 2024, 16:31:14) [GCC 9.3.0]
2024-05-30 16:42:03,827:INFO:executable: /home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/bin/python
2024-05-30 16:42:03,827:INFO:   machine: Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31
2024-05-30 16:42:03,827:INFO:PyCaret required dependencies:
2024-05-30 16:42:03,827:INFO:                 pip: 21.2.3
2024-05-30 16:42:03,828:INFO:          setuptools: 57.4.0
2024-05-30 16:42:03,828:INFO:             pycaret: 3.3.2
2024-05-30 16:42:03,828:INFO:             IPython: 8.24.0
2024-05-30 16:42:03,828:INFO:          ipywidgets: 8.1.3
2024-05-30 16:42:03,828:INFO:                tqdm: 4.66.4
2024-05-30 16:42:03,828:INFO:               numpy: 1.26.4
2024-05-30 16:42:03,828:INFO:              pandas: 2.1.4
2024-05-30 16:42:03,828:INFO:              jinja2: 3.1.4
2024-05-30 16:42:03,828:INFO:               scipy: 1.11.4
2024-05-30 16:42:03,828:INFO:              joblib: 1.3.2
2024-05-30 16:42:03,828:INFO:             sklearn: 1.4.2
2024-05-30 16:42:03,828:INFO:                pyod: 1.1.3
2024-05-30 16:42:03,828:INFO:            imblearn: 0.12.3
2024-05-30 16:42:03,828:INFO:   category_encoders: 2.6.3
2024-05-30 16:42:03,828:INFO:            lightgbm: 4.3.0
2024-05-30 16:42:03,829:INFO:               numba: 0.59.1
2024-05-30 16:42:03,829:INFO:            requests: 2.32.3
2024-05-30 16:42:03,829:INFO:          matplotlib: 3.7.5
2024-05-30 16:42:03,829:INFO:          scikitplot: 0.3.7
2024-05-30 16:42:03,829:INFO:         yellowbrick: 1.5
2024-05-30 16:42:03,829:INFO:              plotly: 5.22.0
2024-05-30 16:42:03,829:INFO:    plotly-resampler: Not installed
2024-05-30 16:42:03,829:INFO:             kaleido: 0.2.1
2024-05-30 16:42:03,829:INFO:           schemdraw: 0.15
2024-05-30 16:42:03,829:INFO:         statsmodels: 0.14.2
2024-05-30 16:42:03,829:INFO:              sktime: 0.26.0
2024-05-30 16:42:03,829:INFO:               tbats: 1.1.3
2024-05-30 16:42:03,829:INFO:            pmdarima: 2.0.4
2024-05-30 16:42:03,829:INFO:              psutil: 5.9.8
2024-05-30 16:42:03,829:INFO:          markupsafe: 2.1.5
2024-05-30 16:42:03,830:INFO:             pickle5: Not installed
2024-05-30 16:42:03,830:INFO:         cloudpickle: 3.0.0
2024-05-30 16:42:03,830:INFO:         deprecation: 2.1.0
2024-05-30 16:42:03,831:INFO:              xxhash: 3.4.1
2024-05-30 16:42:03,831:INFO:           wurlitzer: 3.1.0
2024-05-30 16:42:03,831:INFO:PyCaret optional dependencies:
2024-05-30 16:42:03,832:INFO:                shap: Not installed
2024-05-30 16:42:03,832:INFO:           interpret: Not installed
2024-05-30 16:42:03,832:INFO:                umap: Not installed
2024-05-30 16:42:03,832:INFO:     ydata_profiling: Not installed
2024-05-30 16:42:03,832:INFO:  explainerdashboard: Not installed
2024-05-30 16:42:03,832:INFO:             autoviz: Not installed
2024-05-30 16:42:03,833:INFO:           fairlearn: Not installed
2024-05-30 16:42:03,833:INFO:          deepchecks: Not installed
2024-05-30 16:42:03,833:INFO:             xgboost: Not installed
2024-05-30 16:42:03,833:INFO:            catboost: Not installed
2024-05-30 16:42:03,834:INFO:              kmodes: Not installed
2024-05-30 16:42:03,834:INFO:             mlxtend: Not installed
2024-05-30 16:42:03,834:INFO:       statsforecast: Not installed
2024-05-30 16:42:03,834:INFO:        tune_sklearn: Not installed
2024-05-30 16:42:03,834:INFO:                 ray: Not installed
2024-05-30 16:42:03,834:INFO:            hyperopt: Not installed
2024-05-30 16:42:03,834:INFO:              optuna: Not installed
2024-05-30 16:42:03,834:INFO:               skopt: Not installed
2024-05-30 16:42:03,834:INFO:              mlflow: Not installed
2024-05-30 16:42:03,835:INFO:              gradio: Not installed
2024-05-30 16:42:03,835:INFO:             fastapi: Not installed
2024-05-30 16:42:03,835:INFO:             uvicorn: Not installed
2024-05-30 16:42:03,835:INFO:              m2cgen: Not installed
2024-05-30 16:42:03,835:INFO:           evidently: Not installed
2024-05-30 16:42:03,835:INFO:               fugue: Not installed
2024-05-30 16:42:03,835:INFO:           streamlit: Not installed
2024-05-30 16:42:03,835:INFO:             prophet: Not installed
2024-05-30 16:42:03,835:INFO:None
2024-05-30 16:42:03,835:INFO:Set up data.
2024-05-30 16:42:03,864:INFO:Set up folding strategy.
2024-05-30 16:42:03,864:INFO:Set up train/test split.
2024-05-30 16:42:03,886:INFO:Set up index.
2024-05-30 16:42:03,887:INFO:Assigning column types.
2024-05-30 16:42:03,889:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-30 16:42:03,939:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 16:42:03,939:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 16:42:03,989:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 16:42:03,989:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 16:42:03,989:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-30 16:42:04,045:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 16:42:04,046:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 16:42:04,108:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 16:42:04,109:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 16:42:04,109:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-30 16:42:04,157:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 16:42:04,157:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 16:42:04,207:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 16:42:04,207:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 16:42:04,208:INFO:Preparing preprocessing pipeline...
2024-05-30 16:42:04,209:INFO:Set up label encoding.
2024-05-30 16:42:04,209:INFO:Set up simple imputation.
2024-05-30 16:42:04,210:INFO:Set up encoding of categorical features.
2024-05-30 16:42:04,340:INFO:Finished creating preprocessing pipeline.
2024-05-30 16:42:04,344:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='...
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['Text'],
                                    transformer=TargetEncoder(cols=['Text'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-05-30 16:42:04,344:INFO:Creating final display dataframe.
2024-05-30 16:42:04,777:INFO:Setup _display_container:                     Description  \
0                    Session id   
1                        Target   
2                   Target type   
3                Target mapping   
4           Original data shape   
5        Transformed data shape   
6   Transformed train set shape   
7    Transformed test set shape   
8          Categorical features   
9                    Preprocess   
10              Imputation type   
11           Numeric imputation   
12       Categorical imputation   
13     Maximum one-hot encoding   
14              Encoding method   
15               Fold Generator   
16                  Fold Number   
17                     CPU Jobs   
18                      Use GPU   
19               Log Experiment   
20              Experiment Name   
21                          USI   

                                                Value  
0                                                 124  
1                                             Emotion  
2                                          Multiclass  
3   anger: 0, fear: 1, joy: 2, love: 3, sadness: 4...  
4                                          (21459, 2)  
5                                          (21459, 2)  
6                                          (15021, 2)  
7                                           (6438, 2)  
8                                                   1  
9                                                True  
10                                             simple  
11                                               mean  
12                                               mode  
13                                                 25  
14                                               None  
15                                    StratifiedKFold  
16                                                 10  
17                                                 -1  
18                                              False  
19                                              False  
20                                   clf-default-name  
21                                               0a10  
2024-05-30 16:42:04,838:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 16:42:04,838:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 16:42:04,890:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 16:42:04,890:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 16:42:04,891:INFO:setup() successfully completed in 1.07s...............
2024-05-30 16:42:22,592:INFO:Initializing compare_models()
2024-05-30 16:42:22,593:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f23841a28f0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f23841a28f0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-05-30 16:42:22,594:INFO:Checking exceptions
2024-05-30 16:42:22,599:INFO:Preparing display monitor
2024-05-30 16:42:22,627:INFO:Initializing Logistic Regression
2024-05-30 16:42:22,627:INFO:Total runtime is 5.892912546793619e-06 minutes
2024-05-30 16:42:22,631:INFO:SubProcess create_model() called ==================================
2024-05-30 16:42:22,632:INFO:Initializing create_model()
2024-05-30 16:42:22,632:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f23841a28f0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2384268730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-30 16:42:22,632:INFO:Checking exceptions
2024-05-30 16:42:22,632:INFO:Importing libraries
2024-05-30 16:42:22,632:INFO:Copying training dataset
2024-05-30 16:42:22,639:INFO:Defining folds
2024-05-30 16:42:22,639:INFO:Declaring metric variables
2024-05-30 16:42:22,642:INFO:Importing untrained model
2024-05-30 16:42:22,647:INFO:Logistic Regression Imported successfully
2024-05-30 16:42:22,658:INFO:Starting cross validation
2024-05-30 16:42:22,660:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-30 16:42:28,488:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:28,501:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:28,516:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:28,517:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:28,527:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:28,533:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:28,536:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:28,557:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:28,572:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:28,579:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:28,680:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:28,689:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:28,704:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:28,713:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:28,720:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:28,760:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:28,771:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:28,787:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:28,794:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:28,801:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:28,869:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:28,875:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:28,883:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:28,890:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:28,895:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:28,905:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:28,909:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:28,915:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:28,920:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:28,928:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:28,983:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:28,989:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:28,990:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:28,995:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:29,008:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:29,009:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:29,018:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:29,021:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:29,023:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:29,027:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:29,368:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:29,373:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:29,384:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:29,390:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:29,395:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:29,397:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:29,402:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:29,411:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:29,418:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:29,421:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:29,443:INFO:Calculating mean and std
2024-05-30 16:42:29,445:INFO:Creating metrics dataframe
2024-05-30 16:42:29,449:INFO:Uploading results into container
2024-05-30 16:42:29,449:INFO:Uploading model into container now
2024-05-30 16:42:29,450:INFO:_master_model_container: 1
2024-05-30 16:42:29,450:INFO:_display_container: 2
2024-05-30 16:42:29,451:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-30 16:42:29,451:INFO:create_model() successfully completed......................................
2024-05-30 16:42:29,596:INFO:SubProcess create_model() end ==================================
2024-05-30 16:42:29,596:INFO:Creating metrics dataframe
2024-05-30 16:42:29,604:INFO:Initializing K Neighbors Classifier
2024-05-30 16:42:29,605:INFO:Total runtime is 0.11629442771275839 minutes
2024-05-30 16:42:29,608:INFO:SubProcess create_model() called ==================================
2024-05-30 16:42:29,608:INFO:Initializing create_model()
2024-05-30 16:42:29,609:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f23841a28f0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2384268730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-30 16:42:29,609:INFO:Checking exceptions
2024-05-30 16:42:29,609:INFO:Importing libraries
2024-05-30 16:42:29,609:INFO:Copying training dataset
2024-05-30 16:42:29,615:INFO:Defining folds
2024-05-30 16:42:29,615:INFO:Declaring metric variables
2024-05-30 16:42:29,619:INFO:Importing untrained model
2024-05-30 16:42:29,622:INFO:K Neighbors Classifier Imported successfully
2024-05-30 16:42:29,633:INFO:Starting cross validation
2024-05-30 16:42:29,634:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-30 16:42:30,012:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:30,036:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:30,045:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:30,051:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:30,057:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:30,064:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:30,069:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:30,079:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:30,084:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:30,091:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:30,093:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:30,098:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:30,121:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:30,122:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:30,137:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:30,142:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:30,161:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:30,165:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:30,171:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:30,174:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:30,178:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:30,183:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:30,185:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:30,192:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:30,206:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:30,216:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:30,221:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:30,224:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:30,228:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:30,258:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:30,272:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:30,278:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:30,396:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:30,404:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:30,405:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:30,408:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:30,413:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:30,413:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:30,418:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:30,423:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:30,446:INFO:Calculating mean and std
2024-05-30 16:42:30,448:INFO:Creating metrics dataframe
2024-05-30 16:42:30,450:INFO:Uploading results into container
2024-05-30 16:42:30,450:INFO:Uploading model into container now
2024-05-30 16:42:30,451:INFO:_master_model_container: 2
2024-05-30 16:42:30,451:INFO:_display_container: 2
2024-05-30 16:42:30,452:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-05-30 16:42:30,452:INFO:create_model() successfully completed......................................
2024-05-30 16:42:30,544:INFO:SubProcess create_model() end ==================================
2024-05-30 16:42:30,544:INFO:Creating metrics dataframe
2024-05-30 16:42:30,552:INFO:Initializing Naive Bayes
2024-05-30 16:42:30,552:INFO:Total runtime is 0.13208813269933065 minutes
2024-05-30 16:42:30,555:INFO:SubProcess create_model() called ==================================
2024-05-30 16:42:30,556:INFO:Initializing create_model()
2024-05-30 16:42:30,556:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f23841a28f0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2384268730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-30 16:42:30,556:INFO:Checking exceptions
2024-05-30 16:42:30,556:INFO:Importing libraries
2024-05-30 16:42:30,556:INFO:Copying training dataset
2024-05-30 16:42:30,561:INFO:Defining folds
2024-05-30 16:42:30,562:INFO:Declaring metric variables
2024-05-30 16:42:30,566:INFO:Importing untrained model
2024-05-30 16:42:30,570:INFO:Naive Bayes Imported successfully
2024-05-30 16:42:30,582:INFO:Starting cross validation
2024-05-30 16:42:30,583:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-30 16:42:30,770:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:30,787:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:30,795:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:30,796:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:30,802:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:30,814:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:30,832:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:30,846:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:30,848:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:30,864:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:30,869:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:30,879:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:30,886:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:30,889:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:30,912:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:30,914:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:30,919:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:30,935:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:30,955:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:30,957:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:30,964:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:30,968:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:30,970:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:30,984:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:30,990:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:31,006:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:31,009:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:31,018:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:31,024:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:31,040:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:31,046:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:31,058:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:31,058:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:31,073:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:31,084:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:31,091:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:31,116:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:31,133:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:31,138:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:31,143:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:31,167:INFO:Calculating mean and std
2024-05-30 16:42:31,169:INFO:Creating metrics dataframe
2024-05-30 16:42:31,171:INFO:Uploading results into container
2024-05-30 16:42:31,172:INFO:Uploading model into container now
2024-05-30 16:42:31,172:INFO:_master_model_container: 3
2024-05-30 16:42:31,173:INFO:_display_container: 2
2024-05-30 16:42:31,173:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-05-30 16:42:31,173:INFO:create_model() successfully completed......................................
2024-05-30 16:42:31,251:INFO:SubProcess create_model() end ==================================
2024-05-30 16:42:31,252:INFO:Creating metrics dataframe
2024-05-30 16:42:31,259:INFO:Initializing Decision Tree Classifier
2024-05-30 16:42:31,259:INFO:Total runtime is 0.14387042919794718 minutes
2024-05-30 16:42:31,263:INFO:SubProcess create_model() called ==================================
2024-05-30 16:42:31,263:INFO:Initializing create_model()
2024-05-30 16:42:31,263:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f23841a28f0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2384268730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-30 16:42:31,263:INFO:Checking exceptions
2024-05-30 16:42:31,263:INFO:Importing libraries
2024-05-30 16:42:31,263:INFO:Copying training dataset
2024-05-30 16:42:31,267:INFO:Defining folds
2024-05-30 16:42:31,267:INFO:Declaring metric variables
2024-05-30 16:42:31,271:INFO:Importing untrained model
2024-05-30 16:42:31,274:INFO:Decision Tree Classifier Imported successfully
2024-05-30 16:42:31,287:INFO:Starting cross validation
2024-05-30 16:42:31,289:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-30 16:42:31,480:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:31,495:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:31,506:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:31,512:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:31,529:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:31,542:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:31,550:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:31,557:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:31,606:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:31,620:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:31,628:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:31,637:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:31,648:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:31,666:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:31,673:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:31,683:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:31,726:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:31,740:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:31,750:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:31,757:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:31,763:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:31,789:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:31,795:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:31,798:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:31,800:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:31,803:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:31,807:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:31,813:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:31,813:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:31,818:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:31,820:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:31,829:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:31,852:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:31,861:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:31,863:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:31,865:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:31,868:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:31,870:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:31,874:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:31,879:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:31,897:INFO:Calculating mean and std
2024-05-30 16:42:31,898:INFO:Creating metrics dataframe
2024-05-30 16:42:31,900:INFO:Uploading results into container
2024-05-30 16:42:31,901:INFO:Uploading model into container now
2024-05-30 16:42:31,901:INFO:_master_model_container: 4
2024-05-30 16:42:31,901:INFO:_display_container: 2
2024-05-30 16:42:31,902:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-05-30 16:42:31,902:INFO:create_model() successfully completed......................................
2024-05-30 16:42:31,973:INFO:SubProcess create_model() end ==================================
2024-05-30 16:42:31,974:INFO:Creating metrics dataframe
2024-05-30 16:42:31,982:INFO:Initializing SVM - Linear Kernel
2024-05-30 16:42:31,982:INFO:Total runtime is 0.15591578483581542 minutes
2024-05-30 16:42:31,985:INFO:SubProcess create_model() called ==================================
2024-05-30 16:42:31,986:INFO:Initializing create_model()
2024-05-30 16:42:31,986:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f23841a28f0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2384268730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-30 16:42:31,986:INFO:Checking exceptions
2024-05-30 16:42:31,986:INFO:Importing libraries
2024-05-30 16:42:31,986:INFO:Copying training dataset
2024-05-30 16:42:31,989:INFO:Defining folds
2024-05-30 16:42:31,989:INFO:Declaring metric variables
2024-05-30 16:42:31,992:INFO:Importing untrained model
2024-05-30 16:42:31,996:INFO:SVM - Linear Kernel Imported successfully
2024-05-30 16:42:32,004:INFO:Starting cross validation
2024-05-30 16:42:32,005:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-30 16:42:32,263:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:32,281:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:32,300:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:32,340:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:32,342:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:32,344:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:32,348:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:32,349:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:32,350:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:32,365:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:32,366:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:32,372:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:32,372:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:32,381:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:32,384:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:32,384:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:32,391:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:32,401:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:32,422:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:32,405:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:32,428:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:32,429:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:32,431:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:32,440:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:32,445:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:32,453:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:32,453:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:32,460:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:32,462:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:32,465:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:32,470:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:32,477:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:32,481:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:32,485:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:32,490:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:32,496:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:32,497:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:32,502:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:32,503:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:32,508:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:32,573:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:32,576:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:32,584:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:32,589:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:32,593:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:32,595:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:32,597:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:32,604:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:32,607:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:32,611:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:32,622:INFO:Calculating mean and std
2024-05-30 16:42:32,623:INFO:Creating metrics dataframe
2024-05-30 16:42:32,625:INFO:Uploading results into container
2024-05-30 16:42:32,626:INFO:Uploading model into container now
2024-05-30 16:42:32,626:INFO:_master_model_container: 5
2024-05-30 16:42:32,626:INFO:_display_container: 2
2024-05-30 16:42:32,627:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-05-30 16:42:32,627:INFO:create_model() successfully completed......................................
2024-05-30 16:42:32,703:INFO:SubProcess create_model() end ==================================
2024-05-30 16:42:32,703:INFO:Creating metrics dataframe
2024-05-30 16:42:32,710:INFO:Initializing Ridge Classifier
2024-05-30 16:42:32,711:INFO:Total runtime is 0.16806544462839762 minutes
2024-05-30 16:42:32,714:INFO:SubProcess create_model() called ==================================
2024-05-30 16:42:32,715:INFO:Initializing create_model()
2024-05-30 16:42:32,715:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f23841a28f0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2384268730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-30 16:42:32,715:INFO:Checking exceptions
2024-05-30 16:42:32,715:INFO:Importing libraries
2024-05-30 16:42:32,715:INFO:Copying training dataset
2024-05-30 16:42:32,719:INFO:Defining folds
2024-05-30 16:42:32,719:INFO:Declaring metric variables
2024-05-30 16:42:32,723:INFO:Importing untrained model
2024-05-30 16:42:32,727:INFO:Ridge Classifier Imported successfully
2024-05-30 16:42:32,738:INFO:Starting cross validation
2024-05-30 16:42:32,740:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-30 16:42:32,916:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:32,920:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:32,941:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:32,952:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:32,957:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:32,959:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:32,969:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:32,982:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:32,991:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:32,996:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:33,003:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:33,010:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:33,013:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:33,016:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:33,017:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:33,028:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:33,035:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:33,037:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:33,038:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:33,043:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:33,051:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:33,058:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:33,070:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:33,070:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:33,076:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:33,080:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:33,086:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:33,089:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:33,095:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:33,099:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:33,100:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:33,103:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:33,107:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:33,112:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:33,115:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:33,121:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:33,122:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:33,127:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:33,128:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:33,133:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:33,145:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:33,145:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:33,149:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:33,150:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:33,157:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:33,158:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:33,162:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:33,163:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:33,166:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:33,166:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:33,186:INFO:Calculating mean and std
2024-05-30 16:42:33,186:INFO:Creating metrics dataframe
2024-05-30 16:42:33,189:INFO:Uploading results into container
2024-05-30 16:42:33,189:INFO:Uploading model into container now
2024-05-30 16:42:33,190:INFO:_master_model_container: 6
2024-05-30 16:42:33,190:INFO:_display_container: 2
2024-05-30 16:42:33,191:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-05-30 16:42:33,191:INFO:create_model() successfully completed......................................
2024-05-30 16:42:33,265:INFO:SubProcess create_model() end ==================================
2024-05-30 16:42:33,266:INFO:Creating metrics dataframe
2024-05-30 16:42:33,274:INFO:Initializing Random Forest Classifier
2024-05-30 16:42:33,274:INFO:Total runtime is 0.17745540539423624 minutes
2024-05-30 16:42:33,278:INFO:SubProcess create_model() called ==================================
2024-05-30 16:42:33,279:INFO:Initializing create_model()
2024-05-30 16:42:33,279:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f23841a28f0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2384268730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-30 16:42:33,279:INFO:Checking exceptions
2024-05-30 16:42:33,279:INFO:Importing libraries
2024-05-30 16:42:33,279:INFO:Copying training dataset
2024-05-30 16:42:33,282:INFO:Defining folds
2024-05-30 16:42:33,282:INFO:Declaring metric variables
2024-05-30 16:42:33,286:INFO:Importing untrained model
2024-05-30 16:42:33,289:INFO:Random Forest Classifier Imported successfully
2024-05-30 16:42:33,298:INFO:Starting cross validation
2024-05-30 16:42:33,300:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-30 16:42:34,267:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:34,280:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:34,287:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:34,292:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:34,312:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:34,327:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:34,336:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:34,341:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:34,352:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:34,365:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:34,367:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:34,373:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:34,376:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:34,378:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:34,378:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:34,385:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:34,387:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:34,390:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:34,393:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:34,397:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:34,403:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:34,404:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:34,406:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:34,414:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:34,419:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:34,419:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:34,425:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:34,431:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:34,456:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:34,467:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:34,474:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:34,480:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:34,884:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:34,889:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:34,890:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:34,894:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:34,897:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:34,899:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:34,900:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:34,903:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:34,922:INFO:Calculating mean and std
2024-05-30 16:42:34,922:INFO:Creating metrics dataframe
2024-05-30 16:42:34,925:INFO:Uploading results into container
2024-05-30 16:42:34,926:INFO:Uploading model into container now
2024-05-30 16:42:34,926:INFO:_master_model_container: 7
2024-05-30 16:42:34,927:INFO:_display_container: 2
2024-05-30 16:42:34,927:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-05-30 16:42:34,927:INFO:create_model() successfully completed......................................
2024-05-30 16:42:35,004:INFO:SubProcess create_model() end ==================================
2024-05-30 16:42:35,004:INFO:Creating metrics dataframe
2024-05-30 16:42:35,012:INFO:Initializing Quadratic Discriminant Analysis
2024-05-30 16:42:35,013:INFO:Total runtime is 0.2064354419708252 minutes
2024-05-30 16:42:35,017:INFO:SubProcess create_model() called ==================================
2024-05-30 16:42:35,017:INFO:Initializing create_model()
2024-05-30 16:42:35,017:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f23841a28f0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2384268730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-30 16:42:35,017:INFO:Checking exceptions
2024-05-30 16:42:35,017:INFO:Importing libraries
2024-05-30 16:42:35,017:INFO:Copying training dataset
2024-05-30 16:42:35,021:INFO:Defining folds
2024-05-30 16:42:35,021:INFO:Declaring metric variables
2024-05-30 16:42:35,024:INFO:Importing untrained model
2024-05-30 16:42:35,029:INFO:Quadratic Discriminant Analysis Imported successfully
2024-05-30 16:42:35,040:INFO:Starting cross validation
2024-05-30 16:42:35,041:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-30 16:42:35,173:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:35,178:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:35,188:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:35,189:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:35,193:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:35,193:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:35,199:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:35,205:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:35,212:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:35,218:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:35,255:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:35,260:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:35,277:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:35,285:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:35,287:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:35,292:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:35,295:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:35,310:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:35,313:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:35,318:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:35,322:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:35,329:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:35,332:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:35,335:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:35,339:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:35,339:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:35,345:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:35,351:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:35,358:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:35,364:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:35,376:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:35,382:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:35,383:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:35,389:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:35,393:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:35,399:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:35,400:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:35,401:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:35,403:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:35,403:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:35,407:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:35,410:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:35,413:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:35,415:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:35,415:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:35,422:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:35,424:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:35,428:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:35,430:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:35,435:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:35,453:INFO:Calculating mean and std
2024-05-30 16:42:35,453:INFO:Creating metrics dataframe
2024-05-30 16:42:35,455:INFO:Uploading results into container
2024-05-30 16:42:35,456:INFO:Uploading model into container now
2024-05-30 16:42:35,457:INFO:_master_model_container: 8
2024-05-30 16:42:35,458:INFO:_display_container: 2
2024-05-30 16:42:35,458:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-05-30 16:42:35,458:INFO:create_model() successfully completed......................................
2024-05-30 16:42:35,537:INFO:SubProcess create_model() end ==================================
2024-05-30 16:42:35,538:INFO:Creating metrics dataframe
2024-05-30 16:42:35,546:INFO:Initializing Ada Boost Classifier
2024-05-30 16:42:35,546:INFO:Total runtime is 0.21531378030776976 minutes
2024-05-30 16:42:35,549:INFO:SubProcess create_model() called ==================================
2024-05-30 16:42:35,549:INFO:Initializing create_model()
2024-05-30 16:42:35,549:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f23841a28f0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2384268730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-30 16:42:35,549:INFO:Checking exceptions
2024-05-30 16:42:35,549:INFO:Importing libraries
2024-05-30 16:42:35,550:INFO:Copying training dataset
2024-05-30 16:42:35,553:INFO:Defining folds
2024-05-30 16:42:35,553:INFO:Declaring metric variables
2024-05-30 16:42:35,556:INFO:Importing untrained model
2024-05-30 16:42:35,560:INFO:Ada Boost Classifier Imported successfully
2024-05-30 16:42:35,570:INFO:Starting cross validation
2024-05-30 16:42:35,572:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-30 16:42:35,669:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-30 16:42:35,730:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-30 16:42:35,734:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-30 16:42:35,750:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-30 16:42:35,758:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-30 16:42:35,772:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-30 16:42:35,826:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-30 16:42:35,835:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-30 16:42:36,140:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:36,147:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:36,168:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:36,178:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:36,178:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:36,184:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:36,190:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:36,197:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:36,206:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:36,209:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:36,211:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:36,215:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:36,221:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:36,227:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:36,227:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:36,229:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:36,234:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:36,237:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:36,237:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:36,242:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:36,244:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:36,244:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:36,248:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:36,256:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:36,257:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:36,260:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:36,262:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:36,267:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:36,269:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:36,273:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:36,280:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:36,286:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:36,300:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:36,306:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:36,310:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:36,324:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-30 16:42:36,324:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-30 16:42:36,324:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:36,330:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:36,341:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:36,348:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:36,353:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:36,530:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:36,533:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:36,539:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:36,542:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:36,545:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:36,546:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:36,548:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:36,554:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:36,558:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:36,561:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:36,580:INFO:Calculating mean and std
2024-05-30 16:42:36,580:INFO:Creating metrics dataframe
2024-05-30 16:42:36,582:INFO:Uploading results into container
2024-05-30 16:42:36,583:INFO:Uploading model into container now
2024-05-30 16:42:36,583:INFO:_master_model_container: 9
2024-05-30 16:42:36,583:INFO:_display_container: 2
2024-05-30 16:42:36,583:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-05-30 16:42:36,583:INFO:create_model() successfully completed......................................
2024-05-30 16:42:36,656:INFO:SubProcess create_model() end ==================================
2024-05-30 16:42:36,656:INFO:Creating metrics dataframe
2024-05-30 16:42:36,666:INFO:Initializing Gradient Boosting Classifier
2024-05-30 16:42:36,666:INFO:Total runtime is 0.23398271004358925 minutes
2024-05-30 16:42:36,669:INFO:SubProcess create_model() called ==================================
2024-05-30 16:42:36,669:INFO:Initializing create_model()
2024-05-30 16:42:36,669:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f23841a28f0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2384268730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-30 16:42:36,669:INFO:Checking exceptions
2024-05-30 16:42:36,669:INFO:Importing libraries
2024-05-30 16:42:36,670:INFO:Copying training dataset
2024-05-30 16:42:36,672:INFO:Defining folds
2024-05-30 16:42:36,673:INFO:Declaring metric variables
2024-05-30 16:42:36,675:INFO:Importing untrained model
2024-05-30 16:42:36,679:INFO:Gradient Boosting Classifier Imported successfully
2024-05-30 16:42:36,684:INFO:Starting cross validation
2024-05-30 16:42:36,686:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-30 16:42:39,372:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:39,380:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:39,393:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:39,402:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:39,404:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:39,408:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:39,411:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:39,417:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:39,424:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:39,426:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:39,433:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:39,438:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:39,440:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:39,447:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:39,454:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:39,486:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:39,492:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:39,505:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:39,512:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:39,518:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:39,748:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:39,751:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:39,760:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:39,764:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:39,768:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:39,771:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:39,776:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:39,789:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:39,794:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:39,798:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:39,802:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:39,805:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:39,814:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:39,815:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:39,819:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:39,822:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:39,827:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:39,831:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:39,836:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:39,840:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:40,938:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:40,941:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:40,948:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:40,951:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:40,954:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:40,964:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:40,967:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:40,973:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:40,977:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:40,980:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:40,992:INFO:Calculating mean and std
2024-05-30 16:42:40,993:INFO:Creating metrics dataframe
2024-05-30 16:42:40,995:INFO:Uploading results into container
2024-05-30 16:42:40,996:INFO:Uploading model into container now
2024-05-30 16:42:40,996:INFO:_master_model_container: 10
2024-05-30 16:42:40,997:INFO:_display_container: 2
2024-05-30 16:42:40,997:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-05-30 16:42:40,997:INFO:create_model() successfully completed......................................
2024-05-30 16:42:41,070:INFO:SubProcess create_model() end ==================================
2024-05-30 16:42:41,071:INFO:Creating metrics dataframe
2024-05-30 16:42:41,079:INFO:Initializing Linear Discriminant Analysis
2024-05-30 16:42:41,079:INFO:Total runtime is 0.307533593972524 minutes
2024-05-30 16:42:41,082:INFO:SubProcess create_model() called ==================================
2024-05-30 16:42:41,082:INFO:Initializing create_model()
2024-05-30 16:42:41,082:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f23841a28f0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2384268730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-30 16:42:41,082:INFO:Checking exceptions
2024-05-30 16:42:41,082:INFO:Importing libraries
2024-05-30 16:42:41,082:INFO:Copying training dataset
2024-05-30 16:42:41,085:INFO:Defining folds
2024-05-30 16:42:41,085:INFO:Declaring metric variables
2024-05-30 16:42:41,088:INFO:Importing untrained model
2024-05-30 16:42:41,090:INFO:Linear Discriminant Analysis Imported successfully
2024-05-30 16:42:41,096:INFO:Starting cross validation
2024-05-30 16:42:41,097:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-30 16:42:41,210:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:41,216:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:41,230:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:41,233:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:41,237:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:41,239:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:41,243:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:41,251:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:41,258:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:41,265:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:41,266:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:41,271:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:41,283:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:41,285:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:41,290:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:41,291:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:41,296:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:41,304:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:41,307:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:41,313:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:41,313:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:41,317:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:41,319:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:41,323:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:41,328:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:41,335:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:41,336:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:41,338:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:41,341:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:41,344:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:41,344:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:41,347:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:41,355:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:41,356:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:41,361:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:41,362:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:41,368:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:41,368:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:41,370:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:41,372:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:41,373:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:41,377:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:41,381:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:41,385:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:41,388:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:41,399:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 16:42:41,403:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:41,411:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:41,414:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:41,417:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:41,430:INFO:Calculating mean and std
2024-05-30 16:42:41,431:INFO:Creating metrics dataframe
2024-05-30 16:42:41,433:INFO:Uploading results into container
2024-05-30 16:42:41,434:INFO:Uploading model into container now
2024-05-30 16:42:41,434:INFO:_master_model_container: 11
2024-05-30 16:42:41,434:INFO:_display_container: 2
2024-05-30 16:42:41,434:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-05-30 16:42:41,435:INFO:create_model() successfully completed......................................
2024-05-30 16:42:41,510:INFO:SubProcess create_model() end ==================================
2024-05-30 16:42:41,511:INFO:Creating metrics dataframe
2024-05-30 16:42:41,519:INFO:Initializing Extra Trees Classifier
2024-05-30 16:42:41,519:INFO:Total runtime is 0.314873468875885 minutes
2024-05-30 16:42:41,523:INFO:SubProcess create_model() called ==================================
2024-05-30 16:42:41,523:INFO:Initializing create_model()
2024-05-30 16:42:41,523:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f23841a28f0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2384268730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-30 16:42:41,523:INFO:Checking exceptions
2024-05-30 16:42:41,523:INFO:Importing libraries
2024-05-30 16:42:41,523:INFO:Copying training dataset
2024-05-30 16:42:41,527:INFO:Defining folds
2024-05-30 16:42:41,527:INFO:Declaring metric variables
2024-05-30 16:42:41,531:INFO:Importing untrained model
2024-05-30 16:42:41,535:INFO:Extra Trees Classifier Imported successfully
2024-05-30 16:42:41,547:INFO:Starting cross validation
2024-05-30 16:42:41,549:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-30 16:42:42,236:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:42,251:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:42,257:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:42,262:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:42,265:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:42,266:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:42,270:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:42,273:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:42,279:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:42,281:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:42,286:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:42,292:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:42,297:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:42,311:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:42,316:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:42,322:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:42,342:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:42,353:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:42,360:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:42,366:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:42,372:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:42,385:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:42,389:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:42,392:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:42,395:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:42,399:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:42,402:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:42,403:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:42,407:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:42,414:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:42,420:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:42,427:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:42,670:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:42,677:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:42,681:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:42,681:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:42,684:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:42,689:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:42,694:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 16:42:42,698:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 16:42:42,717:INFO:Calculating mean and std
2024-05-30 16:42:42,717:INFO:Creating metrics dataframe
2024-05-30 16:42:42,720:INFO:Uploading results into container
2024-05-30 16:42:42,721:INFO:Uploading model into container now
2024-05-30 16:42:42,721:INFO:_master_model_container: 12
2024-05-30 16:42:42,721:INFO:_display_container: 2
2024-05-30 16:42:42,721:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-05-30 16:42:42,721:INFO:create_model() successfully completed......................................
2024-05-30 16:42:42,796:INFO:SubProcess create_model() end ==================================
2024-05-30 16:42:42,796:INFO:Creating metrics dataframe
2024-05-30 16:42:42,804:INFO:Initializing Light Gradient Boosting Machine
2024-05-30 16:42:42,804:INFO:Total runtime is 0.33628643353780113 minutes
2024-05-30 16:42:42,807:INFO:SubProcess create_model() called ==================================
2024-05-30 16:42:42,808:INFO:Initializing create_model()
2024-05-30 16:42:42,808:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f23841a28f0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2384268730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-30 16:42:42,808:INFO:Checking exceptions
2024-05-30 16:42:42,808:INFO:Importing libraries
2024-05-30 16:42:42,808:INFO:Copying training dataset
2024-05-30 16:42:42,811:INFO:Defining folds
2024-05-30 16:42:42,811:INFO:Declaring metric variables
2024-05-30 16:42:42,814:INFO:Importing untrained model
2024-05-30 16:42:42,817:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-30 16:42:42,822:INFO:Starting cross validation
2024-05-30 16:42:42,824:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-30 17:29:35,468:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:29:35,808:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:29:36,050:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:29:36,205:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:34:08,581:INFO:PyCaret ClassificationExperiment
2024-05-30 17:34:08,581:INFO:Logging name: clf-default-name
2024-05-30 17:34:08,582:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-30 17:34:08,582:INFO:version 3.3.2
2024-05-30 17:34:08,582:INFO:Initializing setup()
2024-05-30 17:34:08,582:INFO:self.USI: d54c
2024-05-30 17:34:08,582:INFO:self._variable_keys: {'idx', 'USI', 'target_param', 'fold_shuffle_param', 'pipeline', 'gpu_n_jobs_param', 'memory', 'X', 'exp_id', '_ml_usecase', 'fold_groups_param', '_available_plots', 'y', 'y_train', 'X_train', 'fix_imbalance', 'exp_name_log', 'y_test', 'logging_param', 'X_test', 'gpu_param', 'seed', 'is_multiclass', 'data', 'n_jobs_param', 'html_param', 'fold_generator', 'log_plots_param'}
2024-05-30 17:34:08,582:INFO:Checking environment
2024-05-30 17:34:08,582:INFO:python_version: 3.10.0
2024-05-30 17:34:08,582:INFO:python_build: ('default', 'May 30 2024 16:31:14')
2024-05-30 17:34:08,582:INFO:machine: x86_64
2024-05-30 17:34:08,582:INFO:platform: Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31
2024-05-30 17:34:08,583:INFO:Memory: svmem(total=8181506048, available=5077860352, percent=37.9, used=2795659264, free=1222217728, active=1040035840, inactive=5165686784, buffers=466612224, cached=3697016832, shared=73728, slab=603443200)
2024-05-30 17:34:08,592:INFO:Physical Core: 4
2024-05-30 17:34:08,592:INFO:Logical Core: 8
2024-05-30 17:34:08,592:INFO:Checking libraries
2024-05-30 17:34:08,592:INFO:System:
2024-05-30 17:34:08,592:INFO:    python: 3.10.0 (default, May 30 2024, 16:31:14) [GCC 9.3.0]
2024-05-30 17:34:08,592:INFO:executable: /home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/bin/python
2024-05-30 17:34:08,592:INFO:   machine: Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31
2024-05-30 17:34:08,592:INFO:PyCaret required dependencies:
2024-05-30 17:34:08,593:INFO:                 pip: 21.2.3
2024-05-30 17:34:08,593:INFO:          setuptools: 57.4.0
2024-05-30 17:34:08,593:INFO:             pycaret: 3.3.2
2024-05-30 17:34:08,593:INFO:             IPython: 8.24.0
2024-05-30 17:34:08,593:INFO:          ipywidgets: 8.1.3
2024-05-30 17:34:08,593:INFO:                tqdm: 4.66.4
2024-05-30 17:34:08,593:INFO:               numpy: 1.26.4
2024-05-30 17:34:08,593:INFO:              pandas: 2.1.4
2024-05-30 17:34:08,593:INFO:              jinja2: 3.1.4
2024-05-30 17:34:08,593:INFO:               scipy: 1.11.4
2024-05-30 17:34:08,593:INFO:              joblib: 1.3.2
2024-05-30 17:34:08,593:INFO:             sklearn: 1.4.2
2024-05-30 17:34:08,593:INFO:                pyod: 1.1.3
2024-05-30 17:34:08,594:INFO:            imblearn: 0.12.3
2024-05-30 17:34:08,594:INFO:   category_encoders: 2.6.3
2024-05-30 17:34:08,594:INFO:            lightgbm: 4.3.0
2024-05-30 17:34:08,594:INFO:               numba: 0.59.1
2024-05-30 17:34:08,594:INFO:            requests: 2.32.3
2024-05-30 17:34:08,594:INFO:          matplotlib: 3.7.5
2024-05-30 17:34:08,594:INFO:          scikitplot: 0.3.7
2024-05-30 17:34:08,594:INFO:         yellowbrick: 1.5
2024-05-30 17:34:08,594:INFO:              plotly: 5.22.0
2024-05-30 17:34:08,594:INFO:    plotly-resampler: Not installed
2024-05-30 17:34:08,594:INFO:             kaleido: 0.2.1
2024-05-30 17:34:08,594:INFO:           schemdraw: 0.15
2024-05-30 17:34:08,594:INFO:         statsmodels: 0.14.2
2024-05-30 17:34:08,594:INFO:              sktime: 0.26.0
2024-05-30 17:34:08,594:INFO:               tbats: 1.1.3
2024-05-30 17:34:08,594:INFO:            pmdarima: 2.0.4
2024-05-30 17:34:08,594:INFO:              psutil: 5.9.8
2024-05-30 17:34:08,594:INFO:          markupsafe: 2.1.5
2024-05-30 17:34:08,594:INFO:             pickle5: Not installed
2024-05-30 17:34:08,594:INFO:         cloudpickle: 3.0.0
2024-05-30 17:34:08,595:INFO:         deprecation: 2.1.0
2024-05-30 17:34:08,595:INFO:              xxhash: 3.4.1
2024-05-30 17:34:08,595:INFO:           wurlitzer: 3.1.0
2024-05-30 17:34:08,595:INFO:PyCaret optional dependencies:
2024-05-30 17:34:08,595:INFO:                shap: Not installed
2024-05-30 17:34:08,595:INFO:           interpret: Not installed
2024-05-30 17:34:08,595:INFO:                umap: Not installed
2024-05-30 17:34:08,595:INFO:     ydata_profiling: Not installed
2024-05-30 17:34:08,595:INFO:  explainerdashboard: Not installed
2024-05-30 17:34:08,595:INFO:             autoviz: Not installed
2024-05-30 17:34:08,595:INFO:           fairlearn: Not installed
2024-05-30 17:34:08,595:INFO:          deepchecks: Not installed
2024-05-30 17:34:08,595:INFO:             xgboost: Not installed
2024-05-30 17:34:08,595:INFO:            catboost: Not installed
2024-05-30 17:34:08,595:INFO:              kmodes: Not installed
2024-05-30 17:34:08,595:INFO:             mlxtend: Not installed
2024-05-30 17:34:08,595:INFO:       statsforecast: Not installed
2024-05-30 17:34:08,595:INFO:        tune_sklearn: Not installed
2024-05-30 17:34:08,595:INFO:                 ray: Not installed
2024-05-30 17:34:08,595:INFO:            hyperopt: Not installed
2024-05-30 17:34:08,596:INFO:              optuna: Not installed
2024-05-30 17:34:08,596:INFO:               skopt: Not installed
2024-05-30 17:34:08,596:INFO:              mlflow: Not installed
2024-05-30 17:34:08,596:INFO:              gradio: Not installed
2024-05-30 17:34:08,596:INFO:             fastapi: Not installed
2024-05-30 17:34:08,596:INFO:             uvicorn: Not installed
2024-05-30 17:34:08,596:INFO:              m2cgen: Not installed
2024-05-30 17:34:08,596:INFO:           evidently: Not installed
2024-05-30 17:34:08,596:INFO:               fugue: Not installed
2024-05-30 17:34:08,596:INFO:           streamlit: Not installed
2024-05-30 17:34:08,596:INFO:             prophet: Not installed
2024-05-30 17:34:08,596:INFO:None
2024-05-30 17:34:08,596:INFO:Set up data.
2024-05-30 17:34:17,586:INFO:PyCaret ClassificationExperiment
2024-05-30 17:34:17,586:INFO:Logging name: clf-default-name
2024-05-30 17:34:17,586:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-30 17:34:17,586:INFO:version 3.3.2
2024-05-30 17:34:17,586:INFO:Initializing setup()
2024-05-30 17:34:17,587:INFO:self.USI: 8a0b
2024-05-30 17:34:17,587:INFO:self._variable_keys: {'idx', 'USI', 'target_param', 'fold_shuffle_param', 'pipeline', 'gpu_n_jobs_param', 'memory', 'X', 'exp_id', '_ml_usecase', 'fold_groups_param', '_available_plots', 'y', 'y_train', 'X_train', 'fix_imbalance', 'exp_name_log', 'y_test', 'logging_param', 'X_test', 'gpu_param', 'seed', 'is_multiclass', 'data', 'n_jobs_param', 'html_param', 'fold_generator', 'log_plots_param'}
2024-05-30 17:34:17,587:INFO:Checking environment
2024-05-30 17:34:17,587:INFO:python_version: 3.10.0
2024-05-30 17:34:17,587:INFO:python_build: ('default', 'May 30 2024 16:31:14')
2024-05-30 17:34:17,587:INFO:machine: x86_64
2024-05-30 17:34:17,587:INFO:platform: Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31
2024-05-30 17:34:17,587:INFO:Memory: svmem(total=8181506048, available=5072924672, percent=38.0, used=2800594944, free=1217220608, active=1040056320, inactive=5166825472, buffers=466624512, cached=3697065984, shared=73728, slab=603443200)
2024-05-30 17:34:17,588:INFO:Physical Core: 4
2024-05-30 17:34:17,588:INFO:Logical Core: 8
2024-05-30 17:34:17,588:INFO:Checking libraries
2024-05-30 17:34:17,588:INFO:System:
2024-05-30 17:34:17,588:INFO:    python: 3.10.0 (default, May 30 2024, 16:31:14) [GCC 9.3.0]
2024-05-30 17:34:17,588:INFO:executable: /home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/bin/python
2024-05-30 17:34:17,588:INFO:   machine: Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31
2024-05-30 17:34:17,588:INFO:PyCaret required dependencies:
2024-05-30 17:34:17,588:INFO:                 pip: 21.2.3
2024-05-30 17:34:17,588:INFO:          setuptools: 57.4.0
2024-05-30 17:34:17,588:INFO:             pycaret: 3.3.2
2024-05-30 17:34:17,588:INFO:             IPython: 8.24.0
2024-05-30 17:34:17,588:INFO:          ipywidgets: 8.1.3
2024-05-30 17:34:17,588:INFO:                tqdm: 4.66.4
2024-05-30 17:34:17,588:INFO:               numpy: 1.26.4
2024-05-30 17:34:17,588:INFO:              pandas: 2.1.4
2024-05-30 17:34:17,588:INFO:              jinja2: 3.1.4
2024-05-30 17:34:17,588:INFO:               scipy: 1.11.4
2024-05-30 17:34:17,588:INFO:              joblib: 1.3.2
2024-05-30 17:34:17,589:INFO:             sklearn: 1.4.2
2024-05-30 17:34:17,589:INFO:                pyod: 1.1.3
2024-05-30 17:34:17,589:INFO:            imblearn: 0.12.3
2024-05-30 17:34:17,589:INFO:   category_encoders: 2.6.3
2024-05-30 17:34:17,589:INFO:            lightgbm: 4.3.0
2024-05-30 17:34:17,589:INFO:               numba: 0.59.1
2024-05-30 17:34:17,589:INFO:            requests: 2.32.3
2024-05-30 17:34:17,589:INFO:          matplotlib: 3.7.5
2024-05-30 17:34:17,589:INFO:          scikitplot: 0.3.7
2024-05-30 17:34:17,589:INFO:         yellowbrick: 1.5
2024-05-30 17:34:17,589:INFO:              plotly: 5.22.0
2024-05-30 17:34:17,589:INFO:    plotly-resampler: Not installed
2024-05-30 17:34:17,589:INFO:             kaleido: 0.2.1
2024-05-30 17:34:17,589:INFO:           schemdraw: 0.15
2024-05-30 17:34:17,589:INFO:         statsmodels: 0.14.2
2024-05-30 17:34:17,589:INFO:              sktime: 0.26.0
2024-05-30 17:34:17,589:INFO:               tbats: 1.1.3
2024-05-30 17:34:17,589:INFO:            pmdarima: 2.0.4
2024-05-30 17:34:17,589:INFO:              psutil: 5.9.8
2024-05-30 17:34:17,589:INFO:          markupsafe: 2.1.5
2024-05-30 17:34:17,589:INFO:             pickle5: Not installed
2024-05-30 17:34:17,589:INFO:         cloudpickle: 3.0.0
2024-05-30 17:34:17,589:INFO:         deprecation: 2.1.0
2024-05-30 17:34:17,589:INFO:              xxhash: 3.4.1
2024-05-30 17:34:17,589:INFO:           wurlitzer: 3.1.0
2024-05-30 17:34:17,589:INFO:PyCaret optional dependencies:
2024-05-30 17:34:17,590:INFO:                shap: Not installed
2024-05-30 17:34:17,590:INFO:           interpret: Not installed
2024-05-30 17:34:17,590:INFO:                umap: Not installed
2024-05-30 17:34:17,590:INFO:     ydata_profiling: Not installed
2024-05-30 17:34:17,590:INFO:  explainerdashboard: Not installed
2024-05-30 17:34:17,590:INFO:             autoviz: Not installed
2024-05-30 17:34:17,590:INFO:           fairlearn: Not installed
2024-05-30 17:34:17,590:INFO:          deepchecks: Not installed
2024-05-30 17:34:17,590:INFO:             xgboost: Not installed
2024-05-30 17:34:17,590:INFO:            catboost: Not installed
2024-05-30 17:34:17,590:INFO:              kmodes: Not installed
2024-05-30 17:34:17,590:INFO:             mlxtend: Not installed
2024-05-30 17:34:17,590:INFO:       statsforecast: Not installed
2024-05-30 17:34:17,590:INFO:        tune_sklearn: Not installed
2024-05-30 17:34:17,590:INFO:                 ray: Not installed
2024-05-30 17:34:17,590:INFO:            hyperopt: Not installed
2024-05-30 17:34:17,590:INFO:              optuna: Not installed
2024-05-30 17:34:17,590:INFO:               skopt: Not installed
2024-05-30 17:34:17,590:INFO:              mlflow: Not installed
2024-05-30 17:34:17,590:INFO:              gradio: Not installed
2024-05-30 17:34:17,590:INFO:             fastapi: Not installed
2024-05-30 17:34:17,590:INFO:             uvicorn: Not installed
2024-05-30 17:34:17,591:INFO:              m2cgen: Not installed
2024-05-30 17:34:17,591:INFO:           evidently: Not installed
2024-05-30 17:34:17,591:INFO:               fugue: Not installed
2024-05-30 17:34:17,591:INFO:           streamlit: Not installed
2024-05-30 17:34:17,591:INFO:             prophet: Not installed
2024-05-30 17:34:17,591:INFO:None
2024-05-30 17:34:17,591:INFO:Set up data.
2024-05-30 17:34:17,640:INFO:Set up folding strategy.
2024-05-30 17:34:26,000:INFO:PyCaret ClassificationExperiment
2024-05-30 17:34:26,000:INFO:Logging name: clf-default-name
2024-05-30 17:34:26,000:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-30 17:34:26,000:INFO:version 3.3.2
2024-05-30 17:34:26,000:INFO:Initializing setup()
2024-05-30 17:34:26,000:INFO:self.USI: 6d98
2024-05-30 17:34:26,001:INFO:self._variable_keys: {'idx', 'USI', 'target_param', 'fold_shuffle_param', 'pipeline', 'gpu_n_jobs_param', 'memory', 'X', 'exp_id', '_ml_usecase', 'fold_groups_param', '_available_plots', 'y', 'y_train', 'X_train', 'fix_imbalance', 'exp_name_log', 'y_test', 'logging_param', 'X_test', 'gpu_param', 'seed', 'is_multiclass', 'data', 'n_jobs_param', 'html_param', 'fold_generator', 'log_plots_param'}
2024-05-30 17:34:26,001:INFO:Checking environment
2024-05-30 17:34:26,001:INFO:python_version: 3.10.0
2024-05-30 17:34:26,001:INFO:python_build: ('default', 'May 30 2024 16:31:14')
2024-05-30 17:34:26,001:INFO:machine: x86_64
2024-05-30 17:34:26,001:INFO:platform: Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31
2024-05-30 17:34:26,001:INFO:Memory: svmem(total=8181506048, available=5058523136, percent=38.2, used=2814996480, free=1202786304, active=1040179200, inactive=5182038016, buffers=466644992, cached=3697078272, shared=73728, slab=603443200)
2024-05-30 17:34:26,001:INFO:Physical Core: 4
2024-05-30 17:34:26,002:INFO:Logical Core: 8
2024-05-30 17:34:26,002:INFO:Checking libraries
2024-05-30 17:34:26,002:INFO:System:
2024-05-30 17:34:26,002:INFO:    python: 3.10.0 (default, May 30 2024, 16:31:14) [GCC 9.3.0]
2024-05-30 17:34:26,002:INFO:executable: /home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/bin/python
2024-05-30 17:34:26,002:INFO:   machine: Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31
2024-05-30 17:34:26,002:INFO:PyCaret required dependencies:
2024-05-30 17:34:26,002:INFO:                 pip: 21.2.3
2024-05-30 17:34:26,002:INFO:          setuptools: 57.4.0
2024-05-30 17:34:26,002:INFO:             pycaret: 3.3.2
2024-05-30 17:34:26,002:INFO:             IPython: 8.24.0
2024-05-30 17:34:26,002:INFO:          ipywidgets: 8.1.3
2024-05-30 17:34:26,002:INFO:                tqdm: 4.66.4
2024-05-30 17:34:26,002:INFO:               numpy: 1.26.4
2024-05-30 17:34:26,003:INFO:              pandas: 2.1.4
2024-05-30 17:34:26,003:INFO:              jinja2: 3.1.4
2024-05-30 17:34:26,003:INFO:               scipy: 1.11.4
2024-05-30 17:34:26,003:INFO:              joblib: 1.3.2
2024-05-30 17:34:26,003:INFO:             sklearn: 1.4.2
2024-05-30 17:34:26,003:INFO:                pyod: 1.1.3
2024-05-30 17:34:26,003:INFO:            imblearn: 0.12.3
2024-05-30 17:34:26,003:INFO:   category_encoders: 2.6.3
2024-05-30 17:34:26,003:INFO:            lightgbm: 4.3.0
2024-05-30 17:34:26,003:INFO:               numba: 0.59.1
2024-05-30 17:34:26,003:INFO:            requests: 2.32.3
2024-05-30 17:34:26,003:INFO:          matplotlib: 3.7.5
2024-05-30 17:34:26,003:INFO:          scikitplot: 0.3.7
2024-05-30 17:34:26,003:INFO:         yellowbrick: 1.5
2024-05-30 17:34:26,003:INFO:              plotly: 5.22.0
2024-05-30 17:34:26,003:INFO:    plotly-resampler: Not installed
2024-05-30 17:34:26,003:INFO:             kaleido: 0.2.1
2024-05-30 17:34:26,003:INFO:           schemdraw: 0.15
2024-05-30 17:34:26,003:INFO:         statsmodels: 0.14.2
2024-05-30 17:34:26,003:INFO:              sktime: 0.26.0
2024-05-30 17:34:26,003:INFO:               tbats: 1.1.3
2024-05-30 17:34:26,003:INFO:            pmdarima: 2.0.4
2024-05-30 17:34:26,003:INFO:              psutil: 5.9.8
2024-05-30 17:34:26,003:INFO:          markupsafe: 2.1.5
2024-05-30 17:34:26,003:INFO:             pickle5: Not installed
2024-05-30 17:34:26,003:INFO:         cloudpickle: 3.0.0
2024-05-30 17:34:26,003:INFO:         deprecation: 2.1.0
2024-05-30 17:34:26,003:INFO:              xxhash: 3.4.1
2024-05-30 17:34:26,003:INFO:           wurlitzer: 3.1.0
2024-05-30 17:34:26,003:INFO:PyCaret optional dependencies:
2024-05-30 17:34:26,003:INFO:                shap: Not installed
2024-05-30 17:34:26,004:INFO:           interpret: Not installed
2024-05-30 17:34:26,004:INFO:                umap: Not installed
2024-05-30 17:34:26,004:INFO:     ydata_profiling: Not installed
2024-05-30 17:34:26,004:INFO:  explainerdashboard: Not installed
2024-05-30 17:34:26,004:INFO:             autoviz: Not installed
2024-05-30 17:34:26,004:INFO:           fairlearn: Not installed
2024-05-30 17:34:26,004:INFO:          deepchecks: Not installed
2024-05-30 17:34:26,004:INFO:             xgboost: Not installed
2024-05-30 17:34:26,004:INFO:            catboost: Not installed
2024-05-30 17:34:26,004:INFO:              kmodes: Not installed
2024-05-30 17:34:26,004:INFO:             mlxtend: Not installed
2024-05-30 17:34:26,004:INFO:       statsforecast: Not installed
2024-05-30 17:34:26,004:INFO:        tune_sklearn: Not installed
2024-05-30 17:34:26,004:INFO:                 ray: Not installed
2024-05-30 17:34:26,004:INFO:            hyperopt: Not installed
2024-05-30 17:34:26,005:INFO:              optuna: Not installed
2024-05-30 17:34:26,005:INFO:               skopt: Not installed
2024-05-30 17:34:26,005:INFO:              mlflow: Not installed
2024-05-30 17:34:26,005:INFO:              gradio: Not installed
2024-05-30 17:34:26,005:INFO:             fastapi: Not installed
2024-05-30 17:34:26,005:INFO:             uvicorn: Not installed
2024-05-30 17:34:26,005:INFO:              m2cgen: Not installed
2024-05-30 17:34:26,005:INFO:           evidently: Not installed
2024-05-30 17:34:26,005:INFO:               fugue: Not installed
2024-05-30 17:34:26,005:INFO:           streamlit: Not installed
2024-05-30 17:34:26,005:INFO:             prophet: Not installed
2024-05-30 17:34:26,005:INFO:None
2024-05-30 17:34:26,005:INFO:Set up data.
2024-05-30 17:34:26,039:INFO:Set up folding strategy.
2024-05-30 17:34:26,039:INFO:Set up train/test split.
2024-05-30 17:34:26,068:INFO:Set up index.
2024-05-30 17:34:26,069:INFO:Assigning column types.
2024-05-30 17:34:26,071:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-30 17:34:26,102:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-30 17:34:26,103:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-30 17:34:26,122:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:34:26,122:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:34:26,152:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-30 17:34:26,153:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-30 17:34:26,170:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:34:26,171:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:34:26,171:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-30 17:34:26,200:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-30 17:34:26,220:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:34:26,220:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:34:26,249:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-30 17:34:26,267:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:34:26,267:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:34:26,267:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-30 17:34:26,318:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:34:26,319:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:34:26,369:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:34:26,369:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:34:26,370:INFO:Preparing preprocessing pipeline...
2024-05-30 17:34:26,371:INFO:Set up label encoding.
2024-05-30 17:34:26,372:INFO:Set up simple imputation.
2024-05-30 17:34:26,374:INFO:Set up encoding of categorical features.
2024-05-30 17:34:26,559:INFO:Finished creating preprocessing pipeline.
2024-05-30 17:34:26,564:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='...
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['Text'],
                                    transformer=TargetEncoder(cols=['Text'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-05-30 17:34:26,564:INFO:Creating final display dataframe.
2024-05-30 17:34:27,078:INFO:Setup _display_container:                     Description  \
0                    Session id   
1                        Target   
2                   Target type   
3                Target mapping   
4           Original data shape   
5        Transformed data shape   
6   Transformed train set shape   
7    Transformed test set shape   
8          Categorical features   
9                    Preprocess   
10              Imputation type   
11           Numeric imputation   
12       Categorical imputation   
13     Maximum one-hot encoding   
14              Encoding method   
15               Fold Generator   
16                  Fold Number   
17                     CPU Jobs   
18                      Use GPU   
19               Log Experiment   
20              Experiment Name   
21                          USI   

                                                Value  
0                                                  43  
1                                             Emotion  
2                                          Multiclass  
3   anger: 0, fear: 1, joy: 2, love: 3, sadness: 4...  
4                                          (21459, 2)  
5                                          (21459, 2)  
6                                          (15021, 2)  
7                                           (6438, 2)  
8                                                   1  
9                                                True  
10                                             simple  
11                                               mean  
12                                               mode  
13                                                 25  
14                                               None  
15                                    StratifiedKFold  
16                                                  2  
17                                                 -1  
18                                              False  
19                                              False  
20                                   clf-default-name  
21                                               6d98  
2024-05-30 17:34:27,156:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:34:27,156:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:34:27,230:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:34:27,231:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:34:27,232:INFO:setup() successfully completed in 1.23s...............
2024-05-30 17:34:27,233:INFO:Initializing compare_models()
2024-05-30 17:34:27,233:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f23c5012ef0>, include=['lr', 'knn', 'qda', 'lda', 'lightgbm'], fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f23c5012ef0>, 'include': ['lr', 'knn', 'qda', 'lda', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-05-30 17:34:27,233:INFO:Checking exceptions
2024-05-30 17:34:27,237:INFO:Preparing display monitor
2024-05-30 17:34:27,268:INFO:Initializing Logistic Regression
2024-05-30 17:34:27,269:INFO:Total runtime is 7.263819376627604e-06 minutes
2024-05-30 17:34:27,273:INFO:SubProcess create_model() called ==================================
2024-05-30 17:34:27,274:INFO:Initializing create_model()
2024-05-30 17:34:27,274:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f23c5012ef0>, estimator=lr, fold=StratifiedKFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f23c4907fa0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-30 17:34:27,274:INFO:Checking exceptions
2024-05-30 17:34:27,274:INFO:Importing libraries
2024-05-30 17:34:27,274:INFO:Copying training dataset
2024-05-30 17:34:27,279:INFO:Defining folds
2024-05-30 17:34:27,279:INFO:Declaring metric variables
2024-05-30 17:34:27,284:INFO:Importing untrained model
2024-05-30 17:34:27,289:INFO:Logistic Regression Imported successfully
2024-05-30 17:34:27,299:INFO:Starting cross validation
2024-05-30 17:34:27,300:INFO:Cross validating with StratifiedKFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2024-05-30 17:34:29,506:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:34:29,511:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:34:29,523:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:34:29,525:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:34:29,554:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:34:29,556:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:34:29,572:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:34:29,573:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:34:29,588:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:34:29,589:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:34:29,644:INFO:Calculating mean and std
2024-05-30 17:34:29,648:INFO:Creating metrics dataframe
2024-05-30 17:34:29,653:INFO:Uploading results into container
2024-05-30 17:34:29,654:INFO:Uploading model into container now
2024-05-30 17:34:29,655:INFO:_master_model_container: 1
2024-05-30 17:34:29,655:INFO:_display_container: 2
2024-05-30 17:34:29,655:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=43, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-30 17:34:29,655:INFO:create_model() successfully completed......................................
2024-05-30 17:34:29,833:INFO:SubProcess create_model() end ==================================
2024-05-30 17:34:29,833:INFO:Creating metrics dataframe
2024-05-30 17:34:29,840:INFO:Initializing K Neighbors Classifier
2024-05-30 17:34:29,841:INFO:Total runtime is 0.04287495215733846 minutes
2024-05-30 17:34:29,845:INFO:SubProcess create_model() called ==================================
2024-05-30 17:34:29,846:INFO:Initializing create_model()
2024-05-30 17:34:29,846:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f23c5012ef0>, estimator=knn, fold=StratifiedKFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f23c4907fa0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-30 17:34:29,846:INFO:Checking exceptions
2024-05-30 17:34:29,846:INFO:Importing libraries
2024-05-30 17:34:29,846:INFO:Copying training dataset
2024-05-30 17:34:29,852:INFO:Defining folds
2024-05-30 17:34:29,852:INFO:Declaring metric variables
2024-05-30 17:34:29,856:INFO:Importing untrained model
2024-05-30 17:34:29,859:INFO:K Neighbors Classifier Imported successfully
2024-05-30 17:34:29,871:INFO:Starting cross validation
2024-05-30 17:34:29,873:INFO:Cross validating with StratifiedKFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2024-05-30 17:34:31,653:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:34:31,685:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:34:31,703:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:34:31,716:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:34:32,041:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:34:32,070:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:34:32,086:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:34:32,098:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:34:32,139:INFO:Calculating mean and std
2024-05-30 17:34:32,140:INFO:Creating metrics dataframe
2024-05-30 17:34:32,142:INFO:Uploading results into container
2024-05-30 17:34:32,143:INFO:Uploading model into container now
2024-05-30 17:34:32,144:INFO:_master_model_container: 2
2024-05-30 17:34:32,144:INFO:_display_container: 2
2024-05-30 17:34:32,145:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-05-30 17:34:32,145:INFO:create_model() successfully completed......................................
2024-05-30 17:34:32,259:INFO:SubProcess create_model() end ==================================
2024-05-30 17:34:32,260:INFO:Creating metrics dataframe
2024-05-30 17:34:32,280:INFO:Initializing Quadratic Discriminant Analysis
2024-05-30 17:34:32,280:INFO:Total runtime is 0.08353202740351359 minutes
2024-05-30 17:34:32,283:INFO:SubProcess create_model() called ==================================
2024-05-30 17:34:32,284:INFO:Initializing create_model()
2024-05-30 17:34:32,284:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f23c5012ef0>, estimator=qda, fold=StratifiedKFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f23c4907fa0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-30 17:34:32,284:INFO:Checking exceptions
2024-05-30 17:34:32,284:INFO:Importing libraries
2024-05-30 17:34:32,284:INFO:Copying training dataset
2024-05-30 17:34:32,288:INFO:Defining folds
2024-05-30 17:34:32,289:INFO:Declaring metric variables
2024-05-30 17:34:32,292:INFO:Importing untrained model
2024-05-30 17:34:32,298:INFO:Quadratic Discriminant Analysis Imported successfully
2024-05-30 17:34:32,305:INFO:Starting cross validation
2024-05-30 17:34:32,306:INFO:Cross validating with StratifiedKFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2024-05-30 17:34:33,520:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-30 17:34:33,570:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:34:33,587:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:34:33,594:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:34:33,620:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:34:33,661:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:34:33,680:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:34:33,691:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:34:33,718:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:34:33,726:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:34:33,747:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:34:33,810:INFO:Calculating mean and std
2024-05-30 17:34:33,813:INFO:Creating metrics dataframe
2024-05-30 17:34:33,816:INFO:Uploading results into container
2024-05-30 17:34:33,817:INFO:Uploading model into container now
2024-05-30 17:34:33,818:INFO:_master_model_container: 3
2024-05-30 17:34:33,818:INFO:_display_container: 2
2024-05-30 17:34:33,818:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-05-30 17:34:33,819:INFO:create_model() successfully completed......................................
2024-05-30 17:34:33,934:INFO:SubProcess create_model() end ==================================
2024-05-30 17:34:33,934:INFO:Creating metrics dataframe
2024-05-30 17:34:33,941:INFO:Initializing Linear Discriminant Analysis
2024-05-30 17:34:33,941:INFO:Total runtime is 0.11121312777201335 minutes
2024-05-30 17:34:33,945:INFO:SubProcess create_model() called ==================================
2024-05-30 17:34:33,946:INFO:Initializing create_model()
2024-05-30 17:34:33,946:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f23c5012ef0>, estimator=lda, fold=StratifiedKFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f23c4907fa0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-30 17:34:33,946:INFO:Checking exceptions
2024-05-30 17:34:33,946:INFO:Importing libraries
2024-05-30 17:34:33,946:INFO:Copying training dataset
2024-05-30 17:34:33,951:INFO:Defining folds
2024-05-30 17:34:33,951:INFO:Declaring metric variables
2024-05-30 17:34:33,955:INFO:Importing untrained model
2024-05-30 17:34:33,958:INFO:Linear Discriminant Analysis Imported successfully
2024-05-30 17:34:33,967:INFO:Starting cross validation
2024-05-30 17:34:33,970:INFO:Cross validating with StratifiedKFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2024-05-30 17:34:35,170:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:34:35,175:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:34:35,190:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:34:35,195:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:34:35,220:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:34:35,224:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:34:35,237:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:34:35,240:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:34:35,251:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:34:35,253:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:34:35,305:INFO:Calculating mean and std
2024-05-30 17:34:35,306:INFO:Creating metrics dataframe
2024-05-30 17:34:35,309:INFO:Uploading results into container
2024-05-30 17:34:35,310:INFO:Uploading model into container now
2024-05-30 17:34:35,310:INFO:_master_model_container: 4
2024-05-30 17:34:35,311:INFO:_display_container: 2
2024-05-30 17:34:35,311:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-05-30 17:34:35,312:INFO:create_model() successfully completed......................................
2024-05-30 17:34:35,435:INFO:SubProcess create_model() end ==================================
2024-05-30 17:34:35,435:INFO:Creating metrics dataframe
2024-05-30 17:34:35,441:INFO:Initializing Light Gradient Boosting Machine
2024-05-30 17:34:35,442:INFO:Total runtime is 0.1362259030342102 minutes
2024-05-30 17:34:35,446:INFO:SubProcess create_model() called ==================================
2024-05-30 17:34:35,446:INFO:Initializing create_model()
2024-05-30 17:34:35,447:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f23c5012ef0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f23c4907fa0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-30 17:34:35,447:INFO:Checking exceptions
2024-05-30 17:34:35,447:INFO:Importing libraries
2024-05-30 17:34:35,447:INFO:Copying training dataset
2024-05-30 17:34:35,451:INFO:Defining folds
2024-05-30 17:34:35,451:INFO:Declaring metric variables
2024-05-30 17:34:35,454:INFO:Importing untrained model
2024-05-30 17:34:35,458:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-30 17:34:35,466:INFO:Starting cross validation
2024-05-30 17:34:35,468:INFO:Cross validating with StratifiedKFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2024-05-30 17:36:05,055:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:36:05,128:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:36:05,157:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:36:05,178:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:36:06,029:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:36:06,057:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:36:06,072:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:36:06,084:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:36:06,128:INFO:Calculating mean and std
2024-05-30 17:36:06,130:INFO:Creating metrics dataframe
2024-05-30 17:36:06,134:INFO:Uploading results into container
2024-05-30 17:36:06,134:INFO:Uploading model into container now
2024-05-30 17:36:06,135:INFO:_master_model_container: 5
2024-05-30 17:36:06,135:INFO:_display_container: 2
2024-05-30 17:36:06,136:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=43, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-05-30 17:36:06,136:INFO:create_model() successfully completed......................................
2024-05-30 17:36:06,257:INFO:SubProcess create_model() end ==================================
2024-05-30 17:36:06,257:INFO:Creating metrics dataframe
2024-05-30 17:36:06,273:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-30 17:36:06,283:INFO:Initializing create_model()
2024-05-30 17:36:06,284:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f23c5012ef0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=43, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-30 17:36:06,284:INFO:Checking exceptions
2024-05-30 17:36:06,286:INFO:Importing libraries
2024-05-30 17:36:06,286:INFO:Copying training dataset
2024-05-30 17:36:06,289:INFO:Defining folds
2024-05-30 17:36:06,289:INFO:Declaring metric variables
2024-05-30 17:36:06,290:INFO:Importing untrained model
2024-05-30 17:36:06,290:INFO:Declaring custom model
2024-05-30 17:36:06,290:INFO:Logistic Regression Imported successfully
2024-05-30 17:36:06,291:INFO:Cross validation set to False
2024-05-30 17:36:06,291:INFO:Fitting Model
2024-05-30 17:36:06,777:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=43, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-30 17:36:06,777:INFO:create_model() successfully completed......................................
2024-05-30 17:36:06,929:INFO:_master_model_container: 5
2024-05-30 17:36:06,929:INFO:_display_container: 2
2024-05-30 17:36:06,930:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=43, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-30 17:36:06,930:INFO:compare_models() successfully completed......................................
2024-05-30 17:37:09,046:INFO:PyCaret ClassificationExperiment
2024-05-30 17:37:09,046:INFO:Logging name: clf-default-name
2024-05-30 17:37:09,047:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-30 17:37:09,047:INFO:version 3.3.2
2024-05-30 17:37:09,047:INFO:Initializing setup()
2024-05-30 17:37:09,047:INFO:self.USI: ed39
2024-05-30 17:37:09,047:INFO:self._variable_keys: {'idx', 'USI', 'target_param', 'fold_shuffle_param', 'pipeline', 'gpu_n_jobs_param', 'memory', 'X', 'exp_id', '_ml_usecase', 'fold_groups_param', '_available_plots', 'y', 'y_train', 'X_train', 'fix_imbalance', 'exp_name_log', 'y_test', 'logging_param', 'X_test', 'gpu_param', 'seed', 'is_multiclass', 'data', 'n_jobs_param', 'html_param', 'fold_generator', 'log_plots_param'}
2024-05-30 17:37:09,047:INFO:Checking environment
2024-05-30 17:37:09,047:INFO:python_version: 3.10.0
2024-05-30 17:37:09,047:INFO:python_build: ('default', 'May 30 2024 16:31:14')
2024-05-30 17:37:09,047:INFO:machine: x86_64
2024-05-30 17:37:09,047:INFO:platform: Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31
2024-05-30 17:37:09,047:INFO:Memory: svmem(total=8181506048, available=4116860928, percent=49.7, used=3756601344, free=259768320, active=1040973824, inactive=6117314560, buffers=466935808, cached=3698200576, shared=131072, slab=607510528)
2024-05-30 17:37:09,048:INFO:Physical Core: 4
2024-05-30 17:37:09,048:INFO:Logical Core: 8
2024-05-30 17:37:09,048:INFO:Checking libraries
2024-05-30 17:37:09,048:INFO:System:
2024-05-30 17:37:09,048:INFO:    python: 3.10.0 (default, May 30 2024, 16:31:14) [GCC 9.3.0]
2024-05-30 17:37:09,048:INFO:executable: /home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/bin/python
2024-05-30 17:37:09,049:INFO:   machine: Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31
2024-05-30 17:37:09,049:INFO:PyCaret required dependencies:
2024-05-30 17:37:09,049:INFO:                 pip: 21.2.3
2024-05-30 17:37:09,049:INFO:          setuptools: 57.4.0
2024-05-30 17:37:09,049:INFO:             pycaret: 3.3.2
2024-05-30 17:37:09,049:INFO:             IPython: 8.24.0
2024-05-30 17:37:09,049:INFO:          ipywidgets: 8.1.3
2024-05-30 17:37:09,049:INFO:                tqdm: 4.66.4
2024-05-30 17:37:09,049:INFO:               numpy: 1.26.4
2024-05-30 17:37:09,049:INFO:              pandas: 2.1.4
2024-05-30 17:37:09,049:INFO:              jinja2: 3.1.4
2024-05-30 17:37:09,049:INFO:               scipy: 1.11.4
2024-05-30 17:37:09,049:INFO:              joblib: 1.3.2
2024-05-30 17:37:09,049:INFO:             sklearn: 1.4.2
2024-05-30 17:37:09,049:INFO:                pyod: 1.1.3
2024-05-30 17:37:09,049:INFO:            imblearn: 0.12.3
2024-05-30 17:37:09,049:INFO:   category_encoders: 2.6.3
2024-05-30 17:37:09,049:INFO:            lightgbm: 4.3.0
2024-05-30 17:37:09,049:INFO:               numba: 0.59.1
2024-05-30 17:37:09,049:INFO:            requests: 2.32.3
2024-05-30 17:37:09,049:INFO:          matplotlib: 3.7.5
2024-05-30 17:37:09,049:INFO:          scikitplot: 0.3.7
2024-05-30 17:37:09,049:INFO:         yellowbrick: 1.5
2024-05-30 17:37:09,049:INFO:              plotly: 5.22.0
2024-05-30 17:37:09,050:INFO:    plotly-resampler: Not installed
2024-05-30 17:37:09,050:INFO:             kaleido: 0.2.1
2024-05-30 17:37:09,050:INFO:           schemdraw: 0.15
2024-05-30 17:37:09,050:INFO:         statsmodels: 0.14.2
2024-05-30 17:37:09,050:INFO:              sktime: 0.26.0
2024-05-30 17:37:09,050:INFO:               tbats: 1.1.3
2024-05-30 17:37:09,050:INFO:            pmdarima: 2.0.4
2024-05-30 17:37:09,050:INFO:              psutil: 5.9.8
2024-05-30 17:37:09,050:INFO:          markupsafe: 2.1.5
2024-05-30 17:37:09,050:INFO:             pickle5: Not installed
2024-05-30 17:37:09,050:INFO:         cloudpickle: 3.0.0
2024-05-30 17:37:09,050:INFO:         deprecation: 2.1.0
2024-05-30 17:37:09,050:INFO:              xxhash: 3.4.1
2024-05-30 17:37:09,051:INFO:           wurlitzer: 3.1.0
2024-05-30 17:37:09,051:INFO:PyCaret optional dependencies:
2024-05-30 17:37:09,051:INFO:                shap: Not installed
2024-05-30 17:37:09,051:INFO:           interpret: Not installed
2024-05-30 17:37:09,051:INFO:                umap: Not installed
2024-05-30 17:37:09,051:INFO:     ydata_profiling: Not installed
2024-05-30 17:37:09,051:INFO:  explainerdashboard: Not installed
2024-05-30 17:37:09,051:INFO:             autoviz: Not installed
2024-05-30 17:37:09,052:INFO:           fairlearn: Not installed
2024-05-30 17:37:09,053:INFO:          deepchecks: Not installed
2024-05-30 17:37:09,053:INFO:             xgboost: Not installed
2024-05-30 17:37:09,053:INFO:            catboost: Not installed
2024-05-30 17:37:09,053:INFO:              kmodes: Not installed
2024-05-30 17:37:09,053:INFO:             mlxtend: Not installed
2024-05-30 17:37:09,053:INFO:       statsforecast: Not installed
2024-05-30 17:37:09,053:INFO:        tune_sklearn: Not installed
2024-05-30 17:37:09,053:INFO:                 ray: Not installed
2024-05-30 17:37:09,053:INFO:            hyperopt: Not installed
2024-05-30 17:37:09,053:INFO:              optuna: Not installed
2024-05-30 17:37:09,053:INFO:               skopt: Not installed
2024-05-30 17:37:09,053:INFO:              mlflow: Not installed
2024-05-30 17:37:09,053:INFO:              gradio: Not installed
2024-05-30 17:37:09,053:INFO:             fastapi: Not installed
2024-05-30 17:37:09,053:INFO:             uvicorn: Not installed
2024-05-30 17:37:09,053:INFO:              m2cgen: Not installed
2024-05-30 17:37:09,053:INFO:           evidently: Not installed
2024-05-30 17:37:09,053:INFO:               fugue: Not installed
2024-05-30 17:37:09,053:INFO:           streamlit: Not installed
2024-05-30 17:37:09,053:INFO:             prophet: Not installed
2024-05-30 17:37:09,053:INFO:None
2024-05-30 17:37:09,053:INFO:Set up data.
2024-05-30 17:37:09,091:INFO:Set up folding strategy.
2024-05-30 17:37:09,091:INFO:Set up train/test split.
2024-05-30 17:37:09,114:INFO:Set up index.
2024-05-30 17:37:09,115:INFO:Assigning column types.
2024-05-30 17:37:09,117:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-30 17:37:09,157:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-30 17:37:09,158:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-30 17:37:09,187:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:37:09,187:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:37:09,227:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-30 17:37:09,228:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-30 17:37:09,248:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:37:09,249:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:37:09,249:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-30 17:37:09,281:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-30 17:37:09,306:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:37:09,306:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:37:09,338:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-30 17:37:09,359:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:37:09,359:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:37:09,360:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-30 17:37:09,419:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:37:09,419:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:37:09,472:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:37:09,472:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:37:09,473:INFO:Preparing preprocessing pipeline...
2024-05-30 17:37:09,474:INFO:Set up label encoding.
2024-05-30 17:37:09,474:INFO:Set up simple imputation.
2024-05-30 17:37:09,476:INFO:Set up encoding of categorical features.
2024-05-30 17:37:09,620:INFO:Finished creating preprocessing pipeline.
2024-05-30 17:37:09,624:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='...
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['Text'],
                                    transformer=TargetEncoder(cols=['Text'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-05-30 17:37:09,624:INFO:Creating final display dataframe.
2024-05-30 17:37:10,173:INFO:Setup _display_container:                     Description  \
0                    Session id   
1                        Target   
2                   Target type   
3                Target mapping   
4           Original data shape   
5        Transformed data shape   
6   Transformed train set shape   
7    Transformed test set shape   
8          Categorical features   
9                    Preprocess   
10              Imputation type   
11           Numeric imputation   
12       Categorical imputation   
13     Maximum one-hot encoding   
14              Encoding method   
15               Fold Generator   
16                  Fold Number   
17                     CPU Jobs   
18                      Use GPU   
19               Log Experiment   
20              Experiment Name   
21                          USI   

                                                Value  
0                                                  43  
1                                             Emotion  
2                                          Multiclass  
3   anger: 0, fear: 1, joy: 2, love: 3, sadness: 4...  
4                                          (21459, 2)  
5                                          (21459, 2)  
6                                          (15021, 2)  
7                                           (6438, 2)  
8                                                   1  
9                                                True  
10                                             simple  
11                                               mean  
12                                               mode  
13                                                 25  
14                                               None  
15                                    StratifiedKFold  
16                                                100  
17                                                 -1  
18                                              False  
19                                              False  
20                                   clf-default-name  
21                                               ed39  
2024-05-30 17:37:10,250:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:37:10,251:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:37:10,311:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:37:10,311:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:37:10,313:INFO:setup() successfully completed in 1.27s...............
2024-05-30 17:37:10,315:INFO:Initializing compare_models()
2024-05-30 17:37:10,315:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f23c4f263e0>, include=['lr', 'knn', 'qda', 'lda'], fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f23c4f263e0>, 'include': ['lr', 'knn', 'qda', 'lda'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-05-30 17:37:10,315:INFO:Checking exceptions
2024-05-30 17:37:10,317:INFO:Preparing display monitor
2024-05-30 17:37:10,336:INFO:Initializing Logistic Regression
2024-05-30 17:37:10,336:INFO:Total runtime is 3.127257029215495e-06 minutes
2024-05-30 17:37:10,339:INFO:SubProcess create_model() called ==================================
2024-05-30 17:37:10,340:INFO:Initializing create_model()
2024-05-30 17:37:10,340:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f23c4f263e0>, estimator=lr, fold=StratifiedKFold(n_splits=100, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f23842d7430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-30 17:37:10,340:INFO:Checking exceptions
2024-05-30 17:37:10,340:INFO:Importing libraries
2024-05-30 17:37:10,340:INFO:Copying training dataset
2024-05-30 17:37:10,344:INFO:Defining folds
2024-05-30 17:37:10,344:INFO:Declaring metric variables
2024-05-30 17:37:10,349:INFO:Importing untrained model
2024-05-30 17:37:10,355:INFO:Logistic Regression Imported successfully
2024-05-30 17:37:10,364:INFO:Starting cross validation
2024-05-30 17:37:10,366:INFO:Cross validating with StratifiedKFold(n_splits=100, random_state=None, shuffle=False), n_jobs=-1
2024-05-30 17:37:10,944:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:10,947:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:10,953:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:10,956:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:10,960:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:10,975:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:10,975:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:10,978:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:10,978:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:10,984:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:10,986:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:10,987:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:10,990:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:10,991:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:10,993:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:11,049:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:11,053:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:11,065:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:11,066:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:11,069:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:11,069:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:11,069:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:11,073:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:11,073:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:11,074:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:11,074:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:11,077:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:11,077:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:11,080:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:11,077:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:11,084:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:11,088:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:11,099:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:11,102:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:11,105:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:11,232:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:11,236:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:11,244:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:11,248:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:11,252:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:11,567:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:11,570:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:11,578:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:11,580:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:11,583:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:11,717:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:11,720:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:11,722:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:11,725:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:11,729:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:11,732:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:11,735:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:11,735:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:11,737:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:11,741:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:11,843:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:11,846:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:11,851:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:11,854:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:11,858:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:11,968:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:11,970:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:11,987:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:11,991:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:11,994:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:11,999:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:11,999:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:12,001:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:12,001:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:12,002:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:12,004:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:12,004:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:12,016:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:12,019:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:12,027:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:12,152:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:12,159:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:12,169:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:12,176:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:12,179:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:12,362:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:12,366:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:12,376:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:12,378:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:12,382:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:12,569:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:12,573:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:12,581:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:12,584:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:12,588:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:12,718:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:12,721:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:12,728:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:12,732:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:12,735:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:12,738:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:12,741:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:12,747:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:12,749:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:12,749:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:12,752:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:12,752:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:12,756:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:12,758:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:12,760:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:12,761:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:12,763:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:12,766:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:12,769:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:12,772:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:12,799:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:12,802:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:12,810:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:12,812:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:12,816:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:12,825:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:12,828:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:12,834:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:12,838:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:12,841:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:13,017:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:13,020:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:13,027:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:13,029:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:13,033:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:13,043:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:13,048:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:13,054:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:13,057:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:13,062:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:13,337:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:13,339:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:13,347:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:13,351:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:13,354:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:13,416:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:13,419:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:13,423:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:13,428:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:13,432:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:13,437:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:13,441:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:13,450:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:13,453:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:13,457:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:13,481:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:13,485:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:13,489:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:13,491:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:13,498:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:13,594:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:13,594:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:13,601:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:13,603:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:13,610:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:13,611:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:13,612:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:13,615:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:13,616:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:13,618:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:13,710:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:13,715:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:13,726:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:13,729:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:13,732:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:13,860:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:13,863:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:13,869:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:13,872:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:13,876:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:14,040:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:14,046:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:14,053:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:14,056:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:14,067:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:14,136:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:14,142:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:14,148:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:14,149:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:14,152:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:14,153:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:14,155:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:14,162:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:14,165:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:14,168:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:14,233:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:14,235:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:14,247:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:14,250:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:14,253:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:14,306:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:14,317:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:14,323:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:14,326:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:14,342:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:14,414:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:14,418:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:14,423:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:14,429:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:14,434:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:14,475:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:14,485:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:14,503:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:14,505:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:14,509:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:14,699:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:14,702:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:14,711:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:14,714:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:14,717:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:14,754:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:14,759:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:14,765:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:14,767:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:14,771:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:14,801:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:14,804:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:14,809:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:14,812:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:14,817:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:14,969:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:14,975:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:14,980:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:14,982:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:14,985:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:15,024:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:15,027:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:15,033:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:15,035:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:15,039:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:15,064:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:15,075:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:15,080:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:15,083:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:15,087:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:15,120:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:15,122:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:15,135:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:15,138:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:15,142:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:15,253:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:15,259:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:15,266:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:15,269:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:15,277:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:15,355:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:15,359:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:15,365:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:15,367:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:15,370:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:15,389:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:15,393:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:15,399:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:15,401:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:15,402:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:15,404:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:15,405:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:15,413:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:15,417:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:15,420:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:15,675:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:15,678:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:15,683:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:15,686:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:15,690:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:15,725:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:15,727:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:15,734:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:15,737:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:15,741:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:15,758:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:15,761:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:15,774:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:15,777:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:15,780:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:15,915:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:15,918:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:15,931:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:15,933:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:15,936:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:15,939:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:15,942:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:15,944:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:15,944:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:15,950:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:15,950:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:15,952:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:15,952:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:15,955:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:15,957:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:16,072:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:16,077:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:16,082:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:16,085:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:16,091:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:16,100:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:16,104:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:16,111:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:16,114:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:16,118:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:16,246:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:16,250:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:16,256:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:16,259:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:16,263:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:16,515:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:16,519:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:16,527:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:16,530:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:16,535:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:16,554:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:16,561:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:16,567:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:16,569:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:16,594:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:16,594:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:16,597:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:16,602:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:16,605:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:16,612:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:16,798:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:16,801:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:16,814:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:16,817:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:16,825:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:16,864:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:16,867:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:16,883:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:16,885:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:16,889:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:16,892:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:16,895:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:16,911:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:16,925:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:16,930:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:17,047:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:17,050:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:17,067:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:17,083:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:17,097:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:17,103:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:17,107:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:17,124:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:17,127:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:17,130:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:17,224:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:17,227:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:17,232:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:17,235:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:17,238:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:17,289:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:17,293:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:17,299:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:17,301:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:17,305:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:17,420:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:17,423:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:17,428:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:17,431:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:17,433:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:17,434:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:17,437:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:17,443:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:17,446:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:17,449:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:17,574:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:17,578:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:17,583:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:17,586:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:17,591:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:17,593:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:17,596:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:17,601:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:17,604:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:17,609:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:17,664:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:17,667:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:17,671:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:17,675:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:17,676:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:17,678:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:17,680:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:17,681:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:17,683:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:17,686:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:17,784:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:17,787:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:17,795:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:17,798:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:17,803:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:17,834:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:17,837:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:17,843:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:17,848:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:17,852:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:17,974:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:17,980:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:17,987:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:17,990:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:17,994:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:18,153:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:18,158:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:18,163:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:18,165:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:18,169:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:18,193:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:18,196:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:18,201:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:18,204:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:18,207:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:18,220:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:18,227:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:18,233:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:18,235:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:18,242:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:18,256:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:18,260:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:18,266:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:18,268:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:18,272:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:18,323:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:18,326:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:18,336:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:18,341:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:18,344:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:18,422:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:18,426:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:18,431:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:18,434:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:18,437:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:18,554:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:18,558:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:18,565:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:18,567:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:18,570:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:18,581:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:18,584:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:18,590:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:18,594:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:18,597:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:18,859:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:18,862:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:18,867:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:18,869:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:18,874:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:18,903:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:18,906:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:18,911:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:18,914:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:18,917:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:19,062:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:19,064:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:19,067:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:19,075:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:19,076:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:19,078:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:19,080:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:19,081:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:19,082:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:19,085:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:19,122:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:19,126:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:19,131:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:19,134:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:19,137:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:19,161:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:19,164:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:19,165:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:19,169:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:19,176:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:19,178:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:19,179:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:19,188:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:19,192:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:19,195:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:19,269:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:19,274:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:19,279:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:19,282:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:19,284:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:19,432:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:19,434:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:19,438:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:19,441:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:19,444:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:19,450:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:19,453:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:19,459:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:19,461:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:19,463:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:19,552:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:19,554:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:19,557:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:19,559:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:19,559:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:19,561:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:19,561:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:19,563:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:19,565:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:19,566:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:19,580:INFO:Calculating mean and std
2024-05-30 17:37:19,581:INFO:Creating metrics dataframe
2024-05-30 17:37:19,584:INFO:Uploading results into container
2024-05-30 17:37:19,584:INFO:Uploading model into container now
2024-05-30 17:37:19,585:INFO:_master_model_container: 1
2024-05-30 17:37:19,585:INFO:_display_container: 2
2024-05-30 17:37:19,586:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=43, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-30 17:37:19,586:INFO:create_model() successfully completed......................................
2024-05-30 17:37:19,702:INFO:SubProcess create_model() end ==================================
2024-05-30 17:37:19,702:INFO:Creating metrics dataframe
2024-05-30 17:37:19,708:INFO:Initializing K Neighbors Classifier
2024-05-30 17:37:19,708:INFO:Total runtime is 0.15620932976404828 minutes
2024-05-30 17:37:19,712:INFO:SubProcess create_model() called ==================================
2024-05-30 17:37:19,713:INFO:Initializing create_model()
2024-05-30 17:37:19,713:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f23c4f263e0>, estimator=knn, fold=StratifiedKFold(n_splits=100, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f23842d7430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-30 17:37:19,713:INFO:Checking exceptions
2024-05-30 17:37:19,713:INFO:Importing libraries
2024-05-30 17:37:19,713:INFO:Copying training dataset
2024-05-30 17:37:19,717:INFO:Defining folds
2024-05-30 17:37:19,718:INFO:Declaring metric variables
2024-05-30 17:37:19,722:INFO:Importing untrained model
2024-05-30 17:37:19,727:INFO:K Neighbors Classifier Imported successfully
2024-05-30 17:37:19,736:INFO:Starting cross validation
2024-05-30 17:37:19,738:INFO:Cross validating with StratifiedKFold(n_splits=100, random_state=None, shuffle=False), n_jobs=-1
2024-05-30 17:37:19,973:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:19,975:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:19,978:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:19,980:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:19,980:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:19,983:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:19,983:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:19,986:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:19,994:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:19,999:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,001:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:20,003:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,017:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,021:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,023:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,024:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:20,028:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,030:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:20,033:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,035:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,035:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,036:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,040:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,043:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,045:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:20,046:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:20,049:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,049:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,050:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,058:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,061:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:20,064:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,192:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,197:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,199:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:20,202:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,210:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,215:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,217:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:20,222:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,234:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,238:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,241:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:20,244:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,257:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,258:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,264:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,264:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,266:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:20,267:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,269:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,269:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,270:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:20,271:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:20,274:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,274:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,326:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,331:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,333:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:20,337:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,362:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,369:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,373:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:20,376:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,440:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,442:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,445:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,447:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:20,451:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,452:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,453:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:20,456:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,469:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,476:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,479:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:20,482:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,540:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,545:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,548:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:20,550:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,552:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,559:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,562:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,564:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:20,565:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,568:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,571:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:20,579:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,583:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,588:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,593:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:20,597:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,707:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,708:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,713:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,714:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,716:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:20,716:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:20,719:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,722:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,722:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,726:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,733:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,737:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:20,737:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,741:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:20,741:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,744:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,800:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,804:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,807:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:20,811:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,815:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,819:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,819:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,821:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:20,822:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,825:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,826:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,828:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,829:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:20,830:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:20,832:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,832:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,971:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,973:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,978:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,979:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,983:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:20,983:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,984:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:20,986:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,988:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,989:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:20,992:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:20,997:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,038:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,052:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,055:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:21,058:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,078:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,083:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,094:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,095:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:21,101:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,102:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,103:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,107:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:21,110:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,110:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,113:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:21,115:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,140:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,147:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,166:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:21,169:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,190:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,195:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,197:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:21,200:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,258:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,267:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,270:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:21,273:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,287:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,293:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,298:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,299:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,300:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:21,302:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:21,303:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,306:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,367:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,373:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,377:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:21,380:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,390:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,395:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,398:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:21,401:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,418:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,423:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,426:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:21,428:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,429:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,437:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,440:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:21,448:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,516:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,521:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,523:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:21,531:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,561:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,570:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,576:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,579:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:21,585:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,592:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,604:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,605:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,607:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:21,607:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:21,610:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,611:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,686:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,691:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,692:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,693:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:21,697:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,697:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,699:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:21,702:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,751:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,756:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,761:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:21,765:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,802:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,813:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,814:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:21,818:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,852:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,857:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,861:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:21,864:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,881:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,887:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,889:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:21,892:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,913:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,925:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,927:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,927:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:21,930:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,933:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,936:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:21,939:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,970:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,977:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:21,979:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:21,982:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,003:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,012:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,014:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:22,017:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,019:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,027:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,029:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:22,032:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,067:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,072:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,075:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:22,077:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,091:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,097:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,100:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:22,102:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,112:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,117:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,120:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:22,125:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,157:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,161:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,164:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:22,166:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,183:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,188:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,190:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:22,194:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,212:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,216:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,219:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:22,222:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,249:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,253:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,257:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:22,259:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,260:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,263:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,266:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:22,269:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,315:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,318:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,322:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:22,326:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,340:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,342:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,345:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,346:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,347:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:22,349:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:22,350:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,351:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,383:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,387:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,389:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:22,393:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,414:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,420:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,424:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:22,427:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,427:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,431:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,434:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:22,437:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,455:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,459:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,461:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:22,464:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,528:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,532:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,534:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:22,536:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,543:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,550:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,552:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:22,555:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,556:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,561:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,563:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:22,566:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,585:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,592:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,594:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:22,599:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,631:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,635:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,637:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,638:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:22,643:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,645:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,645:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:22,648:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,661:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,665:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,668:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:22,671:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,689:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,702:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,704:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:22,707:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,742:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,743:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,748:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,749:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:22,750:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,753:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:22,754:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,757:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,800:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,805:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,808:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:22,808:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,811:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,818:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,820:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:22,823:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,873:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,878:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,878:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,880:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:22,882:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,882:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,884:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:22,887:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,891:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,896:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,898:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:22,901:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,961:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,965:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,968:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:22,971:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,994:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,996:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:22,998:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,000:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:23,000:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,002:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,002:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:23,006:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,026:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,030:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,032:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:23,033:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,035:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,038:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,041:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:23,044:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,062:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,066:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,067:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:23,069:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,069:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,071:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,073:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:23,074:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,095:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,097:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,098:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:23,099:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,109:INFO:Calculating mean and std
2024-05-30 17:37:23,111:INFO:Creating metrics dataframe
2024-05-30 17:37:23,113:INFO:Uploading results into container
2024-05-30 17:37:23,113:INFO:Uploading model into container now
2024-05-30 17:37:23,114:INFO:_master_model_container: 2
2024-05-30 17:37:23,114:INFO:_display_container: 2
2024-05-30 17:37:23,114:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-05-30 17:37:23,114:INFO:create_model() successfully completed......................................
2024-05-30 17:37:23,217:INFO:SubProcess create_model() end ==================================
2024-05-30 17:37:23,217:INFO:Creating metrics dataframe
2024-05-30 17:37:23,224:INFO:Initializing Quadratic Discriminant Analysis
2024-05-30 17:37:23,224:INFO:Total runtime is 0.2148115674654643 minutes
2024-05-30 17:37:23,228:INFO:SubProcess create_model() called ==================================
2024-05-30 17:37:23,228:INFO:Initializing create_model()
2024-05-30 17:37:23,228:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f23c4f263e0>, estimator=qda, fold=StratifiedKFold(n_splits=100, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f23842d7430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-30 17:37:23,228:INFO:Checking exceptions
2024-05-30 17:37:23,228:INFO:Importing libraries
2024-05-30 17:37:23,229:INFO:Copying training dataset
2024-05-30 17:37:23,232:INFO:Defining folds
2024-05-30 17:37:23,232:INFO:Declaring metric variables
2024-05-30 17:37:23,235:INFO:Importing untrained model
2024-05-30 17:37:23,239:INFO:Quadratic Discriminant Analysis Imported successfully
2024-05-30 17:37:23,249:INFO:Starting cross validation
2024-05-30 17:37:23,251:INFO:Cross validating with StratifiedKFold(n_splits=100, random_state=None, shuffle=False), n_jobs=-1
2024-05-30 17:37:23,399:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:23,401:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,408:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,411:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:23,414:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,418:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:23,421:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,421:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:23,426:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,426:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,428:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:23,430:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,431:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,432:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:23,435:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,438:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:23,442:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,447:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,448:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:23,450:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,461:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:23,464:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,469:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,470:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:23,471:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:23,473:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,475:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,477:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,479:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:23,481:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,494:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:23,496:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,500:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,503:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:23,503:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:23,506:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,506:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,510:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,512:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:23,515:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,579:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:23,582:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,587:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:23,587:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,590:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:23,593:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,594:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,602:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,604:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:23,608:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:23,611:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,611:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,617:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,624:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:23,630:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,634:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:23,637:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,642:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,647:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:23,651:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,667:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:23,671:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,677:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,679:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:23,682:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,697:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:23,700:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,701:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:23,705:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,705:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,707:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:23,710:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,712:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,714:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:23,721:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,729:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:23,732:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,738:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,741:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:23,744:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,803:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:23,806:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,810:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:23,811:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,813:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,814:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:23,818:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,825:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,828:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:23,837:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,857:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:23,860:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,889:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,889:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:23,892:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:23,892:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:23,893:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,902:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,905:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,907:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,908:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:23,912:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,914:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,920:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:23,933:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,951:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:23,961:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,968:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,979:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:23,981:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:23,983:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,985:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,994:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:23,996:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:24,010:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,055:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:24,064:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,071:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,082:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:24,086:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,107:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:24,110:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,128:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,131:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:24,135:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,142:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:24,145:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,145:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:24,149:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,152:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,154:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,156:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:24,157:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:24,159:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,160:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:24,160:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,163:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,168:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,170:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:24,174:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,174:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:24,177:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,184:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:24,184:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,187:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:24,191:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,193:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,196:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,196:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:24,198:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:24,199:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,202:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,204:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,207:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:24,209:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,310:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:24,313:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,319:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,323:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:24,328:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,342:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:24,348:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:24,351:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,352:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,353:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:24,357:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,358:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:24,358:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,359:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:24,360:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,361:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:24,362:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,363:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,366:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,366:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,368:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:24,371:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,371:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,380:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:24,385:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,398:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:24,400:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,406:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,409:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:24,412:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,445:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:24,448:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,460:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,462:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:24,465:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,477:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:24,478:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:24,479:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,480:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,484:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,485:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,486:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:24,488:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:24,492:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,492:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,508:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:24,511:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,518:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,522:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:24,524:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:24,525:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,527:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,533:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,536:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:24,540:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,558:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:24,563:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,569:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,569:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:24,573:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:24,575:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,576:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,579:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,583:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:24,586:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,589:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:24,594:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,598:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,600:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:24,604:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,634:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:24,644:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,649:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,651:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:24,655:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,656:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:24,658:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,663:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,665:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:24,669:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,700:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:24,702:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,703:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:24,708:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,710:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,712:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:24,713:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,716:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:24,716:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,718:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,742:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:24,747:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:24,747:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,750:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,755:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,757:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,758:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:24,760:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:24,760:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,763:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,771:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:24,778:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,783:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,785:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:24,786:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:24,788:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,789:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,795:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,797:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:24,802:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,817:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:24,821:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,826:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,829:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:24,832:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,835:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:24,839:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,844:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,847:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:24,856:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,857:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:24,859:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,863:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,865:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:24,868:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,873:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:24,876:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,881:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,884:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:24,887:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,914:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:24,917:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,923:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,927:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:24,930:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,930:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:24,932:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,938:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,942:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:24,945:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:24,946:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,947:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,952:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,957:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:24,959:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:24,960:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,962:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,967:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,970:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:24,971:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:24,973:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,975:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,980:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,983:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:24,986:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,990:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:24,993:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,998:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:24,999:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:25,002:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,043:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:25,045:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,050:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,052:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:25,055:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,066:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:25,069:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,076:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,078:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:25,082:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,093:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:25,096:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,101:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,103:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:25,106:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:25,109:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,109:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,114:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,116:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:25,119:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:25,121:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,122:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,128:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,130:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:25,133:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,139:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:25,142:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,148:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,150:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:25,156:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,163:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:25,166:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,171:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,175:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:25,178:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,186:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:25,189:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,194:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,195:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:25,196:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:25,198:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,200:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,202:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,204:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:25,208:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,223:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:25,230:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,235:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,237:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:25,246:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:25,246:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,250:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,255:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,257:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:25,260:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,276:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:25,279:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,283:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:25,283:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,285:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:25,288:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,291:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,294:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,297:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:25,299:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,315:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:25,316:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:25,317:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,319:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,324:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,326:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:25,327:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,329:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,330:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:25,333:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,344:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:25,347:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,352:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,355:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:25,358:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,378:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:25,381:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,386:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,389:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:25,392:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,407:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:25,410:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,414:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,416:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:25,418:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,427:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:25,429:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,430:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:25,432:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,434:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,437:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,438:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:25,439:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:25,441:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,442:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,453:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:25,457:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,462:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,465:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:25,468:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,478:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:25,480:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,485:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,487:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:25,491:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,510:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:25,513:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,518:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,520:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:25,524:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,525:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:25,527:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,532:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,534:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:25,537:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,538:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:25,539:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:25,542:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,546:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,547:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,550:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:25,552:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,553:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,554:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:25,557:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,568:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:25,572:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,579:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,582:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:25,585:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,598:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:25,601:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,608:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,611:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:25,614:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,621:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:25,623:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:25,625:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,625:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,629:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,630:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,632:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:25,632:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:25,635:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,635:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,657:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:25,660:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,664:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,666:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:25,669:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,679:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:25,681:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,686:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,689:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:25,692:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,707:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:25,710:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,715:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,717:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:25,719:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:25,719:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,722:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,725:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,726:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:25,728:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:25,728:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,729:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,732:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,733:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:25,733:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:25,735:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,736:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,739:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,741:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:25,742:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,744:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:25,745:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,748:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,749:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:25,751:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:25,767:INFO:Calculating mean and std
2024-05-30 17:37:25,769:INFO:Creating metrics dataframe
2024-05-30 17:37:25,772:INFO:Uploading results into container
2024-05-30 17:37:25,772:INFO:Uploading model into container now
2024-05-30 17:37:25,773:INFO:_master_model_container: 3
2024-05-30 17:37:25,773:INFO:_display_container: 2
2024-05-30 17:37:25,774:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-05-30 17:37:25,774:INFO:create_model() successfully completed......................................
2024-05-30 17:37:25,903:INFO:SubProcess create_model() end ==================================
2024-05-30 17:37:25,904:INFO:Creating metrics dataframe
2024-05-30 17:37:25,912:INFO:Initializing Linear Discriminant Analysis
2024-05-30 17:37:25,912:INFO:Total runtime is 0.25961166620254517 minutes
2024-05-30 17:37:25,915:INFO:SubProcess create_model() called ==================================
2024-05-30 17:37:25,916:INFO:Initializing create_model()
2024-05-30 17:37:25,916:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f23c4f263e0>, estimator=lda, fold=StratifiedKFold(n_splits=100, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f23842d7430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-30 17:37:25,916:INFO:Checking exceptions
2024-05-30 17:37:25,916:INFO:Importing libraries
2024-05-30 17:37:25,916:INFO:Copying training dataset
2024-05-30 17:37:25,920:INFO:Defining folds
2024-05-30 17:37:25,921:INFO:Declaring metric variables
2024-05-30 17:37:25,926:INFO:Importing untrained model
2024-05-30 17:37:25,931:INFO:Linear Discriminant Analysis Imported successfully
2024-05-30 17:37:25,939:INFO:Starting cross validation
2024-05-30 17:37:25,942:INFO:Cross validating with StratifiedKFold(n_splits=100, random_state=None, shuffle=False), n_jobs=-1
2024-05-30 17:37:26,097:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:26,099:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,108:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,111:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:26,116:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,119:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:26,125:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,130:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,132:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:26,136:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,145:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:26,160:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:26,164:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,166:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,166:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:26,168:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,170:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,172:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:26,172:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,175:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:26,175:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,177:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,177:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,180:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:26,183:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,217:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:26,220:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,227:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,229:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:26,233:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,234:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:26,247:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,247:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:26,249:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,252:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,255:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:26,257:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,261:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:26,264:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,267:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,382:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:26,386:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,391:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:26,394:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,395:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,397:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:26,399:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:26,400:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,402:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,407:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,413:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:26,415:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,416:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,418:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:26,426:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,431:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:26,434:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,439:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,442:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:26,443:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:26,445:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,445:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,456:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,459:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:26,462:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,508:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:26,510:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:26,511:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,515:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,517:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,521:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,524:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:26,525:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:26,527:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,528:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,598:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:26,602:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,606:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:26,610:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,612:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,612:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:26,615:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,618:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,622:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:26,630:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,649:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:26,651:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,653:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:26,654:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:26,659:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,660:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,660:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,664:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:26,666:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,666:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,667:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,667:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:26,668:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:26,668:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:26,670:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,673:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,673:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,678:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,680:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:26,683:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,710:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:26,712:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,717:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,719:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:26,721:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:26,724:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,724:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,729:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,731:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:26,734:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,753:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:26,757:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,761:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,764:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:26,767:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,803:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:26,806:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,811:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,814:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:26,814:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:26,815:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:26,816:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,817:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,818:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,821:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,822:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:26,825:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:26,825:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,826:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,828:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:26,828:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,829:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,831:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,831:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:26,834:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:26,835:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,837:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,845:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,848:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:26,851:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,871:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:26,874:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,878:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,879:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:26,882:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,882:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:26,885:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,886:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,889:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:26,898:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,961:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:26,964:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,969:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,974:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:26,975:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:26,977:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,977:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,982:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:26,985:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:26,989:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,003:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:27,006:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,009:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:27,012:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,012:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,014:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:27,018:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,018:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,020:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:27,023:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,035:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:27,038:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,044:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,047:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:27,047:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:27,049:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,050:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,056:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,059:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:27,062:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,068:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:27,071:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,075:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,078:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:27,082:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,111:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:27,112:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:27,115:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,116:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,121:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,122:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,124:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:27,125:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:27,127:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,128:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,145:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:27,148:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,153:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,155:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:27,156:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:27,160:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,161:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,167:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,169:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:27,173:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,180:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:27,183:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,186:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:27,192:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,192:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,195:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:27,198:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,199:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,200:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:27,201:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:27,203:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,204:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,209:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,211:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:27,214:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,223:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:27,226:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,232:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,235:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:27,238:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,263:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:27,266:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,273:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,276:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:27,280:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,298:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:27,301:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,308:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,311:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:27,313:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,330:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:27,334:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,339:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,341:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:27,344:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,345:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:27,347:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,352:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,357:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:27,360:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,370:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:27,373:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,378:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,381:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:27,382:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:27,384:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,385:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,391:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,391:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:27,393:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:27,395:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,396:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,400:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,402:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:27,406:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,411:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:27,414:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,419:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,422:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:27,424:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,448:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:27,450:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,455:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,458:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:27,461:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,493:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:27,494:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:27,496:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,497:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,502:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,502:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,504:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:27,507:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:27,507:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,510:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,515:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:27,518:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,525:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,528:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:27,532:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,532:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:27,534:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,535:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:27,540:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,541:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,543:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:27,544:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:27,546:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,546:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,547:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,549:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:27,551:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,552:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,553:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:27,557:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,572:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:27,575:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,579:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,582:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:27,586:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,597:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:27,601:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,606:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,608:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:27,613:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,632:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:27,635:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,641:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,644:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:27,647:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,682:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:27,685:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,690:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,692:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:27,696:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,712:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:27,715:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,718:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:27,720:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,723:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:27,724:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,727:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,729:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,732:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:27,735:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,747:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:27,749:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,750:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:27,755:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,758:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,760:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:27,760:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,761:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:27,763:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:27,763:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,764:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,765:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,773:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,776:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:27,779:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,788:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:27,790:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,801:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,803:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:27,806:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:27,807:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,810:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,814:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,817:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:27,820:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,821:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:27,824:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,829:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,831:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:27,835:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,868:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:27,871:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,876:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,878:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:27,881:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,889:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:27,893:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,898:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:27,899:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,899:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:27,900:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,902:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:27,902:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,905:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,907:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,910:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:27,911:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,913:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:27,913:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,916:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,930:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:27,933:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,943:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,949:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:27,954:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:27,955:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:27,956:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,957:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,959:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,962:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,963:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,965:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:27,967:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:27,967:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:27,969:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,013:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:28,016:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,021:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,024:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:28,027:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,053:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:28,058:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,063:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,065:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:28,068:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,074:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:28,078:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,083:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,086:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:28,089:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,097:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:28,099:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,108:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,111:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:28,113:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:28,114:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,115:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:28,116:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,117:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,119:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,121:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:28,122:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,124:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:28,127:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,128:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,162:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:28,163:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:28,166:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,167:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,173:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,174:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,176:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:28,177:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:28,178:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,179:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:28,180:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,181:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,188:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,192:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:28,195:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,209:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:28,212:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,218:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,223:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:28,228:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,244:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:28,247:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,254:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,260:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:28,264:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,270:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:28,276:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,281:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:28,282:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,285:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,284:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:28,290:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:28,292:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,293:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,295:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,297:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:28,299:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,300:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,302:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:28,306:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,328:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:28,330:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,332:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:28,335:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,335:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,337:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:28,339:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,340:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,342:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:28,345:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,368:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:28,371:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,375:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,377:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:28,379:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,391:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:28,393:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,396:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:28,398:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,398:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,400:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:28,403:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,403:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,405:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:28,408:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,415:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:37:28,416:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,419:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,420:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:37:28,422:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:37:28,431:INFO:Calculating mean and std
2024-05-30 17:37:28,433:INFO:Creating metrics dataframe
2024-05-30 17:37:28,435:INFO:Uploading results into container
2024-05-30 17:37:28,436:INFO:Uploading model into container now
2024-05-30 17:37:28,437:INFO:_master_model_container: 4
2024-05-30 17:37:28,437:INFO:_display_container: 2
2024-05-30 17:37:28,438:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-05-30 17:37:28,438:INFO:create_model() successfully completed......................................
2024-05-30 17:37:28,544:INFO:SubProcess create_model() end ==================================
2024-05-30 17:37:28,544:INFO:Creating metrics dataframe
2024-05-30 17:37:28,552:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-30 17:37:28,561:INFO:Initializing create_model()
2024-05-30 17:37:28,561:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f23c4f263e0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=43, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=100, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-30 17:37:28,561:INFO:Checking exceptions
2024-05-30 17:37:28,563:INFO:Importing libraries
2024-05-30 17:37:28,563:INFO:Copying training dataset
2024-05-30 17:37:28,567:INFO:Defining folds
2024-05-30 17:37:28,567:INFO:Declaring metric variables
2024-05-30 17:37:28,567:INFO:Importing untrained model
2024-05-30 17:37:28,567:INFO:Declaring custom model
2024-05-30 17:37:28,568:INFO:Logistic Regression Imported successfully
2024-05-30 17:37:28,569:INFO:Cross validation set to False
2024-05-30 17:37:28,569:INFO:Fitting Model
2024-05-30 17:37:29,331:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=43, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-30 17:37:29,332:INFO:create_model() successfully completed......................................
2024-05-30 17:37:29,510:INFO:_master_model_container: 4
2024-05-30 17:37:29,511:INFO:_display_container: 2
2024-05-30 17:37:29,511:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=43, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-30 17:37:29,511:INFO:compare_models() successfully completed......................................
2024-05-30 17:38:59,389:INFO:PyCaret ClassificationExperiment
2024-05-30 17:38:59,389:INFO:Logging name: clf-default-name
2024-05-30 17:38:59,389:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-30 17:38:59,389:INFO:version 3.3.2
2024-05-30 17:38:59,389:INFO:Initializing setup()
2024-05-30 17:38:59,389:INFO:self.USI: 62ed
2024-05-30 17:38:59,389:INFO:self._variable_keys: {'idx', 'USI', 'target_param', 'fold_shuffle_param', 'pipeline', 'gpu_n_jobs_param', 'memory', 'X', 'exp_id', '_ml_usecase', 'fold_groups_param', '_available_plots', 'y', 'y_train', 'X_train', 'fix_imbalance', 'exp_name_log', 'y_test', 'logging_param', 'X_test', 'gpu_param', 'seed', 'is_multiclass', 'data', 'n_jobs_param', 'html_param', 'fold_generator', 'log_plots_param'}
2024-05-30 17:38:59,389:INFO:Checking environment
2024-05-30 17:38:59,389:INFO:python_version: 3.10.0
2024-05-30 17:38:59,389:INFO:python_build: ('default', 'May 30 2024 16:31:14')
2024-05-30 17:38:59,389:INFO:machine: x86_64
2024-05-30 17:38:59,389:INFO:platform: Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31
2024-05-30 17:38:59,389:INFO:Memory: svmem(total=8181506048, available=4060635136, percent=50.4, used=3812827136, free=201547776, active=1041166336, inactive=6173110272, buffers=467128320, cached=3700002816, shared=131072, slab=607432704)
2024-05-30 17:38:59,390:INFO:Physical Core: 4
2024-05-30 17:38:59,391:INFO:Logical Core: 8
2024-05-30 17:38:59,391:INFO:Checking libraries
2024-05-30 17:38:59,391:INFO:System:
2024-05-30 17:38:59,391:INFO:    python: 3.10.0 (default, May 30 2024, 16:31:14) [GCC 9.3.0]
2024-05-30 17:38:59,391:INFO:executable: /home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/bin/python
2024-05-30 17:38:59,391:INFO:   machine: Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31
2024-05-30 17:38:59,391:INFO:PyCaret required dependencies:
2024-05-30 17:38:59,392:INFO:                 pip: 21.2.3
2024-05-30 17:38:59,392:INFO:          setuptools: 57.4.0
2024-05-30 17:38:59,392:INFO:             pycaret: 3.3.2
2024-05-30 17:38:59,392:INFO:             IPython: 8.24.0
2024-05-30 17:38:59,392:INFO:          ipywidgets: 8.1.3
2024-05-30 17:38:59,392:INFO:                tqdm: 4.66.4
2024-05-30 17:38:59,392:INFO:               numpy: 1.26.4
2024-05-30 17:38:59,392:INFO:              pandas: 2.1.4
2024-05-30 17:38:59,392:INFO:              jinja2: 3.1.4
2024-05-30 17:38:59,392:INFO:               scipy: 1.11.4
2024-05-30 17:38:59,392:INFO:              joblib: 1.3.2
2024-05-30 17:38:59,392:INFO:             sklearn: 1.4.2
2024-05-30 17:38:59,392:INFO:                pyod: 1.1.3
2024-05-30 17:38:59,392:INFO:            imblearn: 0.12.3
2024-05-30 17:38:59,392:INFO:   category_encoders: 2.6.3
2024-05-30 17:38:59,392:INFO:            lightgbm: 4.3.0
2024-05-30 17:38:59,392:INFO:               numba: 0.59.1
2024-05-30 17:38:59,392:INFO:            requests: 2.32.3
2024-05-30 17:38:59,393:INFO:          matplotlib: 3.7.5
2024-05-30 17:38:59,393:INFO:          scikitplot: 0.3.7
2024-05-30 17:38:59,393:INFO:         yellowbrick: 1.5
2024-05-30 17:38:59,393:INFO:              plotly: 5.22.0
2024-05-30 17:38:59,393:INFO:    plotly-resampler: Not installed
2024-05-30 17:38:59,393:INFO:             kaleido: 0.2.1
2024-05-30 17:38:59,393:INFO:           schemdraw: 0.15
2024-05-30 17:38:59,393:INFO:         statsmodels: 0.14.2
2024-05-30 17:38:59,393:INFO:              sktime: 0.26.0
2024-05-30 17:38:59,393:INFO:               tbats: 1.1.3
2024-05-30 17:38:59,393:INFO:            pmdarima: 2.0.4
2024-05-30 17:38:59,393:INFO:              psutil: 5.9.8
2024-05-30 17:38:59,393:INFO:          markupsafe: 2.1.5
2024-05-30 17:38:59,393:INFO:             pickle5: Not installed
2024-05-30 17:38:59,393:INFO:         cloudpickle: 3.0.0
2024-05-30 17:38:59,393:INFO:         deprecation: 2.1.0
2024-05-30 17:38:59,393:INFO:              xxhash: 3.4.1
2024-05-30 17:38:59,393:INFO:           wurlitzer: 3.1.0
2024-05-30 17:38:59,394:INFO:PyCaret optional dependencies:
2024-05-30 17:38:59,394:INFO:                shap: Not installed
2024-05-30 17:38:59,394:INFO:           interpret: Not installed
2024-05-30 17:38:59,394:INFO:                umap: Not installed
2024-05-30 17:38:59,394:INFO:     ydata_profiling: Not installed
2024-05-30 17:38:59,394:INFO:  explainerdashboard: Not installed
2024-05-30 17:38:59,394:INFO:             autoviz: Not installed
2024-05-30 17:38:59,395:INFO:           fairlearn: Not installed
2024-05-30 17:38:59,395:INFO:          deepchecks: Not installed
2024-05-30 17:38:59,395:INFO:             xgboost: Not installed
2024-05-30 17:38:59,395:INFO:            catboost: Not installed
2024-05-30 17:38:59,395:INFO:              kmodes: Not installed
2024-05-30 17:38:59,395:INFO:             mlxtend: Not installed
2024-05-30 17:38:59,395:INFO:       statsforecast: Not installed
2024-05-30 17:38:59,395:INFO:        tune_sklearn: Not installed
2024-05-30 17:38:59,395:INFO:                 ray: Not installed
2024-05-30 17:38:59,395:INFO:            hyperopt: Not installed
2024-05-30 17:38:59,395:INFO:              optuna: Not installed
2024-05-30 17:38:59,395:INFO:               skopt: Not installed
2024-05-30 17:38:59,395:INFO:              mlflow: Not installed
2024-05-30 17:38:59,395:INFO:              gradio: Not installed
2024-05-30 17:38:59,395:INFO:             fastapi: Not installed
2024-05-30 17:38:59,396:INFO:             uvicorn: Not installed
2024-05-30 17:38:59,396:INFO:              m2cgen: Not installed
2024-05-30 17:38:59,396:INFO:           evidently: Not installed
2024-05-30 17:38:59,396:INFO:               fugue: Not installed
2024-05-30 17:38:59,396:INFO:           streamlit: Not installed
2024-05-30 17:38:59,396:INFO:             prophet: Not installed
2024-05-30 17:38:59,396:INFO:None
2024-05-30 17:38:59,396:INFO:Set up data.
2024-05-30 17:38:59,423:INFO:Set up folding strategy.
2024-05-30 17:40:29,898:INFO:PyCaret ClassificationExperiment
2024-05-30 17:40:29,899:INFO:Logging name: clf-default-name
2024-05-30 17:40:29,899:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-30 17:40:29,899:INFO:version 3.3.2
2024-05-30 17:40:29,899:INFO:Initializing setup()
2024-05-30 17:40:29,899:INFO:self.USI: 1568
2024-05-30 17:40:29,899:INFO:self._variable_keys: {'idx', 'USI', 'target_param', 'fold_shuffle_param', 'pipeline', 'gpu_n_jobs_param', 'memory', 'X', 'exp_id', '_ml_usecase', 'fold_groups_param', '_available_plots', 'y', 'y_train', 'X_train', 'fix_imbalance', 'exp_name_log', 'y_test', 'logging_param', 'X_test', 'gpu_param', 'seed', 'is_multiclass', 'data', 'n_jobs_param', 'html_param', 'fold_generator', 'log_plots_param'}
2024-05-30 17:40:29,899:INFO:Checking environment
2024-05-30 17:40:29,899:INFO:python_version: 3.10.0
2024-05-30 17:40:29,899:INFO:python_build: ('default', 'May 30 2024 16:31:14')
2024-05-30 17:40:29,899:INFO:machine: x86_64
2024-05-30 17:40:29,899:INFO:platform: Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31
2024-05-30 17:40:29,900:INFO:Memory: svmem(total=8181506048, available=4107558912, percent=49.8, used=3765903360, free=248332288, active=1041350656, inactive=6126985216, buffers=467283968, cached=3699986432, shared=131072, slab=607428608)
2024-05-30 17:40:29,900:INFO:Physical Core: 4
2024-05-30 17:40:29,900:INFO:Logical Core: 8
2024-05-30 17:40:29,900:INFO:Checking libraries
2024-05-30 17:40:29,900:INFO:System:
2024-05-30 17:40:29,901:INFO:    python: 3.10.0 (default, May 30 2024, 16:31:14) [GCC 9.3.0]
2024-05-30 17:40:29,901:INFO:executable: /home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/bin/python
2024-05-30 17:40:29,901:INFO:   machine: Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31
2024-05-30 17:40:29,901:INFO:PyCaret required dependencies:
2024-05-30 17:40:29,901:INFO:                 pip: 21.2.3
2024-05-30 17:40:29,901:INFO:          setuptools: 57.4.0
2024-05-30 17:40:29,901:INFO:             pycaret: 3.3.2
2024-05-30 17:40:29,901:INFO:             IPython: 8.24.0
2024-05-30 17:40:29,901:INFO:          ipywidgets: 8.1.3
2024-05-30 17:40:29,901:INFO:                tqdm: 4.66.4
2024-05-30 17:40:29,901:INFO:               numpy: 1.26.4
2024-05-30 17:40:29,901:INFO:              pandas: 2.1.4
2024-05-30 17:40:29,901:INFO:              jinja2: 3.1.4
2024-05-30 17:40:29,901:INFO:               scipy: 1.11.4
2024-05-30 17:40:29,901:INFO:              joblib: 1.3.2
2024-05-30 17:40:29,902:INFO:             sklearn: 1.4.2
2024-05-30 17:40:29,902:INFO:                pyod: 1.1.3
2024-05-30 17:40:29,902:INFO:            imblearn: 0.12.3
2024-05-30 17:40:29,902:INFO:   category_encoders: 2.6.3
2024-05-30 17:40:29,902:INFO:            lightgbm: 4.3.0
2024-05-30 17:40:29,902:INFO:               numba: 0.59.1
2024-05-30 17:40:29,902:INFO:            requests: 2.32.3
2024-05-30 17:40:29,902:INFO:          matplotlib: 3.7.5
2024-05-30 17:40:29,902:INFO:          scikitplot: 0.3.7
2024-05-30 17:40:29,902:INFO:         yellowbrick: 1.5
2024-05-30 17:40:29,902:INFO:              plotly: 5.22.0
2024-05-30 17:40:29,902:INFO:    plotly-resampler: Not installed
2024-05-30 17:40:29,902:INFO:             kaleido: 0.2.1
2024-05-30 17:40:29,902:INFO:           schemdraw: 0.15
2024-05-30 17:40:29,902:INFO:         statsmodels: 0.14.2
2024-05-30 17:40:29,902:INFO:              sktime: 0.26.0
2024-05-30 17:40:29,902:INFO:               tbats: 1.1.3
2024-05-30 17:40:29,902:INFO:            pmdarima: 2.0.4
2024-05-30 17:40:29,903:INFO:              psutil: 5.9.8
2024-05-30 17:40:29,903:INFO:          markupsafe: 2.1.5
2024-05-30 17:40:29,903:INFO:             pickle5: Not installed
2024-05-30 17:40:29,903:INFO:         cloudpickle: 3.0.0
2024-05-30 17:40:29,903:INFO:         deprecation: 2.1.0
2024-05-30 17:40:29,903:INFO:              xxhash: 3.4.1
2024-05-30 17:40:29,903:INFO:           wurlitzer: 3.1.0
2024-05-30 17:40:29,903:INFO:PyCaret optional dependencies:
2024-05-30 17:40:29,903:INFO:                shap: Not installed
2024-05-30 17:40:29,903:INFO:           interpret: Not installed
2024-05-30 17:40:29,903:INFO:                umap: Not installed
2024-05-30 17:40:29,903:INFO:     ydata_profiling: Not installed
2024-05-30 17:40:29,903:INFO:  explainerdashboard: Not installed
2024-05-30 17:40:29,903:INFO:             autoviz: Not installed
2024-05-30 17:40:29,903:INFO:           fairlearn: Not installed
2024-05-30 17:40:29,903:INFO:          deepchecks: Not installed
2024-05-30 17:40:29,903:INFO:             xgboost: Not installed
2024-05-30 17:40:29,903:INFO:            catboost: Not installed
2024-05-30 17:40:29,904:INFO:              kmodes: Not installed
2024-05-30 17:40:29,904:INFO:             mlxtend: Not installed
2024-05-30 17:40:29,904:INFO:       statsforecast: Not installed
2024-05-30 17:40:29,904:INFO:        tune_sklearn: Not installed
2024-05-30 17:40:29,904:INFO:                 ray: Not installed
2024-05-30 17:40:29,904:INFO:            hyperopt: Not installed
2024-05-30 17:40:29,904:INFO:              optuna: Not installed
2024-05-30 17:40:29,904:INFO:               skopt: Not installed
2024-05-30 17:40:29,904:INFO:              mlflow: Not installed
2024-05-30 17:40:29,904:INFO:              gradio: Not installed
2024-05-30 17:40:29,904:INFO:             fastapi: Not installed
2024-05-30 17:40:29,904:INFO:             uvicorn: Not installed
2024-05-30 17:40:29,904:INFO:              m2cgen: Not installed
2024-05-30 17:40:29,904:INFO:           evidently: Not installed
2024-05-30 17:40:29,904:INFO:               fugue: Not installed
2024-05-30 17:40:29,904:INFO:           streamlit: Not installed
2024-05-30 17:40:29,904:INFO:             prophet: Not installed
2024-05-30 17:40:29,904:INFO:None
2024-05-30 17:40:29,904:INFO:Set up data.
2024-05-30 17:40:29,938:INFO:Set up folding strategy.
2024-05-30 17:40:29,938:INFO:Set up train/test split.
2024-05-30 17:40:29,964:INFO:Set up index.
2024-05-30 17:40:29,964:INFO:Assigning column types.
2024-05-30 17:40:29,968:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-30 17:40:30,004:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-30 17:40:30,005:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-30 17:40:30,026:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:40:30,026:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:40:30,059:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-30 17:40:30,060:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-30 17:40:30,077:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:40:30,077:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:40:30,078:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-30 17:40:30,106:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-30 17:40:30,125:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:40:30,125:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:40:30,154:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-30 17:40:30,174:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:40:30,174:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:40:30,174:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-30 17:40:30,222:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:40:30,223:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:40:30,272:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:40:30,272:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:40:30,273:INFO:Preparing preprocessing pipeline...
2024-05-30 17:40:30,274:INFO:Set up label encoding.
2024-05-30 17:40:30,274:INFO:Set up simple imputation.
2024-05-30 17:40:30,276:INFO:Set up encoding of categorical features.
2024-05-30 17:40:30,396:INFO:Finished creating preprocessing pipeline.
2024-05-30 17:40:30,400:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='...
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['Text'],
                                    transformer=TargetEncoder(cols=['Text'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-05-30 17:40:30,400:INFO:Creating final display dataframe.
2024-05-30 17:40:30,667:INFO:Setup _display_container:                     Description  \
0                    Session id   
1                        Target   
2                   Target type   
3                Target mapping   
4           Original data shape   
5        Transformed data shape   
6   Transformed train set shape   
7    Transformed test set shape   
8          Categorical features   
9                    Preprocess   
10              Imputation type   
11           Numeric imputation   
12       Categorical imputation   
13     Maximum one-hot encoding   
14              Encoding method   
15               Fold Generator   
16                  Fold Number   
17                     CPU Jobs   
18                      Use GPU   
19               Log Experiment   
20              Experiment Name   
21                          USI   

                                                Value  
0                                                  43  
1                                             Emotion  
2                                          Multiclass  
3   anger: 0, fear: 1, joy: 2, love: 3, sadness: 4...  
4                                          (21459, 2)  
5                                          (21459, 2)  
6                                          (15021, 2)  
7                                           (6438, 2)  
8                                                   1  
9                                                True  
10                                             simple  
11                                               mean  
12                                               mode  
13                                                 25  
14                                               None  
15                                    StratifiedKFold  
16                                                  2  
17                                                 -1  
18                                              False  
19                                              False  
20                                   clf-default-name  
21                                               1568  
2024-05-30 17:40:30,738:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:40:30,739:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:40:30,802:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:40:30,802:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:40:30,804:INFO:setup() successfully completed in 0.91s...............
2024-05-30 17:40:30,805:INFO:Initializing compare_models()
2024-05-30 17:40:30,806:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f23c48344c0>, include=['lr', 'knn', 'qda', 'lda'], fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f23c48344c0>, 'include': ['lr', 'knn', 'qda', 'lda'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-05-30 17:40:30,806:INFO:Checking exceptions
2024-05-30 17:40:30,809:INFO:Preparing display monitor
2024-05-30 17:40:30,831:INFO:Initializing Logistic Regression
2024-05-30 17:40:30,831:INFO:Total runtime is 6.2783559163411456e-06 minutes
2024-05-30 17:40:30,836:INFO:SubProcess create_model() called ==================================
2024-05-30 17:40:30,836:INFO:Initializing create_model()
2024-05-30 17:40:30,836:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f23c48344c0>, estimator=lr, fold=StratifiedKFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f23c50c4100>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-30 17:40:30,836:INFO:Checking exceptions
2024-05-30 17:40:30,837:INFO:Importing libraries
2024-05-30 17:40:30,837:INFO:Copying training dataset
2024-05-30 17:40:30,841:INFO:Defining folds
2024-05-30 17:40:30,841:INFO:Declaring metric variables
2024-05-30 17:40:30,847:INFO:Importing untrained model
2024-05-30 17:40:30,852:INFO:Logistic Regression Imported successfully
2024-05-30 17:40:30,870:INFO:Starting cross validation
2024-05-30 17:40:30,873:INFO:Cross validating with StratifiedKFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2024-05-30 17:40:31,105:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:40:31,108:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:40:31,117:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:40:31,120:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:40:31,147:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:40:31,148:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:40:31,164:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:40:31,165:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:40:31,176:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:40:31,177:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:40:31,220:INFO:Calculating mean and std
2024-05-30 17:40:31,220:INFO:Creating metrics dataframe
2024-05-30 17:40:31,222:INFO:Uploading results into container
2024-05-30 17:40:31,222:INFO:Uploading model into container now
2024-05-30 17:40:31,223:INFO:_master_model_container: 1
2024-05-30 17:40:31,223:INFO:_display_container: 2
2024-05-30 17:40:31,223:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=43, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-30 17:40:31,223:INFO:create_model() successfully completed......................................
2024-05-30 17:40:31,376:INFO:SubProcess create_model() end ==================================
2024-05-30 17:40:31,376:INFO:Creating metrics dataframe
2024-05-30 17:40:31,384:INFO:Initializing K Neighbors Classifier
2024-05-30 17:40:31,385:INFO:Total runtime is 0.009228098392486573 minutes
2024-05-30 17:40:31,389:INFO:SubProcess create_model() called ==================================
2024-05-30 17:40:31,390:INFO:Initializing create_model()
2024-05-30 17:40:31,390:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f23c48344c0>, estimator=knn, fold=StratifiedKFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f23c50c4100>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-30 17:40:31,390:INFO:Checking exceptions
2024-05-30 17:40:31,390:INFO:Importing libraries
2024-05-30 17:40:31,390:INFO:Copying training dataset
2024-05-30 17:40:31,394:INFO:Defining folds
2024-05-30 17:40:31,394:INFO:Declaring metric variables
2024-05-30 17:40:31,398:INFO:Importing untrained model
2024-05-30 17:40:31,404:INFO:K Neighbors Classifier Imported successfully
2024-05-30 17:40:31,413:INFO:Starting cross validation
2024-05-30 17:40:31,414:INFO:Cross validating with StratifiedKFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2024-05-30 17:40:31,954:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:40:31,983:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:40:32,003:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:40:32,023:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:40:32,236:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:40:32,263:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:40:32,281:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:40:32,292:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:40:32,341:INFO:Calculating mean and std
2024-05-30 17:40:32,343:INFO:Creating metrics dataframe
2024-05-30 17:40:32,345:INFO:Uploading results into container
2024-05-30 17:40:32,345:INFO:Uploading model into container now
2024-05-30 17:40:32,346:INFO:_master_model_container: 2
2024-05-30 17:40:32,346:INFO:_display_container: 2
2024-05-30 17:40:32,346:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-05-30 17:40:32,346:INFO:create_model() successfully completed......................................
2024-05-30 17:40:32,449:INFO:SubProcess create_model() end ==================================
2024-05-30 17:40:32,449:INFO:Creating metrics dataframe
2024-05-30 17:40:32,457:INFO:Initializing Quadratic Discriminant Analysis
2024-05-30 17:40:32,458:INFO:Total runtime is 0.027107699712117517 minutes
2024-05-30 17:40:32,460:INFO:SubProcess create_model() called ==================================
2024-05-30 17:40:32,461:INFO:Initializing create_model()
2024-05-30 17:40:32,461:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f23c48344c0>, estimator=qda, fold=StratifiedKFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f23c50c4100>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-30 17:40:32,461:INFO:Checking exceptions
2024-05-30 17:40:32,461:INFO:Importing libraries
2024-05-30 17:40:32,461:INFO:Copying training dataset
2024-05-30 17:40:32,466:INFO:Defining folds
2024-05-30 17:40:32,466:INFO:Declaring metric variables
2024-05-30 17:40:32,471:INFO:Importing untrained model
2024-05-30 17:40:32,475:INFO:Quadratic Discriminant Analysis Imported successfully
2024-05-30 17:40:32,484:INFO:Starting cross validation
2024-05-30 17:40:32,486:INFO:Cross validating with StratifiedKFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2024-05-30 17:40:32,556:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-30 17:40:32,580:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:40:32,589:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:40:32,594:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:40:32,601:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:40:32,628:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:40:32,635:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:40:32,643:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:40:32,650:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:40:32,656:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:40:32,666:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:40:32,708:INFO:Calculating mean and std
2024-05-30 17:40:32,710:INFO:Creating metrics dataframe
2024-05-30 17:40:32,712:INFO:Uploading results into container
2024-05-30 17:40:32,712:INFO:Uploading model into container now
2024-05-30 17:40:32,713:INFO:_master_model_container: 3
2024-05-30 17:40:32,713:INFO:_display_container: 2
2024-05-30 17:40:32,714:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-05-30 17:40:32,714:INFO:create_model() successfully completed......................................
2024-05-30 17:40:32,815:INFO:SubProcess create_model() end ==================================
2024-05-30 17:40:32,815:INFO:Creating metrics dataframe
2024-05-30 17:40:32,822:INFO:Initializing Linear Discriminant Analysis
2024-05-30 17:40:32,822:INFO:Total runtime is 0.03317895730336508 minutes
2024-05-30 17:40:32,825:INFO:SubProcess create_model() called ==================================
2024-05-30 17:40:32,825:INFO:Initializing create_model()
2024-05-30 17:40:32,825:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f23c48344c0>, estimator=lda, fold=StratifiedKFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f23c50c4100>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-30 17:40:32,825:INFO:Checking exceptions
2024-05-30 17:40:32,825:INFO:Importing libraries
2024-05-30 17:40:32,825:INFO:Copying training dataset
2024-05-30 17:40:32,828:INFO:Defining folds
2024-05-30 17:40:32,828:INFO:Declaring metric variables
2024-05-30 17:40:32,832:INFO:Importing untrained model
2024-05-30 17:40:32,836:INFO:Linear Discriminant Analysis Imported successfully
2024-05-30 17:40:32,843:INFO:Starting cross validation
2024-05-30 17:40:32,846:INFO:Cross validating with StratifiedKFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2024-05-30 17:40:32,950:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:40:32,956:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:40:32,960:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:40:32,968:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:40:32,990:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:40:32,996:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:40:33,006:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:40:33,012:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:40:33,018:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:40:33,024:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:40:33,077:INFO:Calculating mean and std
2024-05-30 17:40:33,078:INFO:Creating metrics dataframe
2024-05-30 17:40:33,080:INFO:Uploading results into container
2024-05-30 17:40:33,081:INFO:Uploading model into container now
2024-05-30 17:40:33,082:INFO:_master_model_container: 4
2024-05-30 17:40:33,082:INFO:_display_container: 2
2024-05-30 17:40:33,083:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-05-30 17:40:33,083:INFO:create_model() successfully completed......................................
2024-05-30 17:40:33,189:INFO:SubProcess create_model() end ==================================
2024-05-30 17:40:33,190:INFO:Creating metrics dataframe
2024-05-30 17:40:33,197:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-30 17:40:33,206:INFO:Initializing create_model()
2024-05-30 17:40:33,207:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f23c48344c0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=43, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-30 17:40:33,207:INFO:Checking exceptions
2024-05-30 17:40:33,208:INFO:Importing libraries
2024-05-30 17:40:33,208:INFO:Copying training dataset
2024-05-30 17:40:33,212:INFO:Defining folds
2024-05-30 17:40:33,212:INFO:Declaring metric variables
2024-05-30 17:40:33,212:INFO:Importing untrained model
2024-05-30 17:40:33,212:INFO:Declaring custom model
2024-05-30 17:40:33,213:INFO:Logistic Regression Imported successfully
2024-05-30 17:40:33,215:INFO:Cross validation set to False
2024-05-30 17:40:33,215:INFO:Fitting Model
2024-05-30 17:40:33,896:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=43, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-30 17:40:33,897:INFO:create_model() successfully completed......................................
2024-05-30 17:40:34,074:INFO:_master_model_container: 4
2024-05-30 17:40:34,075:INFO:_display_container: 2
2024-05-30 17:40:34,075:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=43, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-30 17:40:34,075:INFO:compare_models() successfully completed......................................
2024-05-30 17:41:17,166:INFO:PyCaret ClassificationExperiment
2024-05-30 17:41:17,166:INFO:Logging name: clf-default-name
2024-05-30 17:41:17,166:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-30 17:41:17,166:INFO:version 3.3.2
2024-05-30 17:41:17,166:INFO:Initializing setup()
2024-05-30 17:41:17,166:INFO:self.USI: 69d8
2024-05-30 17:41:17,166:INFO:self._variable_keys: {'idx', 'USI', 'target_param', 'fold_shuffle_param', 'pipeline', 'gpu_n_jobs_param', 'memory', 'X', 'exp_id', '_ml_usecase', 'fold_groups_param', '_available_plots', 'y', 'y_train', 'X_train', 'fix_imbalance', 'exp_name_log', 'y_test', 'logging_param', 'X_test', 'gpu_param', 'seed', 'is_multiclass', 'data', 'n_jobs_param', 'html_param', 'fold_generator', 'log_plots_param'}
2024-05-30 17:41:17,166:INFO:Checking environment
2024-05-30 17:41:17,166:INFO:python_version: 3.10.0
2024-05-30 17:41:17,166:INFO:python_build: ('default', 'May 30 2024 16:31:14')
2024-05-30 17:41:17,166:INFO:machine: x86_64
2024-05-30 17:41:17,166:INFO:platform: Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31
2024-05-30 17:41:17,167:INFO:Memory: svmem(total=8181506048, available=4107870208, percent=49.8, used=3765583872, free=248475648, active=1042038784, inactive=6126182400, buffers=467374080, cached=3700072448, shared=131072, slab=607387648)
2024-05-30 17:41:17,167:INFO:Physical Core: 4
2024-05-30 17:41:17,167:INFO:Logical Core: 8
2024-05-30 17:41:17,167:INFO:Checking libraries
2024-05-30 17:41:17,167:INFO:System:
2024-05-30 17:41:17,167:INFO:    python: 3.10.0 (default, May 30 2024, 16:31:14) [GCC 9.3.0]
2024-05-30 17:41:17,167:INFO:executable: /home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/bin/python
2024-05-30 17:41:17,167:INFO:   machine: Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31
2024-05-30 17:41:17,167:INFO:PyCaret required dependencies:
2024-05-30 17:41:17,168:INFO:                 pip: 21.2.3
2024-05-30 17:41:17,168:INFO:          setuptools: 57.4.0
2024-05-30 17:41:17,168:INFO:             pycaret: 3.3.2
2024-05-30 17:41:17,168:INFO:             IPython: 8.24.0
2024-05-30 17:41:17,168:INFO:          ipywidgets: 8.1.3
2024-05-30 17:41:17,168:INFO:                tqdm: 4.66.4
2024-05-30 17:41:17,168:INFO:               numpy: 1.26.4
2024-05-30 17:41:17,168:INFO:              pandas: 2.1.4
2024-05-30 17:41:17,168:INFO:              jinja2: 3.1.4
2024-05-30 17:41:17,168:INFO:               scipy: 1.11.4
2024-05-30 17:41:17,168:INFO:              joblib: 1.3.2
2024-05-30 17:41:17,168:INFO:             sklearn: 1.4.2
2024-05-30 17:41:17,168:INFO:                pyod: 1.1.3
2024-05-30 17:41:17,168:INFO:            imblearn: 0.12.3
2024-05-30 17:41:17,168:INFO:   category_encoders: 2.6.3
2024-05-30 17:41:17,168:INFO:            lightgbm: 4.3.0
2024-05-30 17:41:17,168:INFO:               numba: 0.59.1
2024-05-30 17:41:17,168:INFO:            requests: 2.32.3
2024-05-30 17:41:17,168:INFO:          matplotlib: 3.7.5
2024-05-30 17:41:17,168:INFO:          scikitplot: 0.3.7
2024-05-30 17:41:17,169:INFO:         yellowbrick: 1.5
2024-05-30 17:41:17,169:INFO:              plotly: 5.22.0
2024-05-30 17:41:17,169:INFO:    plotly-resampler: Not installed
2024-05-30 17:41:17,169:INFO:             kaleido: 0.2.1
2024-05-30 17:41:17,169:INFO:           schemdraw: 0.15
2024-05-30 17:41:17,169:INFO:         statsmodels: 0.14.2
2024-05-30 17:41:17,169:INFO:              sktime: 0.26.0
2024-05-30 17:41:17,169:INFO:               tbats: 1.1.3
2024-05-30 17:41:17,169:INFO:            pmdarima: 2.0.4
2024-05-30 17:41:17,169:INFO:              psutil: 5.9.8
2024-05-30 17:41:17,169:INFO:          markupsafe: 2.1.5
2024-05-30 17:41:17,169:INFO:             pickle5: Not installed
2024-05-30 17:41:17,169:INFO:         cloudpickle: 3.0.0
2024-05-30 17:41:17,169:INFO:         deprecation: 2.1.0
2024-05-30 17:41:17,169:INFO:              xxhash: 3.4.1
2024-05-30 17:41:17,169:INFO:           wurlitzer: 3.1.0
2024-05-30 17:41:17,169:INFO:PyCaret optional dependencies:
2024-05-30 17:41:17,169:INFO:                shap: Not installed
2024-05-30 17:41:17,169:INFO:           interpret: Not installed
2024-05-30 17:41:17,169:INFO:                umap: Not installed
2024-05-30 17:41:17,169:INFO:     ydata_profiling: Not installed
2024-05-30 17:41:17,170:INFO:  explainerdashboard: Not installed
2024-05-30 17:41:17,170:INFO:             autoviz: Not installed
2024-05-30 17:41:17,170:INFO:           fairlearn: Not installed
2024-05-30 17:41:17,170:INFO:          deepchecks: Not installed
2024-05-30 17:41:17,170:INFO:             xgboost: Not installed
2024-05-30 17:41:17,170:INFO:            catboost: Not installed
2024-05-30 17:41:17,170:INFO:              kmodes: Not installed
2024-05-30 17:41:17,170:INFO:             mlxtend: Not installed
2024-05-30 17:41:17,170:INFO:       statsforecast: Not installed
2024-05-30 17:41:17,170:INFO:        tune_sklearn: Not installed
2024-05-30 17:41:17,170:INFO:                 ray: Not installed
2024-05-30 17:41:17,170:INFO:            hyperopt: Not installed
2024-05-30 17:41:17,170:INFO:              optuna: Not installed
2024-05-30 17:41:17,170:INFO:               skopt: Not installed
2024-05-30 17:41:17,170:INFO:              mlflow: Not installed
2024-05-30 17:41:17,170:INFO:              gradio: Not installed
2024-05-30 17:41:17,170:INFO:             fastapi: Not installed
2024-05-30 17:41:17,170:INFO:             uvicorn: Not installed
2024-05-30 17:41:17,170:INFO:              m2cgen: Not installed
2024-05-30 17:41:17,171:INFO:           evidently: Not installed
2024-05-30 17:41:17,171:INFO:               fugue: Not installed
2024-05-30 17:41:17,171:INFO:           streamlit: Not installed
2024-05-30 17:41:17,171:INFO:             prophet: Not installed
2024-05-30 17:41:17,171:INFO:None
2024-05-30 17:41:17,171:INFO:Set up data.
2024-05-30 17:41:17,205:INFO:Set up folding strategy.
2024-05-30 17:41:17,206:INFO:Set up train/test split.
2024-05-30 17:41:17,224:INFO:Set up index.
2024-05-30 17:41:17,225:INFO:Assigning column types.
2024-05-30 17:41:17,227:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-30 17:41:17,260:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-30 17:41:17,261:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-30 17:41:17,279:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:41:17,280:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:41:17,310:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-30 17:41:17,311:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-30 17:41:17,328:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:41:17,329:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:41:17,329:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-30 17:41:17,359:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-30 17:41:17,378:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:41:17,379:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:41:17,408:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-30 17:41:17,425:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:41:17,425:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:41:17,425:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-30 17:41:17,471:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:41:17,471:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:41:17,517:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:41:17,518:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:41:17,519:INFO:Preparing preprocessing pipeline...
2024-05-30 17:41:17,519:INFO:Set up label encoding.
2024-05-30 17:41:17,520:INFO:Set up simple imputation.
2024-05-30 17:41:17,521:INFO:Set up encoding of categorical features.
2024-05-30 17:41:17,664:INFO:Finished creating preprocessing pipeline.
2024-05-30 17:41:17,668:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='...
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['Text'],
                                    transformer=TargetEncoder(cols=['Text'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-05-30 17:41:17,668:INFO:Creating final display dataframe.
2024-05-30 17:41:17,920:INFO:Setup _display_container:                     Description  \
0                    Session id   
1                        Target   
2                   Target type   
3                Target mapping   
4           Original data shape   
5        Transformed data shape   
6   Transformed train set shape   
7    Transformed test set shape   
8          Categorical features   
9                    Preprocess   
10              Imputation type   
11           Numeric imputation   
12       Categorical imputation   
13     Maximum one-hot encoding   
14              Encoding method   
15               Fold Generator   
16                  Fold Number   
17                     CPU Jobs   
18                      Use GPU   
19               Log Experiment   
20              Experiment Name   
21                          USI   

                                                Value  
0                                                  43  
1                                             Emotion  
2                                          Multiclass  
3   anger: 0, fear: 1, joy: 2, love: 3, sadness: 4...  
4                                          (21459, 2)  
5                                          (21459, 2)  
6                                          (15021, 2)  
7                                           (6438, 2)  
8                                                   1  
9                                                True  
10                                             simple  
11                                               mean  
12                                               mode  
13                                                 25  
14                                               None  
15                                    StratifiedKFold  
16                                                  2  
17                                                 -1  
18                                              False  
19                                              False  
20                                   clf-default-name  
21                                               69d8  
2024-05-30 17:41:17,981:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:41:17,981:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:41:18,032:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:41:18,032:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:41:18,033:INFO:setup() successfully completed in 0.87s...............
2024-05-30 17:41:18,034:INFO:Initializing compare_models()
2024-05-30 17:41:18,034:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f23c66f53f0>, include=['lr', 'knn', 'qda', 'lda', 'lightgbm', 'nb', 'et', 'catboost', 'gbc', 'xgboost', 'dt', 'rf', 'ada', 'ridge', 'svm', 'dummy'], fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f23c66f53f0>, 'include': ['lr', 'knn', 'qda', 'lda', 'lightgbm', 'nb', 'et', 'catboost', 'gbc', 'xgboost', 'dt', 'rf', 'ada', 'ridge', 'svm', 'dummy'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-05-30 17:41:18,034:INFO:Checking exceptions
2024-05-30 17:42:26,087:INFO:gpu_param set to False
2024-05-30 17:42:26,148:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:42:26,149:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:42:26,197:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:42:26,197:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:42:37,569:INFO:gpu_param set to False
2024-05-30 17:42:37,627:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:42:37,627:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:42:37,676:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:42:37,676:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:42:44,189:INFO:gpu_param set to False
2024-05-30 17:42:44,362:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:42:44,363:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:42:44,587:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:42:44,587:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:42:49,631:INFO:gpu_param set to False
2024-05-30 17:42:49,721:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:42:49,721:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:42:49,788:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:42:49,789:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:19,382:INFO:PyCaret ClassificationExperiment
2024-05-30 17:43:19,382:INFO:Logging name: clf-default-name
2024-05-30 17:43:19,382:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-30 17:43:19,383:INFO:version 3.3.2
2024-05-30 17:43:19,383:INFO:Initializing setup()
2024-05-30 17:43:19,383:INFO:self.USI: 45ad
2024-05-30 17:43:19,383:INFO:self._variable_keys: {'idx', 'USI', 'target_param', 'fold_shuffle_param', 'pipeline', 'gpu_n_jobs_param', 'memory', 'X', 'exp_id', '_ml_usecase', 'fold_groups_param', '_available_plots', 'y', 'y_train', 'X_train', 'fix_imbalance', 'exp_name_log', 'y_test', 'logging_param', 'X_test', 'gpu_param', 'seed', 'is_multiclass', 'data', 'n_jobs_param', 'html_param', 'fold_generator', 'log_plots_param'}
2024-05-30 17:43:19,383:INFO:Checking environment
2024-05-30 17:43:19,383:INFO:python_version: 3.10.0
2024-05-30 17:43:19,383:INFO:python_build: ('default', 'May 30 2024 16:31:14')
2024-05-30 17:43:19,383:INFO:machine: x86_64
2024-05-30 17:43:19,383:INFO:platform: Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31
2024-05-30 17:43:19,383:INFO:Memory: svmem(total=8181506048, available=3977723904, percent=51.4, used=3895738368, free=118038528, active=1042956288, inactive=6255464448, buffers=467628032, cached=3700101120, shared=131072, slab=607404032)
2024-05-30 17:43:19,384:INFO:Physical Core: 4
2024-05-30 17:43:19,384:INFO:Logical Core: 8
2024-05-30 17:43:19,384:INFO:Checking libraries
2024-05-30 17:43:19,384:INFO:System:
2024-05-30 17:43:19,384:INFO:    python: 3.10.0 (default, May 30 2024, 16:31:14) [GCC 9.3.0]
2024-05-30 17:43:19,384:INFO:executable: /home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/bin/python
2024-05-30 17:43:19,384:INFO:   machine: Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31
2024-05-30 17:43:19,384:INFO:PyCaret required dependencies:
2024-05-30 17:43:19,384:INFO:                 pip: 21.2.3
2024-05-30 17:43:19,385:INFO:          setuptools: 57.4.0
2024-05-30 17:43:19,385:INFO:             pycaret: 3.3.2
2024-05-30 17:43:19,385:INFO:             IPython: 8.24.0
2024-05-30 17:43:19,385:INFO:          ipywidgets: 8.1.3
2024-05-30 17:43:19,385:INFO:                tqdm: 4.66.4
2024-05-30 17:43:19,385:INFO:               numpy: 1.26.4
2024-05-30 17:43:19,385:INFO:              pandas: 2.1.4
2024-05-30 17:43:19,385:INFO:              jinja2: 3.1.4
2024-05-30 17:43:19,385:INFO:               scipy: 1.11.4
2024-05-30 17:43:19,385:INFO:              joblib: 1.3.2
2024-05-30 17:43:19,385:INFO:             sklearn: 1.4.2
2024-05-30 17:43:19,385:INFO:                pyod: 1.1.3
2024-05-30 17:43:19,385:INFO:            imblearn: 0.12.3
2024-05-30 17:43:19,385:INFO:   category_encoders: 2.6.3
2024-05-30 17:43:19,385:INFO:            lightgbm: 4.3.0
2024-05-30 17:43:19,385:INFO:               numba: 0.59.1
2024-05-30 17:43:19,385:INFO:            requests: 2.32.3
2024-05-30 17:43:19,385:INFO:          matplotlib: 3.7.5
2024-05-30 17:43:19,386:INFO:          scikitplot: 0.3.7
2024-05-30 17:43:19,386:INFO:         yellowbrick: 1.5
2024-05-30 17:43:19,386:INFO:              plotly: 5.22.0
2024-05-30 17:43:19,386:INFO:    plotly-resampler: Not installed
2024-05-30 17:43:19,386:INFO:             kaleido: 0.2.1
2024-05-30 17:43:19,386:INFO:           schemdraw: 0.15
2024-05-30 17:43:19,386:INFO:         statsmodels: 0.14.2
2024-05-30 17:43:19,386:INFO:              sktime: 0.26.0
2024-05-30 17:43:19,386:INFO:               tbats: 1.1.3
2024-05-30 17:43:19,386:INFO:            pmdarima: 2.0.4
2024-05-30 17:43:19,386:INFO:              psutil: 5.9.8
2024-05-30 17:43:19,386:INFO:          markupsafe: 2.1.5
2024-05-30 17:43:19,386:INFO:             pickle5: Not installed
2024-05-30 17:43:19,386:INFO:         cloudpickle: 3.0.0
2024-05-30 17:43:19,386:INFO:         deprecation: 2.1.0
2024-05-30 17:43:19,386:INFO:              xxhash: 3.4.1
2024-05-30 17:43:19,387:INFO:           wurlitzer: 3.1.0
2024-05-30 17:43:19,387:INFO:PyCaret optional dependencies:
2024-05-30 17:43:19,387:INFO:                shap: Not installed
2024-05-30 17:43:19,387:INFO:           interpret: Not installed
2024-05-30 17:43:19,387:INFO:                umap: Not installed
2024-05-30 17:43:19,387:INFO:     ydata_profiling: Not installed
2024-05-30 17:43:19,387:INFO:  explainerdashboard: Not installed
2024-05-30 17:43:19,387:INFO:             autoviz: Not installed
2024-05-30 17:43:19,387:INFO:           fairlearn: Not installed
2024-05-30 17:43:19,387:INFO:          deepchecks: Not installed
2024-05-30 17:43:19,387:INFO:             xgboost: Not installed
2024-05-30 17:43:19,387:INFO:            catboost: Not installed
2024-05-30 17:43:19,387:INFO:              kmodes: Not installed
2024-05-30 17:43:19,387:INFO:             mlxtend: Not installed
2024-05-30 17:43:19,387:INFO:       statsforecast: Not installed
2024-05-30 17:43:19,387:INFO:        tune_sklearn: Not installed
2024-05-30 17:43:19,387:INFO:                 ray: Not installed
2024-05-30 17:43:19,387:INFO:            hyperopt: Not installed
2024-05-30 17:43:19,387:INFO:              optuna: Not installed
2024-05-30 17:43:19,388:INFO:               skopt: Not installed
2024-05-30 17:43:19,388:INFO:              mlflow: Not installed
2024-05-30 17:43:19,388:INFO:              gradio: Not installed
2024-05-30 17:43:19,388:INFO:             fastapi: Not installed
2024-05-30 17:43:19,388:INFO:             uvicorn: Not installed
2024-05-30 17:43:19,388:INFO:              m2cgen: Not installed
2024-05-30 17:43:19,388:INFO:           evidently: Not installed
2024-05-30 17:43:19,388:INFO:               fugue: Not installed
2024-05-30 17:43:19,388:INFO:           streamlit: Not installed
2024-05-30 17:43:19,388:INFO:             prophet: Not installed
2024-05-30 17:43:19,388:INFO:None
2024-05-30 17:43:19,388:INFO:Set up data.
2024-05-30 17:43:19,423:INFO:Set up folding strategy.
2024-05-30 17:43:19,423:INFO:Set up train/test split.
2024-05-30 17:43:19,486:INFO:Set up index.
2024-05-30 17:43:19,487:INFO:Assigning column types.
2024-05-30 17:43:19,489:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-30 17:43:19,532:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-30 17:43:19,533:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-30 17:43:19,556:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:19,556:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:19,594:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-30 17:43:19,595:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-30 17:43:19,615:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:19,615:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:19,616:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-30 17:43:19,648:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-30 17:43:19,668:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:19,668:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:19,699:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-30 17:43:19,717:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:19,717:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:19,718:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-30 17:43:19,764:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:19,765:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:19,814:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:19,815:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:19,816:INFO:Preparing preprocessing pipeline...
2024-05-30 17:43:19,816:INFO:Set up label encoding.
2024-05-30 17:43:19,816:INFO:Set up simple imputation.
2024-05-30 17:43:19,818:INFO:Set up encoding of categorical features.
2024-05-30 17:43:19,966:INFO:Finished creating preprocessing pipeline.
2024-05-30 17:43:19,970:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='...
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['Text'],
                                    transformer=TargetEncoder(cols=['Text'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-05-30 17:43:19,970:INFO:Creating final display dataframe.
2024-05-30 17:43:20,223:INFO:Setup _display_container:                     Description  \
0                    Session id   
1                        Target   
2                   Target type   
3                Target mapping   
4           Original data shape   
5        Transformed data shape   
6   Transformed train set shape   
7    Transformed test set shape   
8          Categorical features   
9                    Preprocess   
10              Imputation type   
11           Numeric imputation   
12       Categorical imputation   
13     Maximum one-hot encoding   
14              Encoding method   
15               Fold Generator   
16                  Fold Number   
17                     CPU Jobs   
18                      Use GPU   
19               Log Experiment   
20              Experiment Name   
21                          USI   

                                                Value  
0                                                  43  
1                                             Emotion  
2                                          Multiclass  
3   anger: 0, fear: 1, joy: 2, love: 3, sadness: 4...  
4                                          (21459, 2)  
5                                          (21459, 2)  
6                                          (15021, 2)  
7                                           (6438, 2)  
8                                                   1  
9                                                True  
10                                             simple  
11                                               mean  
12                                               mode  
13                                                 25  
14                                               None  
15                                    StratifiedKFold  
16                                                  2  
17                                                 -1  
18                                              False  
19                                              False  
20                                   clf-default-name  
21                                               45ad  
2024-05-30 17:43:20,285:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:20,285:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:20,335:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:20,336:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:20,337:INFO:setup() successfully completed in 0.96s...............
2024-05-30 17:43:20,337:INFO:gpu_param set to False
2024-05-30 17:43:20,385:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:20,386:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:20,433:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:20,434:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:20,438:INFO:Initializing compare_models()
2024-05-30 17:43:20,438:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2397d9abc0>, include=Index(['lr', 'knn', 'nb', 'dt', 'svm', 'rbfsvm', 'gpc', 'mlp', 'ridge', 'rf',
       'qda', 'ada', 'gbc', 'lda', 'et', 'lightgbm', 'dummy'],
      dtype='object', name='ID'), fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f2397d9abc0>, 'include': Index(['lr', 'knn', 'nb', 'dt', 'svm', 'rbfsvm', 'gpc', 'mlp', 'ridge', 'rf',
       'qda', 'ada', 'gbc', 'lda', 'et', 'lightgbm', 'dummy'],
      dtype='object', name='ID'), 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-05-30 17:43:20,438:INFO:Checking exceptions
2024-05-30 17:43:20,440:INFO:Preparing display monitor
2024-05-30 17:43:39,835:INFO:PyCaret ClassificationExperiment
2024-05-30 17:43:39,835:INFO:Logging name: clf-default-name
2024-05-30 17:43:39,835:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-30 17:43:39,835:INFO:version 3.3.2
2024-05-30 17:43:39,835:INFO:Initializing setup()
2024-05-30 17:43:39,836:INFO:self.USI: fe67
2024-05-30 17:43:39,836:INFO:self._variable_keys: {'idx', 'USI', 'target_param', 'fold_shuffle_param', 'pipeline', 'gpu_n_jobs_param', 'memory', 'X', 'exp_id', '_ml_usecase', 'fold_groups_param', '_available_plots', 'y', 'y_train', 'X_train', 'fix_imbalance', 'exp_name_log', 'y_test', 'logging_param', 'X_test', 'gpu_param', 'seed', 'is_multiclass', 'data', 'n_jobs_param', 'html_param', 'fold_generator', 'log_plots_param'}
2024-05-30 17:43:39,836:INFO:Checking environment
2024-05-30 17:43:39,836:INFO:python_version: 3.10.0
2024-05-30 17:43:39,836:INFO:python_build: ('default', 'May 30 2024 16:31:14')
2024-05-30 17:43:39,836:INFO:machine: x86_64
2024-05-30 17:43:39,836:INFO:platform: Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31
2024-05-30 17:43:39,836:INFO:Memory: svmem(total=8181506048, available=3979927552, percent=51.4, used=3893534720, free=177897472, active=1037496320, inactive=6208733184, buffers=467677184, cached=3642396672, shared=131072, slab=606011392)
2024-05-30 17:43:39,837:INFO:Physical Core: 4
2024-05-30 17:43:39,837:INFO:Logical Core: 8
2024-05-30 17:43:39,837:INFO:Checking libraries
2024-05-30 17:43:39,837:INFO:System:
2024-05-30 17:43:39,837:INFO:    python: 3.10.0 (default, May 30 2024, 16:31:14) [GCC 9.3.0]
2024-05-30 17:43:39,837:INFO:executable: /home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/bin/python
2024-05-30 17:43:39,838:INFO:   machine: Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31
2024-05-30 17:43:39,838:INFO:PyCaret required dependencies:
2024-05-30 17:43:39,838:INFO:                 pip: 21.2.3
2024-05-30 17:43:39,838:INFO:          setuptools: 57.4.0
2024-05-30 17:43:39,838:INFO:             pycaret: 3.3.2
2024-05-30 17:43:39,838:INFO:             IPython: 8.24.0
2024-05-30 17:43:39,838:INFO:          ipywidgets: 8.1.3
2024-05-30 17:43:39,838:INFO:                tqdm: 4.66.4
2024-05-30 17:43:39,838:INFO:               numpy: 1.26.4
2024-05-30 17:43:39,838:INFO:              pandas: 2.1.4
2024-05-30 17:43:39,838:INFO:              jinja2: 3.1.4
2024-05-30 17:43:39,838:INFO:               scipy: 1.11.4
2024-05-30 17:43:39,838:INFO:              joblib: 1.3.2
2024-05-30 17:43:39,838:INFO:             sklearn: 1.4.2
2024-05-30 17:43:39,838:INFO:                pyod: 1.1.3
2024-05-30 17:43:39,838:INFO:            imblearn: 0.12.3
2024-05-30 17:43:39,839:INFO:   category_encoders: 2.6.3
2024-05-30 17:43:39,839:INFO:            lightgbm: 4.3.0
2024-05-30 17:43:39,839:INFO:               numba: 0.59.1
2024-05-30 17:43:39,839:INFO:            requests: 2.32.3
2024-05-30 17:43:39,839:INFO:          matplotlib: 3.7.5
2024-05-30 17:43:39,839:INFO:          scikitplot: 0.3.7
2024-05-30 17:43:39,839:INFO:         yellowbrick: 1.5
2024-05-30 17:43:39,839:INFO:              plotly: 5.22.0
2024-05-30 17:43:39,839:INFO:    plotly-resampler: Not installed
2024-05-30 17:43:39,839:INFO:             kaleido: 0.2.1
2024-05-30 17:43:39,839:INFO:           schemdraw: 0.15
2024-05-30 17:43:39,839:INFO:         statsmodels: 0.14.2
2024-05-30 17:43:39,839:INFO:              sktime: 0.26.0
2024-05-30 17:43:39,839:INFO:               tbats: 1.1.3
2024-05-30 17:43:39,839:INFO:            pmdarima: 2.0.4
2024-05-30 17:43:39,839:INFO:              psutil: 5.9.8
2024-05-30 17:43:39,839:INFO:          markupsafe: 2.1.5
2024-05-30 17:43:39,839:INFO:             pickle5: Not installed
2024-05-30 17:43:39,839:INFO:         cloudpickle: 3.0.0
2024-05-30 17:43:39,839:INFO:         deprecation: 2.1.0
2024-05-30 17:43:39,839:INFO:              xxhash: 3.4.1
2024-05-30 17:43:39,839:INFO:           wurlitzer: 3.1.0
2024-05-30 17:43:39,839:INFO:PyCaret optional dependencies:
2024-05-30 17:43:39,840:INFO:                shap: Not installed
2024-05-30 17:43:39,840:INFO:           interpret: Not installed
2024-05-30 17:43:39,840:INFO:                umap: Not installed
2024-05-30 17:43:39,840:INFO:     ydata_profiling: Not installed
2024-05-30 17:43:39,840:INFO:  explainerdashboard: Not installed
2024-05-30 17:43:39,840:INFO:             autoviz: Not installed
2024-05-30 17:43:39,840:INFO:           fairlearn: Not installed
2024-05-30 17:43:39,840:INFO:          deepchecks: Not installed
2024-05-30 17:43:39,840:INFO:             xgboost: Not installed
2024-05-30 17:43:39,840:INFO:            catboost: Not installed
2024-05-30 17:43:39,840:INFO:              kmodes: Not installed
2024-05-30 17:43:39,840:INFO:             mlxtend: Not installed
2024-05-30 17:43:39,840:INFO:       statsforecast: Not installed
2024-05-30 17:43:39,840:INFO:        tune_sklearn: Not installed
2024-05-30 17:43:39,840:INFO:                 ray: Not installed
2024-05-30 17:43:39,841:INFO:            hyperopt: Not installed
2024-05-30 17:43:39,841:INFO:              optuna: Not installed
2024-05-30 17:43:39,841:INFO:               skopt: Not installed
2024-05-30 17:43:39,841:INFO:              mlflow: Not installed
2024-05-30 17:43:39,841:INFO:              gradio: Not installed
2024-05-30 17:43:39,841:INFO:             fastapi: Not installed
2024-05-30 17:43:39,841:INFO:             uvicorn: Not installed
2024-05-30 17:43:39,841:INFO:              m2cgen: Not installed
2024-05-30 17:43:39,841:INFO:           evidently: Not installed
2024-05-30 17:43:39,841:INFO:               fugue: Not installed
2024-05-30 17:43:39,841:INFO:           streamlit: Not installed
2024-05-30 17:43:39,841:INFO:             prophet: Not installed
2024-05-30 17:43:39,841:INFO:None
2024-05-30 17:43:39,841:INFO:Set up data.
2024-05-30 17:43:39,902:INFO:Set up folding strategy.
2024-05-30 17:43:39,902:INFO:Set up train/test split.
2024-05-30 17:43:39,950:INFO:Set up index.
2024-05-30 17:43:39,951:INFO:Assigning column types.
2024-05-30 17:43:39,954:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-30 17:43:39,992:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-30 17:43:39,993:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-30 17:43:40,012:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:40,013:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:40,044:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-30 17:43:40,045:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-30 17:43:40,064:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:40,064:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:40,064:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-30 17:43:40,094:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-30 17:43:40,113:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:40,113:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:40,147:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-30 17:43:40,168:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:40,168:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:40,169:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-30 17:43:40,220:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:40,220:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:40,269:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:40,269:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:40,270:INFO:Preparing preprocessing pipeline...
2024-05-30 17:43:40,271:INFO:Set up label encoding.
2024-05-30 17:43:40,271:INFO:Set up simple imputation.
2024-05-30 17:43:40,273:INFO:Set up encoding of categorical features.
2024-05-30 17:43:40,413:INFO:Finished creating preprocessing pipeline.
2024-05-30 17:43:40,419:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='...
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['Text'],
                                    transformer=TargetEncoder(cols=['Text'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-05-30 17:43:40,419:INFO:Creating final display dataframe.
2024-05-30 17:43:40,696:INFO:Setup _display_container:                     Description  \
0                    Session id   
1                        Target   
2                   Target type   
3                Target mapping   
4           Original data shape   
5        Transformed data shape   
6   Transformed train set shape   
7    Transformed test set shape   
8          Categorical features   
9                    Preprocess   
10              Imputation type   
11           Numeric imputation   
12       Categorical imputation   
13     Maximum one-hot encoding   
14              Encoding method   
15               Fold Generator   
16                  Fold Number   
17                     CPU Jobs   
18                      Use GPU   
19               Log Experiment   
20              Experiment Name   
21                          USI   

                                                Value  
0                                                  43  
1                                             Emotion  
2                                          Multiclass  
3   anger: 0, fear: 1, joy: 2, love: 3, sadness: 4...  
4                                          (21459, 2)  
5                                          (21459, 2)  
6                                          (15021, 2)  
7                                           (6438, 2)  
8                                                   1  
9                                                True  
10                                             simple  
11                                               mean  
12                                               mode  
13                                                 25  
14                                               None  
15                                    StratifiedKFold  
16                                                  2  
17                                                 -1  
18                                              False  
19                                              False  
20                                   clf-default-name  
21                                               fe67  
2024-05-30 17:43:40,758:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:40,758:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:40,808:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:40,808:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:40,809:INFO:setup() successfully completed in 0.98s...............
2024-05-30 17:43:40,809:INFO:gpu_param set to False
2024-05-30 17:43:40,858:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:40,858:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:40,904:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:40,905:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:40,907:INFO:Initializing compare_models()
2024-05-30 17:43:40,908:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2397c82ad0>, include=Index(['lr'], dtype='object', name='ID'), fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f2397c82ad0>, 'include': Index(['lr'], dtype='object', name='ID'), 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-05-30 17:43:40,908:INFO:Checking exceptions
2024-05-30 17:43:40,910:INFO:Preparing display monitor
2024-05-30 17:43:43,017:INFO:PyCaret ClassificationExperiment
2024-05-30 17:43:43,017:INFO:Logging name: clf-default-name
2024-05-30 17:43:43,017:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-30 17:43:43,017:INFO:version 3.3.2
2024-05-30 17:43:43,017:INFO:Initializing setup()
2024-05-30 17:43:43,017:INFO:self.USI: 19c0
2024-05-30 17:43:43,017:INFO:self._variable_keys: {'idx', 'USI', 'target_param', 'fold_shuffle_param', 'pipeline', 'gpu_n_jobs_param', 'memory', 'X', 'exp_id', '_ml_usecase', 'fold_groups_param', '_available_plots', 'y', 'y_train', 'X_train', 'fix_imbalance', 'exp_name_log', 'y_test', 'logging_param', 'X_test', 'gpu_param', 'seed', 'is_multiclass', 'data', 'n_jobs_param', 'html_param', 'fold_generator', 'log_plots_param'}
2024-05-30 17:43:43,018:INFO:Checking environment
2024-05-30 17:43:43,018:INFO:python_version: 3.10.0
2024-05-30 17:43:43,018:INFO:python_build: ('default', 'May 30 2024 16:31:14')
2024-05-30 17:43:43,018:INFO:machine: x86_64
2024-05-30 17:43:43,018:INFO:platform: Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31
2024-05-30 17:43:43,018:INFO:Memory: svmem(total=8181506048, available=4016463872, percent=50.9, used=3856998400, free=214401024, active=1037512704, inactive=6167855104, buffers=467693568, cached=3642413056, shared=131072, slab=606015488)
2024-05-30 17:43:43,018:INFO:Physical Core: 4
2024-05-30 17:43:43,018:INFO:Logical Core: 8
2024-05-30 17:43:43,018:INFO:Checking libraries
2024-05-30 17:43:43,018:INFO:System:
2024-05-30 17:43:43,019:INFO:    python: 3.10.0 (default, May 30 2024, 16:31:14) [GCC 9.3.0]
2024-05-30 17:43:43,019:INFO:executable: /home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/bin/python
2024-05-30 17:43:43,019:INFO:   machine: Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31
2024-05-30 17:43:43,019:INFO:PyCaret required dependencies:
2024-05-30 17:43:43,019:INFO:                 pip: 21.2.3
2024-05-30 17:43:43,019:INFO:          setuptools: 57.4.0
2024-05-30 17:43:43,019:INFO:             pycaret: 3.3.2
2024-05-30 17:43:43,019:INFO:             IPython: 8.24.0
2024-05-30 17:43:43,019:INFO:          ipywidgets: 8.1.3
2024-05-30 17:43:43,019:INFO:                tqdm: 4.66.4
2024-05-30 17:43:43,019:INFO:               numpy: 1.26.4
2024-05-30 17:43:43,019:INFO:              pandas: 2.1.4
2024-05-30 17:43:43,019:INFO:              jinja2: 3.1.4
2024-05-30 17:43:43,019:INFO:               scipy: 1.11.4
2024-05-30 17:43:43,019:INFO:              joblib: 1.3.2
2024-05-30 17:43:43,019:INFO:             sklearn: 1.4.2
2024-05-30 17:43:43,019:INFO:                pyod: 1.1.3
2024-05-30 17:43:43,019:INFO:            imblearn: 0.12.3
2024-05-30 17:43:43,020:INFO:   category_encoders: 2.6.3
2024-05-30 17:43:43,020:INFO:            lightgbm: 4.3.0
2024-05-30 17:43:43,020:INFO:               numba: 0.59.1
2024-05-30 17:43:43,020:INFO:            requests: 2.32.3
2024-05-30 17:43:43,020:INFO:          matplotlib: 3.7.5
2024-05-30 17:43:43,020:INFO:          scikitplot: 0.3.7
2024-05-30 17:43:43,020:INFO:         yellowbrick: 1.5
2024-05-30 17:43:43,020:INFO:              plotly: 5.22.0
2024-05-30 17:43:43,020:INFO:    plotly-resampler: Not installed
2024-05-30 17:43:43,020:INFO:             kaleido: 0.2.1
2024-05-30 17:43:43,020:INFO:           schemdraw: 0.15
2024-05-30 17:43:43,020:INFO:         statsmodels: 0.14.2
2024-05-30 17:43:43,020:INFO:              sktime: 0.26.0
2024-05-30 17:43:43,020:INFO:               tbats: 1.1.3
2024-05-30 17:43:43,020:INFO:            pmdarima: 2.0.4
2024-05-30 17:43:43,020:INFO:              psutil: 5.9.8
2024-05-30 17:43:43,020:INFO:          markupsafe: 2.1.5
2024-05-30 17:43:43,020:INFO:             pickle5: Not installed
2024-05-30 17:43:43,020:INFO:         cloudpickle: 3.0.0
2024-05-30 17:43:43,020:INFO:         deprecation: 2.1.0
2024-05-30 17:43:43,020:INFO:              xxhash: 3.4.1
2024-05-30 17:43:43,020:INFO:           wurlitzer: 3.1.0
2024-05-30 17:43:43,020:INFO:PyCaret optional dependencies:
2024-05-30 17:43:43,020:INFO:                shap: Not installed
2024-05-30 17:43:43,020:INFO:           interpret: Not installed
2024-05-30 17:43:43,020:INFO:                umap: Not installed
2024-05-30 17:43:43,020:INFO:     ydata_profiling: Not installed
2024-05-30 17:43:43,020:INFO:  explainerdashboard: Not installed
2024-05-30 17:43:43,020:INFO:             autoviz: Not installed
2024-05-30 17:43:43,020:INFO:           fairlearn: Not installed
2024-05-30 17:43:43,020:INFO:          deepchecks: Not installed
2024-05-30 17:43:43,020:INFO:             xgboost: Not installed
2024-05-30 17:43:43,020:INFO:            catboost: Not installed
2024-05-30 17:43:43,020:INFO:              kmodes: Not installed
2024-05-30 17:43:43,020:INFO:             mlxtend: Not installed
2024-05-30 17:43:43,020:INFO:       statsforecast: Not installed
2024-05-30 17:43:43,020:INFO:        tune_sklearn: Not installed
2024-05-30 17:43:43,020:INFO:                 ray: Not installed
2024-05-30 17:43:43,020:INFO:            hyperopt: Not installed
2024-05-30 17:43:43,020:INFO:              optuna: Not installed
2024-05-30 17:43:43,020:INFO:               skopt: Not installed
2024-05-30 17:43:43,020:INFO:              mlflow: Not installed
2024-05-30 17:43:43,020:INFO:              gradio: Not installed
2024-05-30 17:43:43,020:INFO:             fastapi: Not installed
2024-05-30 17:43:43,020:INFO:             uvicorn: Not installed
2024-05-30 17:43:43,020:INFO:              m2cgen: Not installed
2024-05-30 17:43:43,020:INFO:           evidently: Not installed
2024-05-30 17:43:43,020:INFO:               fugue: Not installed
2024-05-30 17:43:43,021:INFO:           streamlit: Not installed
2024-05-30 17:43:43,021:INFO:             prophet: Not installed
2024-05-30 17:43:43,021:INFO:None
2024-05-30 17:43:43,021:INFO:Set up data.
2024-05-30 17:43:43,064:INFO:Set up folding strategy.
2024-05-30 17:43:43,065:INFO:Set up train/test split.
2024-05-30 17:43:43,091:INFO:Set up index.
2024-05-30 17:43:43,092:INFO:Assigning column types.
2024-05-30 17:43:43,094:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-30 17:43:43,129:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-30 17:43:43,130:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-30 17:43:43,152:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:43,152:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:43,201:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-30 17:43:43,203:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-30 17:43:43,230:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:43,231:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:43,232:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-30 17:43:43,288:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-30 17:43:43,327:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:43,328:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:43,383:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-30 17:43:43,404:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:43,404:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:43,404:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-30 17:43:43,460:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:43,460:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:43,511:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:43,512:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:43,512:INFO:Preparing preprocessing pipeline...
2024-05-30 17:43:43,513:INFO:Set up label encoding.
2024-05-30 17:43:43,513:INFO:Set up simple imputation.
2024-05-30 17:43:43,516:INFO:Set up encoding of categorical features.
2024-05-30 17:43:43,663:INFO:Finished creating preprocessing pipeline.
2024-05-30 17:43:43,667:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='...
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['Text'],
                                    transformer=TargetEncoder(cols=['Text'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-05-30 17:43:43,667:INFO:Creating final display dataframe.
2024-05-30 17:43:43,929:INFO:Setup _display_container:                     Description  \
0                    Session id   
1                        Target   
2                   Target type   
3                Target mapping   
4           Original data shape   
5        Transformed data shape   
6   Transformed train set shape   
7    Transformed test set shape   
8          Categorical features   
9                    Preprocess   
10              Imputation type   
11           Numeric imputation   
12       Categorical imputation   
13     Maximum one-hot encoding   
14              Encoding method   
15               Fold Generator   
16                  Fold Number   
17                     CPU Jobs   
18                      Use GPU   
19               Log Experiment   
20              Experiment Name   
21                          USI   

                                                Value  
0                                                  43  
1                                             Emotion  
2                                          Multiclass  
3   anger: 0, fear: 1, joy: 2, love: 3, sadness: 4...  
4                                          (21459, 2)  
5                                          (21459, 2)  
6                                          (15021, 2)  
7                                           (6438, 2)  
8                                                   1  
9                                                True  
10                                             simple  
11                                               mean  
12                                               mode  
13                                                 25  
14                                               None  
15                                    StratifiedKFold  
16                                                  2  
17                                                 -1  
18                                              False  
19                                              False  
20                                   clf-default-name  
21                                               19c0  
2024-05-30 17:43:43,989:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:43,990:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:44,061:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:44,061:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:44,062:INFO:setup() successfully completed in 1.05s...............
2024-05-30 17:43:44,063:INFO:gpu_param set to False
2024-05-30 17:43:44,112:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:44,113:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:44,161:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:44,162:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:44,163:INFO:Initializing compare_models()
2024-05-30 17:43:44,163:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f236bf9c190>, include=lr, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f236bf9c190>, 'include': 'lr', 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-05-30 17:43:44,163:INFO:Checking exceptions
2024-05-30 17:43:53,487:INFO:gpu_param set to False
2024-05-30 17:43:53,554:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:53,554:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:53,614:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:43:53,615:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:44:01,108:INFO:PyCaret ClassificationExperiment
2024-05-30 17:44:01,109:INFO:Logging name: clf-default-name
2024-05-30 17:44:01,109:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-30 17:44:01,109:INFO:version 3.3.2
2024-05-30 17:44:01,109:INFO:Initializing setup()
2024-05-30 17:44:01,109:INFO:self.USI: 3ea3
2024-05-30 17:44:01,109:INFO:self._variable_keys: {'idx', 'USI', 'target_param', 'fold_shuffle_param', 'pipeline', 'gpu_n_jobs_param', 'memory', 'X', 'exp_id', '_ml_usecase', 'fold_groups_param', '_available_plots', 'y', 'y_train', 'X_train', 'fix_imbalance', 'exp_name_log', 'y_test', 'logging_param', 'X_test', 'gpu_param', 'seed', 'is_multiclass', 'data', 'n_jobs_param', 'html_param', 'fold_generator', 'log_plots_param'}
2024-05-30 17:44:01,109:INFO:Checking environment
2024-05-30 17:44:01,109:INFO:python_version: 3.10.0
2024-05-30 17:44:01,109:INFO:python_build: ('default', 'May 30 2024 16:31:14')
2024-05-30 17:44:01,109:INFO:machine: x86_64
2024-05-30 17:44:01,109:INFO:platform: Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31
2024-05-30 17:44:01,109:INFO:Memory: svmem(total=8181506048, available=4002615296, percent=51.1, used=3870846976, free=200450048, active=1037561856, inactive=6183665664, buffers=467734528, cached=3642474496, shared=131072, slab=606035968)
2024-05-30 17:44:01,110:INFO:Physical Core: 4
2024-05-30 17:44:01,111:INFO:Logical Core: 8
2024-05-30 17:44:01,111:INFO:Checking libraries
2024-05-30 17:44:01,111:INFO:System:
2024-05-30 17:44:01,112:INFO:    python: 3.10.0 (default, May 30 2024, 16:31:14) [GCC 9.3.0]
2024-05-30 17:44:01,112:INFO:executable: /home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/bin/python
2024-05-30 17:44:01,112:INFO:   machine: Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31
2024-05-30 17:44:01,112:INFO:PyCaret required dependencies:
2024-05-30 17:44:01,112:INFO:                 pip: 21.2.3
2024-05-30 17:44:01,112:INFO:          setuptools: 57.4.0
2024-05-30 17:44:01,112:INFO:             pycaret: 3.3.2
2024-05-30 17:44:01,112:INFO:             IPython: 8.24.0
2024-05-30 17:44:01,112:INFO:          ipywidgets: 8.1.3
2024-05-30 17:44:01,112:INFO:                tqdm: 4.66.4
2024-05-30 17:44:01,112:INFO:               numpy: 1.26.4
2024-05-30 17:44:01,112:INFO:              pandas: 2.1.4
2024-05-30 17:44:01,112:INFO:              jinja2: 3.1.4
2024-05-30 17:44:01,112:INFO:               scipy: 1.11.4
2024-05-30 17:44:01,112:INFO:              joblib: 1.3.2
2024-05-30 17:44:01,112:INFO:             sklearn: 1.4.2
2024-05-30 17:44:01,112:INFO:                pyod: 1.1.3
2024-05-30 17:44:01,112:INFO:            imblearn: 0.12.3
2024-05-30 17:44:01,112:INFO:   category_encoders: 2.6.3
2024-05-30 17:44:01,112:INFO:            lightgbm: 4.3.0
2024-05-30 17:44:01,112:INFO:               numba: 0.59.1
2024-05-30 17:44:01,112:INFO:            requests: 2.32.3
2024-05-30 17:44:01,112:INFO:          matplotlib: 3.7.5
2024-05-30 17:44:01,112:INFO:          scikitplot: 0.3.7
2024-05-30 17:44:01,112:INFO:         yellowbrick: 1.5
2024-05-30 17:44:01,112:INFO:              plotly: 5.22.0
2024-05-30 17:44:01,112:INFO:    plotly-resampler: Not installed
2024-05-30 17:44:01,112:INFO:             kaleido: 0.2.1
2024-05-30 17:44:01,112:INFO:           schemdraw: 0.15
2024-05-30 17:44:01,112:INFO:         statsmodels: 0.14.2
2024-05-30 17:44:01,112:INFO:              sktime: 0.26.0
2024-05-30 17:44:01,112:INFO:               tbats: 1.1.3
2024-05-30 17:44:01,112:INFO:            pmdarima: 2.0.4
2024-05-30 17:44:01,112:INFO:              psutil: 5.9.8
2024-05-30 17:44:01,113:INFO:          markupsafe: 2.1.5
2024-05-30 17:44:01,113:INFO:             pickle5: Not installed
2024-05-30 17:44:01,113:INFO:         cloudpickle: 3.0.0
2024-05-30 17:44:01,113:INFO:         deprecation: 2.1.0
2024-05-30 17:44:01,113:INFO:              xxhash: 3.4.1
2024-05-30 17:44:01,113:INFO:           wurlitzer: 3.1.0
2024-05-30 17:44:01,113:INFO:PyCaret optional dependencies:
2024-05-30 17:44:01,113:INFO:                shap: Not installed
2024-05-30 17:44:01,113:INFO:           interpret: Not installed
2024-05-30 17:44:01,113:INFO:                umap: Not installed
2024-05-30 17:44:01,113:INFO:     ydata_profiling: Not installed
2024-05-30 17:44:01,113:INFO:  explainerdashboard: Not installed
2024-05-30 17:44:01,113:INFO:             autoviz: Not installed
2024-05-30 17:44:01,113:INFO:           fairlearn: Not installed
2024-05-30 17:44:01,113:INFO:          deepchecks: Not installed
2024-05-30 17:44:01,113:INFO:             xgboost: Not installed
2024-05-30 17:44:01,113:INFO:            catboost: Not installed
2024-05-30 17:44:01,113:INFO:              kmodes: Not installed
2024-05-30 17:44:01,113:INFO:             mlxtend: Not installed
2024-05-30 17:44:01,113:INFO:       statsforecast: Not installed
2024-05-30 17:44:01,113:INFO:        tune_sklearn: Not installed
2024-05-30 17:44:01,113:INFO:                 ray: Not installed
2024-05-30 17:44:01,113:INFO:            hyperopt: Not installed
2024-05-30 17:44:01,113:INFO:              optuna: Not installed
2024-05-30 17:44:01,113:INFO:               skopt: Not installed
2024-05-30 17:44:01,113:INFO:              mlflow: Not installed
2024-05-30 17:44:01,113:INFO:              gradio: Not installed
2024-05-30 17:44:01,113:INFO:             fastapi: Not installed
2024-05-30 17:44:01,113:INFO:             uvicorn: Not installed
2024-05-30 17:44:01,113:INFO:              m2cgen: Not installed
2024-05-30 17:44:01,113:INFO:           evidently: Not installed
2024-05-30 17:44:01,113:INFO:               fugue: Not installed
2024-05-30 17:44:01,113:INFO:           streamlit: Not installed
2024-05-30 17:44:01,113:INFO:             prophet: Not installed
2024-05-30 17:44:01,114:INFO:None
2024-05-30 17:44:01,114:INFO:Set up data.
2024-05-30 17:44:01,161:INFO:Set up folding strategy.
2024-05-30 17:44:01,162:INFO:Set up train/test split.
2024-05-30 17:44:01,187:INFO:Set up index.
2024-05-30 17:44:01,187:INFO:Assigning column types.
2024-05-30 17:44:01,190:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-30 17:44:01,231:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-30 17:44:01,232:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-30 17:44:01,253:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:44:01,253:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:44:01,286:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-30 17:44:01,287:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-30 17:44:01,306:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:44:01,306:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:44:01,306:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-30 17:44:01,337:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-30 17:44:01,355:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:44:01,355:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:44:01,384:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-30 17:44:01,404:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:44:01,404:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:44:01,404:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-30 17:44:01,458:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:44:01,458:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:44:01,532:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:44:01,532:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:44:01,533:INFO:Preparing preprocessing pipeline...
2024-05-30 17:44:01,534:INFO:Set up label encoding.
2024-05-30 17:44:01,534:INFO:Set up simple imputation.
2024-05-30 17:44:01,537:INFO:Set up encoding of categorical features.
2024-05-30 17:44:01,714:INFO:Finished creating preprocessing pipeline.
2024-05-30 17:44:01,718:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='...
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['Text'],
                                    transformer=TargetEncoder(cols=['Text'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-05-30 17:44:01,718:INFO:Creating final display dataframe.
2024-05-30 17:44:02,015:INFO:Setup _display_container:                     Description  \
0                    Session id   
1                        Target   
2                   Target type   
3                Target mapping   
4           Original data shape   
5        Transformed data shape   
6   Transformed train set shape   
7    Transformed test set shape   
8          Categorical features   
9                    Preprocess   
10              Imputation type   
11           Numeric imputation   
12       Categorical imputation   
13     Maximum one-hot encoding   
14              Encoding method   
15               Fold Generator   
16                  Fold Number   
17                     CPU Jobs   
18                      Use GPU   
19               Log Experiment   
20              Experiment Name   
21                          USI   

                                                Value  
0                                                  43  
1                                             Emotion  
2                                          Multiclass  
3   anger: 0, fear: 1, joy: 2, love: 3, sadness: 4...  
4                                          (21459, 2)  
5                                          (21459, 2)  
6                                          (15021, 2)  
7                                           (6438, 2)  
8                                                   1  
9                                                True  
10                                             simple  
11                                               mean  
12                                               mode  
13                                                 25  
14                                               None  
15                                    StratifiedKFold  
16                                                  2  
17                                                 -1  
18                                              False  
19                                              False  
20                                   clf-default-name  
21                                               3ea3  
2024-05-30 17:44:02,078:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:44:02,078:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:44:02,141:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:44:02,142:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:44:02,143:INFO:setup() successfully completed in 1.04s...............
2024-05-30 17:44:02,143:INFO:Initializing compare_models()
2024-05-30 17:44:02,144:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2397618820>, include=['lr'], fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f2397618820>, 'include': ['lr'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-05-30 17:44:02,144:INFO:Checking exceptions
2024-05-30 17:44:02,147:INFO:Preparing display monitor
2024-05-30 17:44:02,169:INFO:Initializing Logistic Regression
2024-05-30 17:44:02,169:INFO:Total runtime is 3.4054120381673177e-06 minutes
2024-05-30 17:44:02,172:INFO:SubProcess create_model() called ==================================
2024-05-30 17:44:02,173:INFO:Initializing create_model()
2024-05-30 17:44:02,173:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2397618820>, estimator=lr, fold=StratifiedKFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f23979f71f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-30 17:44:02,173:INFO:Checking exceptions
2024-05-30 17:44:02,173:INFO:Importing libraries
2024-05-30 17:44:02,173:INFO:Copying training dataset
2024-05-30 17:44:02,178:INFO:Defining folds
2024-05-30 17:44:02,179:INFO:Declaring metric variables
2024-05-30 17:44:02,183:INFO:Importing untrained model
2024-05-30 17:44:02,188:INFO:Logistic Regression Imported successfully
2024-05-30 17:44:02,196:INFO:Starting cross validation
2024-05-30 17:44:02,198:INFO:Cross validating with StratifiedKFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2024-05-30 17:44:02,374:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:44:02,383:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:44:02,384:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:44:02,394:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:44:02,413:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:44:02,423:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:44:02,428:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:44:02,439:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:44:02,439:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:44:02,449:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:44:02,485:INFO:Calculating mean and std
2024-05-30 17:44:02,485:INFO:Creating metrics dataframe
2024-05-30 17:44:02,487:INFO:Uploading results into container
2024-05-30 17:44:02,488:INFO:Uploading model into container now
2024-05-30 17:44:02,488:INFO:_master_model_container: 1
2024-05-30 17:44:02,488:INFO:_display_container: 2
2024-05-30 17:44:02,489:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=43, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-30 17:44:02,489:INFO:create_model() successfully completed......................................
2024-05-30 17:44:02,635:INFO:SubProcess create_model() end ==================================
2024-05-30 17:44:02,635:INFO:Creating metrics dataframe
2024-05-30 17:44:02,641:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-30 17:44:02,652:INFO:Initializing create_model()
2024-05-30 17:44:02,653:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2397618820>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=43, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-30 17:44:02,653:INFO:Checking exceptions
2024-05-30 17:44:02,655:INFO:Importing libraries
2024-05-30 17:44:02,655:INFO:Copying training dataset
2024-05-30 17:44:02,659:INFO:Defining folds
2024-05-30 17:44:02,660:INFO:Declaring metric variables
2024-05-30 17:44:02,660:INFO:Importing untrained model
2024-05-30 17:44:02,660:INFO:Declaring custom model
2024-05-30 17:44:02,661:INFO:Logistic Regression Imported successfully
2024-05-30 17:44:02,663:INFO:Cross validation set to False
2024-05-30 17:44:02,663:INFO:Fitting Model
2024-05-30 17:44:03,168:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=43, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-30 17:44:03,169:INFO:create_model() successfully completed......................................
2024-05-30 17:44:03,361:INFO:_master_model_container: 1
2024-05-30 17:44:03,362:INFO:_display_container: 2
2024-05-30 17:44:03,362:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=43, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-30 17:44:03,363:INFO:compare_models() successfully completed......................................
2024-05-30 17:44:14,789:INFO:gpu_param set to False
2024-05-30 17:44:14,849:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:44:14,849:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:44:14,906:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:44:14,906:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:44:20,403:INFO:gpu_param set to False
2024-05-30 17:44:20,468:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:44:20,469:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:44:20,517:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:44:20,517:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:44:24,539:INFO:gpu_param set to False
2024-05-30 17:44:24,614:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:44:24,614:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:44:24,682:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:44:24,682:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:44:36,554:INFO:gpu_param set to False
2024-05-30 17:44:36,642:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:44:36,643:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:44:36,700:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:44:36,701:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:44:40,479:INFO:gpu_param set to False
2024-05-30 17:44:40,544:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:44:40,544:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:44:40,607:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:44:40,607:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:44:45,320:INFO:gpu_param set to False
2024-05-30 17:44:45,391:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:44:45,392:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:44:45,457:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:44:45,458:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:44:50,739:INFO:gpu_param set to False
2024-05-30 17:44:50,806:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:44:50,807:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:44:50,868:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:44:50,868:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:44:58,768:INFO:gpu_param set to False
2024-05-30 17:44:58,828:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:44:58,829:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:44:58,884:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:44:58,885:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:45:05,933:INFO:PyCaret ClassificationExperiment
2024-05-30 17:45:05,933:INFO:Logging name: clf-default-name
2024-05-30 17:45:05,933:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-30 17:45:05,933:INFO:version 3.3.2
2024-05-30 17:45:05,933:INFO:Initializing setup()
2024-05-30 17:45:05,933:INFO:self.USI: 698a
2024-05-30 17:45:05,934:INFO:self._variable_keys: {'idx', 'USI', 'target_param', 'fold_shuffle_param', 'pipeline', 'gpu_n_jobs_param', 'memory', 'X', 'exp_id', '_ml_usecase', 'fold_groups_param', '_available_plots', 'y', 'y_train', 'X_train', 'fix_imbalance', 'exp_name_log', 'y_test', 'logging_param', 'X_test', 'gpu_param', 'seed', 'is_multiclass', 'data', 'n_jobs_param', 'html_param', 'fold_generator', 'log_plots_param'}
2024-05-30 17:45:05,934:INFO:Checking environment
2024-05-30 17:45:05,934:INFO:python_version: 3.10.0
2024-05-30 17:45:05,934:INFO:python_build: ('default', 'May 30 2024 16:31:14')
2024-05-30 17:45:05,934:INFO:machine: x86_64
2024-05-30 17:45:05,934:INFO:platform: Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31
2024-05-30 17:45:05,934:INFO:Memory: svmem(total=8181506048, available=3707199488, percent=54.7, used=4166262784, free=120004608, active=1037742080, inactive=6258786304, buffers=467906560, cached=3427332096, shared=131072, slab=601870336)
2024-05-30 17:45:05,935:INFO:Physical Core: 4
2024-05-30 17:45:05,935:INFO:Logical Core: 8
2024-05-30 17:45:05,935:INFO:Checking libraries
2024-05-30 17:45:05,935:INFO:System:
2024-05-30 17:45:05,935:INFO:    python: 3.10.0 (default, May 30 2024, 16:31:14) [GCC 9.3.0]
2024-05-30 17:45:05,935:INFO:executable: /home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/bin/python
2024-05-30 17:45:05,935:INFO:   machine: Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31
2024-05-30 17:45:05,935:INFO:PyCaret required dependencies:
2024-05-30 17:45:05,935:INFO:                 pip: 21.2.3
2024-05-30 17:45:05,935:INFO:          setuptools: 57.4.0
2024-05-30 17:45:05,935:INFO:             pycaret: 3.3.2
2024-05-30 17:45:05,936:INFO:             IPython: 8.24.0
2024-05-30 17:45:05,936:INFO:          ipywidgets: 8.1.3
2024-05-30 17:45:05,936:INFO:                tqdm: 4.66.4
2024-05-30 17:45:05,936:INFO:               numpy: 1.26.4
2024-05-30 17:45:05,936:INFO:              pandas: 2.1.4
2024-05-30 17:45:05,936:INFO:              jinja2: 3.1.4
2024-05-30 17:45:05,936:INFO:               scipy: 1.11.4
2024-05-30 17:45:05,936:INFO:              joblib: 1.3.2
2024-05-30 17:45:05,936:INFO:             sklearn: 1.4.2
2024-05-30 17:45:05,936:INFO:                pyod: 1.1.3
2024-05-30 17:45:05,936:INFO:            imblearn: 0.12.3
2024-05-30 17:45:05,936:INFO:   category_encoders: 2.6.3
2024-05-30 17:45:05,936:INFO:            lightgbm: 4.3.0
2024-05-30 17:45:05,936:INFO:               numba: 0.59.1
2024-05-30 17:45:05,936:INFO:            requests: 2.32.3
2024-05-30 17:45:05,937:INFO:          matplotlib: 3.7.5
2024-05-30 17:45:05,937:INFO:          scikitplot: 0.3.7
2024-05-30 17:45:05,937:INFO:         yellowbrick: 1.5
2024-05-30 17:45:05,938:INFO:              plotly: 5.22.0
2024-05-30 17:45:05,938:INFO:    plotly-resampler: Not installed
2024-05-30 17:45:05,938:INFO:             kaleido: 0.2.1
2024-05-30 17:45:05,938:INFO:           schemdraw: 0.15
2024-05-30 17:45:05,938:INFO:         statsmodels: 0.14.2
2024-05-30 17:45:05,938:INFO:              sktime: 0.26.0
2024-05-30 17:45:05,938:INFO:               tbats: 1.1.3
2024-05-30 17:45:05,938:INFO:            pmdarima: 2.0.4
2024-05-30 17:45:05,938:INFO:              psutil: 5.9.8
2024-05-30 17:45:05,938:INFO:          markupsafe: 2.1.5
2024-05-30 17:45:05,938:INFO:             pickle5: Not installed
2024-05-30 17:45:05,938:INFO:         cloudpickle: 3.0.0
2024-05-30 17:45:05,939:INFO:         deprecation: 2.1.0
2024-05-30 17:45:05,940:INFO:              xxhash: 3.4.1
2024-05-30 17:45:05,941:INFO:           wurlitzer: 3.1.0
2024-05-30 17:45:05,941:INFO:PyCaret optional dependencies:
2024-05-30 17:45:05,941:INFO:                shap: Not installed
2024-05-30 17:45:05,941:INFO:           interpret: Not installed
2024-05-30 17:45:05,941:INFO:                umap: Not installed
2024-05-30 17:45:05,941:INFO:     ydata_profiling: Not installed
2024-05-30 17:45:05,941:INFO:  explainerdashboard: Not installed
2024-05-30 17:45:05,941:INFO:             autoviz: Not installed
2024-05-30 17:45:05,941:INFO:           fairlearn: Not installed
2024-05-30 17:45:05,941:INFO:          deepchecks: Not installed
2024-05-30 17:45:05,941:INFO:             xgboost: Not installed
2024-05-30 17:45:05,941:INFO:            catboost: Not installed
2024-05-30 17:45:05,942:INFO:              kmodes: Not installed
2024-05-30 17:45:05,942:INFO:             mlxtend: Not installed
2024-05-30 17:45:05,942:INFO:       statsforecast: Not installed
2024-05-30 17:45:05,942:INFO:        tune_sklearn: Not installed
2024-05-30 17:45:05,942:INFO:                 ray: Not installed
2024-05-30 17:45:05,942:INFO:            hyperopt: Not installed
2024-05-30 17:45:05,942:INFO:              optuna: Not installed
2024-05-30 17:45:05,942:INFO:               skopt: Not installed
2024-05-30 17:45:05,942:INFO:              mlflow: Not installed
2024-05-30 17:45:05,942:INFO:              gradio: Not installed
2024-05-30 17:45:05,942:INFO:             fastapi: Not installed
2024-05-30 17:45:05,942:INFO:             uvicorn: Not installed
2024-05-30 17:45:05,942:INFO:              m2cgen: Not installed
2024-05-30 17:45:05,942:INFO:           evidently: Not installed
2024-05-30 17:45:05,943:INFO:               fugue: Not installed
2024-05-30 17:45:05,943:INFO:           streamlit: Not installed
2024-05-30 17:45:05,943:INFO:             prophet: Not installed
2024-05-30 17:45:05,943:INFO:None
2024-05-30 17:45:05,943:INFO:Set up data.
2024-05-30 17:45:05,975:INFO:Set up folding strategy.
2024-05-30 17:45:05,975:INFO:Set up train/test split.
2024-05-30 17:45:06,004:INFO:Set up index.
2024-05-30 17:45:06,004:INFO:Assigning column types.
2024-05-30 17:45:06,008:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-30 17:45:06,049:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-30 17:45:06,050:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-30 17:45:06,070:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:45:06,070:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:45:06,103:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-30 17:45:06,104:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-30 17:45:06,130:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:45:06,130:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:45:06,130:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-30 17:45:06,163:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-30 17:45:06,226:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:45:06,227:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:45:06,272:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-30 17:45:06,298:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:45:06,299:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:45:06,299:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-30 17:45:06,354:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:45:06,355:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:45:06,411:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:45:06,411:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:45:06,413:INFO:Preparing preprocessing pipeline...
2024-05-30 17:45:06,414:INFO:Set up label encoding.
2024-05-30 17:45:06,414:INFO:Set up simple imputation.
2024-05-30 17:45:06,416:INFO:Set up encoding of categorical features.
2024-05-30 17:45:06,551:INFO:Finished creating preprocessing pipeline.
2024-05-30 17:45:06,555:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='...
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['Text'],
                                    transformer=TargetEncoder(cols=['Text'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-05-30 17:45:06,555:INFO:Creating final display dataframe.
2024-05-30 17:45:06,846:INFO:Setup _display_container:                     Description  \
0                    Session id   
1                        Target   
2                   Target type   
3                Target mapping   
4           Original data shape   
5        Transformed data shape   
6   Transformed train set shape   
7    Transformed test set shape   
8          Categorical features   
9                    Preprocess   
10              Imputation type   
11           Numeric imputation   
12       Categorical imputation   
13     Maximum one-hot encoding   
14              Encoding method   
15               Fold Generator   
16                  Fold Number   
17                     CPU Jobs   
18                      Use GPU   
19               Log Experiment   
20              Experiment Name   
21                          USI   

                                                Value  
0                                                  43  
1                                             Emotion  
2                                          Multiclass  
3   anger: 0, fear: 1, joy: 2, love: 3, sadness: 4...  
4                                          (21459, 2)  
5                                          (21459, 2)  
6                                          (15021, 2)  
7                                           (6438, 2)  
8                                                   1  
9                                                True  
10                                             simple  
11                                               mean  
12                                               mode  
13                                                 25  
14                                               None  
15                                    StratifiedKFold  
16                                                  2  
17                                                 -1  
18                                              False  
19                                              False  
20                                   clf-default-name  
21                                               698a  
2024-05-30 17:45:06,904:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:45:06,905:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:45:06,956:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:45:06,956:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:45:06,957:INFO:setup() successfully completed in 1.03s...............
2024-05-30 17:45:06,958:INFO:gpu_param set to False
2024-05-30 17:45:07,008:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:45:07,008:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:45:07,057:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:45:07,058:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:45:07,059:INFO:Initializing compare_models()
2024-05-30 17:45:07,059:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2397b3acb0>, include=Index(['lr', 'knn'], dtype='object', name='ID'), fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f2397b3acb0>, 'include': Index(['lr', 'knn'], dtype='object', name='ID'), 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-05-30 17:45:07,059:INFO:Checking exceptions
2024-05-30 17:45:07,061:INFO:Preparing display monitor
2024-05-30 17:45:18,649:INFO:gpu_param set to False
2024-05-30 17:45:18,711:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:45:18,712:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:45:18,767:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:45:18,767:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:45:23,284:INFO:gpu_param set to False
2024-05-30 17:45:23,367:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:45:23,367:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:45:23,432:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:45:23,433:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:45:38,478:INFO:PyCaret ClassificationExperiment
2024-05-30 17:45:38,478:INFO:Logging name: clf-default-name
2024-05-30 17:45:38,479:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-05-30 17:45:38,479:INFO:version 3.3.2
2024-05-30 17:45:38,479:INFO:Initializing setup()
2024-05-30 17:45:38,479:INFO:self.USI: 9924
2024-05-30 17:45:38,479:INFO:self._variable_keys: {'idx', 'USI', 'target_param', 'fold_shuffle_param', 'pipeline', 'gpu_n_jobs_param', 'memory', 'X', 'exp_id', '_ml_usecase', 'fold_groups_param', '_available_plots', 'y', 'y_train', 'X_train', 'fix_imbalance', 'exp_name_log', 'y_test', 'logging_param', 'X_test', 'gpu_param', 'seed', 'is_multiclass', 'data', 'n_jobs_param', 'html_param', 'fold_generator', 'log_plots_param'}
2024-05-30 17:45:38,479:INFO:Checking environment
2024-05-30 17:45:38,479:INFO:python_version: 3.10.0
2024-05-30 17:45:38,479:INFO:python_build: ('default', 'May 30 2024 16:31:14')
2024-05-30 17:45:38,479:INFO:machine: x86_64
2024-05-30 17:45:38,479:INFO:platform: Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31
2024-05-30 17:45:38,480:INFO:Memory: svmem(total=8181506048, available=4811579392, percent=41.2, used=3061903360, free=1295101952, active=1044463616, inactive=5088350208, buffers=467988480, cached=3356512256, shared=106496, slab=598462464)
2024-05-30 17:45:38,480:INFO:Physical Core: 4
2024-05-30 17:45:38,480:INFO:Logical Core: 8
2024-05-30 17:45:38,480:INFO:Checking libraries
2024-05-30 17:45:38,480:INFO:System:
2024-05-30 17:45:38,481:INFO:    python: 3.10.0 (default, May 30 2024, 16:31:14) [GCC 9.3.0]
2024-05-30 17:45:38,481:INFO:executable: /home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/bin/python
2024-05-30 17:45:38,481:INFO:   machine: Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31
2024-05-30 17:45:38,481:INFO:PyCaret required dependencies:
2024-05-30 17:45:38,481:INFO:                 pip: 21.2.3
2024-05-30 17:45:38,481:INFO:          setuptools: 57.4.0
2024-05-30 17:45:38,481:INFO:             pycaret: 3.3.2
2024-05-30 17:45:38,481:INFO:             IPython: 8.24.0
2024-05-30 17:45:38,481:INFO:          ipywidgets: 8.1.3
2024-05-30 17:45:38,481:INFO:                tqdm: 4.66.4
2024-05-30 17:45:38,481:INFO:               numpy: 1.26.4
2024-05-30 17:45:38,481:INFO:              pandas: 2.1.4
2024-05-30 17:45:38,481:INFO:              jinja2: 3.1.4
2024-05-30 17:45:38,481:INFO:               scipy: 1.11.4
2024-05-30 17:45:38,481:INFO:              joblib: 1.3.2
2024-05-30 17:45:38,481:INFO:             sklearn: 1.4.2
2024-05-30 17:45:38,482:INFO:                pyod: 1.1.3
2024-05-30 17:45:38,482:INFO:            imblearn: 0.12.3
2024-05-30 17:45:38,482:INFO:   category_encoders: 2.6.3
2024-05-30 17:45:38,482:INFO:            lightgbm: 4.3.0
2024-05-30 17:45:38,482:INFO:               numba: 0.59.1
2024-05-30 17:45:38,482:INFO:            requests: 2.32.3
2024-05-30 17:45:38,482:INFO:          matplotlib: 3.7.5
2024-05-30 17:45:38,482:INFO:          scikitplot: 0.3.7
2024-05-30 17:45:38,482:INFO:         yellowbrick: 1.5
2024-05-30 17:45:38,482:INFO:              plotly: 5.22.0
2024-05-30 17:45:38,482:INFO:    plotly-resampler: Not installed
2024-05-30 17:45:38,483:INFO:             kaleido: 0.2.1
2024-05-30 17:45:38,483:INFO:           schemdraw: 0.15
2024-05-30 17:45:38,483:INFO:         statsmodels: 0.14.2
2024-05-30 17:45:38,483:INFO:              sktime: 0.26.0
2024-05-30 17:45:38,483:INFO:               tbats: 1.1.3
2024-05-30 17:45:38,483:INFO:            pmdarima: 2.0.4
2024-05-30 17:45:38,483:INFO:              psutil: 5.9.8
2024-05-30 17:45:38,483:INFO:          markupsafe: 2.1.5
2024-05-30 17:45:38,483:INFO:             pickle5: Not installed
2024-05-30 17:45:38,483:INFO:         cloudpickle: 3.0.0
2024-05-30 17:45:38,483:INFO:         deprecation: 2.1.0
2024-05-30 17:45:38,483:INFO:              xxhash: 3.4.1
2024-05-30 17:45:38,483:INFO:           wurlitzer: 3.1.0
2024-05-30 17:45:38,483:INFO:PyCaret optional dependencies:
2024-05-30 17:45:38,483:INFO:                shap: Not installed
2024-05-30 17:45:38,483:INFO:           interpret: Not installed
2024-05-30 17:45:38,483:INFO:                umap: Not installed
2024-05-30 17:45:38,483:INFO:     ydata_profiling: Not installed
2024-05-30 17:45:38,484:INFO:  explainerdashboard: Not installed
2024-05-30 17:45:38,484:INFO:             autoviz: Not installed
2024-05-30 17:45:38,484:INFO:           fairlearn: Not installed
2024-05-30 17:45:38,484:INFO:          deepchecks: Not installed
2024-05-30 17:45:38,484:INFO:             xgboost: Not installed
2024-05-30 17:45:38,484:INFO:            catboost: Not installed
2024-05-30 17:45:38,484:INFO:              kmodes: Not installed
2024-05-30 17:45:38,484:INFO:             mlxtend: Not installed
2024-05-30 17:45:38,484:INFO:       statsforecast: Not installed
2024-05-30 17:45:38,484:INFO:        tune_sklearn: Not installed
2024-05-30 17:45:38,484:INFO:                 ray: Not installed
2024-05-30 17:45:38,484:INFO:            hyperopt: Not installed
2024-05-30 17:45:38,484:INFO:              optuna: Not installed
2024-05-30 17:45:38,484:INFO:               skopt: Not installed
2024-05-30 17:45:38,484:INFO:              mlflow: Not installed
2024-05-30 17:45:38,484:INFO:              gradio: Not installed
2024-05-30 17:45:38,484:INFO:             fastapi: Not installed
2024-05-30 17:45:38,484:INFO:             uvicorn: Not installed
2024-05-30 17:45:38,484:INFO:              m2cgen: Not installed
2024-05-30 17:45:38,484:INFO:           evidently: Not installed
2024-05-30 17:45:38,484:INFO:               fugue: Not installed
2024-05-30 17:45:38,484:INFO:           streamlit: Not installed
2024-05-30 17:45:38,484:INFO:             prophet: Not installed
2024-05-30 17:45:38,485:INFO:None
2024-05-30 17:45:38,485:INFO:Set up data.
2024-05-30 17:45:38,514:INFO:Set up folding strategy.
2024-05-30 17:45:38,514:INFO:Set up train/test split.
2024-05-30 17:45:38,534:INFO:Set up index.
2024-05-30 17:45:38,534:INFO:Assigning column types.
2024-05-30 17:45:38,536:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-30 17:45:38,570:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-30 17:45:38,571:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-30 17:45:38,590:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:45:38,591:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:45:38,621:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-30 17:45:38,621:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-30 17:45:38,638:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:45:38,638:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:45:38,638:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-30 17:45:38,667:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-30 17:45:38,684:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:45:38,684:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:45:38,715:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-05-30 17:45:38,733:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:45:38,733:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:45:38,733:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-05-30 17:45:38,797:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:45:38,797:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:45:38,859:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:45:38,859:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:45:38,860:INFO:Preparing preprocessing pipeline...
2024-05-30 17:45:38,861:INFO:Set up label encoding.
2024-05-30 17:45:38,861:INFO:Set up simple imputation.
2024-05-30 17:45:38,863:INFO:Set up encoding of categorical features.
2024-05-30 17:45:39,049:INFO:Finished creating preprocessing pipeline.
2024-05-30 17:45:39,053:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='...
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['Text'],
                                    transformer=TargetEncoder(cols=['Text'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-05-30 17:45:39,054:INFO:Creating final display dataframe.
2024-05-30 17:45:39,489:INFO:Setup _display_container:                     Description  \
0                    Session id   
1                        Target   
2                   Target type   
3                Target mapping   
4           Original data shape   
5        Transformed data shape   
6   Transformed train set shape   
7    Transformed test set shape   
8          Categorical features   
9                    Preprocess   
10              Imputation type   
11           Numeric imputation   
12       Categorical imputation   
13     Maximum one-hot encoding   
14              Encoding method   
15               Fold Generator   
16                  Fold Number   
17                     CPU Jobs   
18                      Use GPU   
19               Log Experiment   
20              Experiment Name   
21                          USI   

                                                Value  
0                                                  43  
1                                             Emotion  
2                                          Multiclass  
3   anger: 0, fear: 1, joy: 2, love: 3, sadness: 4...  
4                                          (21459, 2)  
5                                          (21459, 2)  
6                                          (15021, 2)  
7                                           (6438, 2)  
8                                                   1  
9                                                True  
10                                             simple  
11                                               mean  
12                                               mode  
13                                                 25  
14                                               None  
15                                    StratifiedKFold  
16                                                  2  
17                                                 -1  
18                                              False  
19                                              False  
20                                   clf-default-name  
21                                               9924  
2024-05-30 17:45:39,552:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:45:39,552:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:45:39,616:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:45:39,616:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-30 17:45:39,617:INFO:setup() successfully completed in 1.14s...............
2024-05-30 17:45:39,617:INFO:Initializing compare_models()
2024-05-30 17:45:39,617:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2397b0d3c0>, include=['lr', 'knn', 'nb', 'dt', 'svm', 'rbfsvm', 'gpc', 'mlp', 'ridge', 'rf', 'qda', 'ada', 'gbc', 'lda', 'et', 'lightgbm', 'dummy'], fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f2397b0d3c0>, 'include': ['lr', 'knn', 'nb', 'dt', 'svm', 'rbfsvm', 'gpc', 'mlp', 'ridge', 'rf', 'qda', 'ada', 'gbc', 'lda', 'et', 'lightgbm', 'dummy'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-05-30 17:45:39,617:INFO:Checking exceptions
2024-05-30 17:45:39,620:INFO:Preparing display monitor
2024-05-30 17:45:39,643:INFO:Initializing Logistic Regression
2024-05-30 17:45:39,644:INFO:Total runtime is 6.441275278727213e-06 minutes
2024-05-30 17:45:39,648:INFO:SubProcess create_model() called ==================================
2024-05-30 17:45:39,648:INFO:Initializing create_model()
2024-05-30 17:45:39,649:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2397b0d3c0>, estimator=lr, fold=StratifiedKFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f23c52b9bd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-30 17:45:39,649:INFO:Checking exceptions
2024-05-30 17:45:39,649:INFO:Importing libraries
2024-05-30 17:45:39,649:INFO:Copying training dataset
2024-05-30 17:45:39,653:INFO:Defining folds
2024-05-30 17:45:39,654:INFO:Declaring metric variables
2024-05-30 17:45:39,659:INFO:Importing untrained model
2024-05-30 17:45:39,665:INFO:Logistic Regression Imported successfully
2024-05-30 17:45:39,677:INFO:Starting cross validation
2024-05-30 17:45:39,679:INFO:Cross validating with StratifiedKFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2024-05-30 17:45:40,020:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:45:40,038:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:45:40,080:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:45:40,100:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:45:40,111:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:45:40,123:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:45:40,134:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:45:40,160:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:45:40,175:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:45:40,185:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:45:40,229:INFO:Calculating mean and std
2024-05-30 17:45:40,230:INFO:Creating metrics dataframe
2024-05-30 17:45:40,233:INFO:Uploading results into container
2024-05-30 17:45:40,234:INFO:Uploading model into container now
2024-05-30 17:45:40,235:INFO:_master_model_container: 1
2024-05-30 17:45:40,235:INFO:_display_container: 2
2024-05-30 17:45:40,235:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=43, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-30 17:45:40,235:INFO:create_model() successfully completed......................................
2024-05-30 17:45:40,401:INFO:SubProcess create_model() end ==================================
2024-05-30 17:45:40,402:INFO:Creating metrics dataframe
2024-05-30 17:45:40,408:INFO:Initializing K Neighbors Classifier
2024-05-30 17:45:40,408:INFO:Total runtime is 0.012748245398203533 minutes
2024-05-30 17:45:40,412:INFO:SubProcess create_model() called ==================================
2024-05-30 17:45:40,413:INFO:Initializing create_model()
2024-05-30 17:45:40,413:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2397b0d3c0>, estimator=knn, fold=StratifiedKFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f23c52b9bd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-30 17:45:40,414:INFO:Checking exceptions
2024-05-30 17:45:40,414:INFO:Importing libraries
2024-05-30 17:45:40,414:INFO:Copying training dataset
2024-05-30 17:45:40,418:INFO:Defining folds
2024-05-30 17:45:40,418:INFO:Declaring metric variables
2024-05-30 17:45:40,422:INFO:Importing untrained model
2024-05-30 17:45:40,427:INFO:K Neighbors Classifier Imported successfully
2024-05-30 17:45:40,435:INFO:Starting cross validation
2024-05-30 17:45:40,436:INFO:Cross validating with StratifiedKFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2024-05-30 17:45:42,144:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:45:42,177:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:45:42,193:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:45:42,204:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:45:42,485:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:45:42,512:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:45:42,529:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:45:42,540:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:45:42,586:INFO:Calculating mean and std
2024-05-30 17:45:42,587:INFO:Creating metrics dataframe
2024-05-30 17:45:42,590:INFO:Uploading results into container
2024-05-30 17:45:42,591:INFO:Uploading model into container now
2024-05-30 17:45:42,591:INFO:_master_model_container: 2
2024-05-30 17:45:42,591:INFO:_display_container: 2
2024-05-30 17:45:42,592:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-05-30 17:45:42,592:INFO:create_model() successfully completed......................................
2024-05-30 17:45:42,733:INFO:SubProcess create_model() end ==================================
2024-05-30 17:45:42,734:INFO:Creating metrics dataframe
2024-05-30 17:45:42,739:INFO:Initializing Naive Bayes
2024-05-30 17:45:42,740:INFO:Total runtime is 0.05160217682520549 minutes
2024-05-30 17:45:42,745:INFO:SubProcess create_model() called ==================================
2024-05-30 17:45:42,745:INFO:Initializing create_model()
2024-05-30 17:45:42,746:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2397b0d3c0>, estimator=nb, fold=StratifiedKFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f23c52b9bd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-30 17:45:42,746:INFO:Checking exceptions
2024-05-30 17:45:42,746:INFO:Importing libraries
2024-05-30 17:45:42,746:INFO:Copying training dataset
2024-05-30 17:45:42,750:INFO:Defining folds
2024-05-30 17:45:42,751:INFO:Declaring metric variables
2024-05-30 17:45:42,754:INFO:Importing untrained model
2024-05-30 17:45:42,756:INFO:Naive Bayes Imported successfully
2024-05-30 17:45:42,765:INFO:Starting cross validation
2024-05-30 17:45:42,767:INFO:Cross validating with StratifiedKFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2024-05-30 17:45:44,085:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:45:44,091:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:45:44,119:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:45:44,121:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:45:44,137:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:45:44,139:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:45:44,150:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:45:44,152:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:45:44,202:INFO:Calculating mean and std
2024-05-30 17:45:44,204:INFO:Creating metrics dataframe
2024-05-30 17:45:44,206:INFO:Uploading results into container
2024-05-30 17:45:44,207:INFO:Uploading model into container now
2024-05-30 17:45:44,209:INFO:_master_model_container: 3
2024-05-30 17:45:44,209:INFO:_display_container: 2
2024-05-30 17:45:44,210:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-05-30 17:45:44,210:INFO:create_model() successfully completed......................................
2024-05-30 17:45:44,346:INFO:SubProcess create_model() end ==================================
2024-05-30 17:45:44,347:INFO:Creating metrics dataframe
2024-05-30 17:45:44,353:INFO:Initializing Decision Tree Classifier
2024-05-30 17:45:44,353:INFO:Total runtime is 0.07849886814753215 minutes
2024-05-30 17:45:44,356:INFO:SubProcess create_model() called ==================================
2024-05-30 17:45:44,357:INFO:Initializing create_model()
2024-05-30 17:45:44,357:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2397b0d3c0>, estimator=dt, fold=StratifiedKFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f23c52b9bd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-30 17:45:44,357:INFO:Checking exceptions
2024-05-30 17:45:44,357:INFO:Importing libraries
2024-05-30 17:45:44,357:INFO:Copying training dataset
2024-05-30 17:45:44,363:INFO:Defining folds
2024-05-30 17:45:44,363:INFO:Declaring metric variables
2024-05-30 17:45:44,367:INFO:Importing untrained model
2024-05-30 17:45:44,371:INFO:Decision Tree Classifier Imported successfully
2024-05-30 17:45:44,379:INFO:Starting cross validation
2024-05-30 17:45:44,381:INFO:Cross validating with StratifiedKFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2024-05-30 17:45:45,573:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:45:45,599:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:45:45,600:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:45:45,621:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:45:45,634:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:45:45,634:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:45:45,651:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:45:45,665:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:45:45,707:INFO:Calculating mean and std
2024-05-30 17:45:45,710:INFO:Creating metrics dataframe
2024-05-30 17:45:45,713:INFO:Uploading results into container
2024-05-30 17:45:45,713:INFO:Uploading model into container now
2024-05-30 17:45:45,714:INFO:_master_model_container: 4
2024-05-30 17:45:45,714:INFO:_display_container: 2
2024-05-30 17:45:45,715:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=43, splitter='best')
2024-05-30 17:45:45,715:INFO:create_model() successfully completed......................................
2024-05-30 17:45:45,866:INFO:SubProcess create_model() end ==================================
2024-05-30 17:45:45,867:INFO:Creating metrics dataframe
2024-05-30 17:45:45,873:INFO:Initializing SVM - Linear Kernel
2024-05-30 17:45:45,874:INFO:Total runtime is 0.10383854707082113 minutes
2024-05-30 17:45:45,878:INFO:SubProcess create_model() called ==================================
2024-05-30 17:45:45,879:INFO:Initializing create_model()
2024-05-30 17:45:45,879:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2397b0d3c0>, estimator=svm, fold=StratifiedKFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f23c52b9bd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-30 17:45:45,879:INFO:Checking exceptions
2024-05-30 17:45:45,879:INFO:Importing libraries
2024-05-30 17:45:45,879:INFO:Copying training dataset
2024-05-30 17:45:45,883:INFO:Defining folds
2024-05-30 17:45:45,883:INFO:Declaring metric variables
2024-05-30 17:45:45,886:INFO:Importing untrained model
2024-05-30 17:45:45,890:INFO:SVM - Linear Kernel Imported successfully
2024-05-30 17:45:45,898:INFO:Starting cross validation
2024-05-30 17:45:45,899:INFO:Cross validating with StratifiedKFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2024-05-30 17:45:46,067:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:45:46,070:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:45:46,080:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:45:46,083:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:45:46,112:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:45:46,113:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:45:46,135:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:45:46,137:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:45:46,149:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:45:46,154:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:45:46,206:INFO:Calculating mean and std
2024-05-30 17:45:46,208:INFO:Creating metrics dataframe
2024-05-30 17:45:46,210:INFO:Uploading results into container
2024-05-30 17:45:46,211:INFO:Uploading model into container now
2024-05-30 17:45:46,212:INFO:_master_model_container: 5
2024-05-30 17:45:46,212:INFO:_display_container: 2
2024-05-30 17:45:46,213:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=43, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-05-30 17:45:46,213:INFO:create_model() successfully completed......................................
2024-05-30 17:45:46,333:INFO:SubProcess create_model() end ==================================
2024-05-30 17:45:46,334:INFO:Creating metrics dataframe
2024-05-30 17:45:46,341:INFO:Initializing SVM - Radial Kernel
2024-05-30 17:45:46,341:INFO:Total runtime is 0.1116258978843689 minutes
2024-05-30 17:45:46,345:INFO:SubProcess create_model() called ==================================
2024-05-30 17:45:46,345:INFO:Initializing create_model()
2024-05-30 17:45:46,345:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2397b0d3c0>, estimator=rbfsvm, fold=StratifiedKFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f23c52b9bd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-30 17:45:46,345:INFO:Checking exceptions
2024-05-30 17:45:46,345:INFO:Importing libraries
2024-05-30 17:45:46,346:INFO:Copying training dataset
2024-05-30 17:45:46,350:INFO:Defining folds
2024-05-30 17:45:46,351:INFO:Declaring metric variables
2024-05-30 17:45:46,354:INFO:Importing untrained model
2024-05-30 17:45:46,361:INFO:SVM - Radial Kernel Imported successfully
2024-05-30 17:45:46,371:INFO:Starting cross validation
2024-05-30 17:45:46,373:INFO:Cross validating with StratifiedKFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2024-05-30 17:45:46,916:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:45:46,920:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:45:46,927:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:45:46,932:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:45:46,954:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:45:46,958:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:45:46,971:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:45:46,977:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:45:46,986:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:45:46,990:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:45:47,044:INFO:Calculating mean and std
2024-05-30 17:45:47,045:INFO:Creating metrics dataframe
2024-05-30 17:45:47,047:INFO:Uploading results into container
2024-05-30 17:45:47,047:INFO:Uploading model into container now
2024-05-30 17:45:47,048:INFO:_master_model_container: 6
2024-05-30 17:45:47,048:INFO:_display_container: 2
2024-05-30 17:45:47,048:INFO:SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',
    max_iter=-1, probability=True, random_state=43, shrinking=True, tol=0.001,
    verbose=False)
2024-05-30 17:45:47,048:INFO:create_model() successfully completed......................................
2024-05-30 17:45:47,177:INFO:SubProcess create_model() end ==================================
2024-05-30 17:45:47,177:INFO:Creating metrics dataframe
2024-05-30 17:45:47,184:INFO:Initializing Gaussian Process Classifier
2024-05-30 17:45:47,184:INFO:Total runtime is 0.1256773273150126 minutes
2024-05-30 17:45:47,187:INFO:SubProcess create_model() called ==================================
2024-05-30 17:45:47,187:INFO:Initializing create_model()
2024-05-30 17:45:47,187:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2397b0d3c0>, estimator=gpc, fold=StratifiedKFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f23c52b9bd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-30 17:45:47,188:INFO:Checking exceptions
2024-05-30 17:45:47,188:INFO:Importing libraries
2024-05-30 17:45:47,188:INFO:Copying training dataset
2024-05-30 17:45:47,192:INFO:Defining folds
2024-05-30 17:45:47,193:INFO:Declaring metric variables
2024-05-30 17:45:47,196:INFO:Importing untrained model
2024-05-30 17:45:47,199:INFO:Gaussian Process Classifier Imported successfully
2024-05-30 17:45:47,207:INFO:Starting cross validation
2024-05-30 17:45:47,208:INFO:Cross validating with StratifiedKFold(n_splits=2, random_state=None, shuffle=False), n_jobs=1
2024-05-30 17:46:44,059:WARNING:create_model() for gpc raised an exception or returned all 0.0, trying without fit_kwargs:
2024-05-30 17:46:44,078:WARNING:Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 2 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py", line 741, in fit
    self.base_estimator_.fit(X, y)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/multiclass.py", line 373, in fit
    self.estimators_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose)(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/joblib/parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/joblib/parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/joblib/parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/joblib/parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/joblib/parallel.py", line 736, in get_result
    return self._return_or_raise()
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/joblib/parallel.py", line 754, in _return_or_raise
    raise self._result
joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.

The exit codes of the workers are {SIGKILL(-9)}


2024-05-30 17:46:44,191:INFO:Initializing create_model()
2024-05-30 17:46:44,191:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2397b0d3c0>, estimator=gpc, fold=StratifiedKFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f23c52b9bd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-30 17:46:44,192:INFO:Checking exceptions
2024-05-30 17:46:44,194:INFO:Importing libraries
2024-05-30 17:46:44,270:INFO:Copying training dataset
2024-05-30 17:46:45,269:INFO:Defining folds
2024-05-30 17:46:45,271:INFO:Declaring metric variables
2024-05-30 17:46:45,781:INFO:Importing untrained model
2024-05-30 17:46:45,791:INFO:Gaussian Process Classifier Imported successfully
2024-05-30 17:46:45,973:INFO:Starting cross validation
2024-05-30 17:46:46,202:INFO:Cross validating with StratifiedKFold(n_splits=2, random_state=None, shuffle=False), n_jobs=1
2024-05-30 17:47:17,991:ERROR:create_model() for gpc raised an exception or returned all 0.0:
2024-05-30 17:47:17,999:ERROR:Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 2 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py", line 741, in fit
    self.base_estimator_.fit(X, y)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/multiclass.py", line 373, in fit
    self.estimators_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose)(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/joblib/parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/joblib/parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/joblib/parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/joblib/parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/joblib/parallel.py", line 736, in get_result
    return self._return_or_raise()
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/joblib/parallel.py", line 754, in _return_or_raise
    raise self._result
joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.

The exit codes of the workers are {SIGKILL(-9)}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 2 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 2 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py", line 741, in fit
    self.base_estimator_.fit(X, y)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/multiclass.py", line 373, in fit
    self.estimators_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose)(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/joblib/parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/joblib/parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/joblib/parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/joblib/parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/joblib/parallel.py", line 736, in get_result
    return self._return_or_raise()
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/joblib/parallel.py", line 754, in _return_or_raise
    raise self._result
joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.

The exit codes of the workers are {SIGKILL(-9)}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/gaussian_process/_gpc.py", line 741, in fit
    self.base_estimator_.fit(X, y)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/multiclass.py", line 373, in fit
    self.estimators_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose)(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/joblib/parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/joblib/parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/joblib/parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/joblib/parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/joblib/parallel.py", line 736, in get_result
    return self._return_or_raise()
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/joblib/parallel.py", line 754, in _return_or_raise
    raise self._result
joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.

The exit codes of the workers are {SIGKILL(-9)}


2024-05-30 17:47:18,019:INFO:Initializing MLP Classifier
2024-05-30 17:47:18,020:INFO:Total runtime is 1.6396092653274537 minutes
2024-05-30 17:47:19,001:INFO:SubProcess create_model() called ==================================
2024-05-30 17:47:19,015:INFO:Initializing create_model()
2024-05-30 17:47:19,015:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2397b0d3c0>, estimator=mlp, fold=StratifiedKFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f23c52b9bd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-30 17:47:19,016:INFO:Checking exceptions
2024-05-30 17:47:19,017:INFO:Importing libraries
2024-05-30 17:47:19,022:INFO:Copying training dataset
2024-05-30 17:47:19,314:INFO:Defining folds
2024-05-30 17:47:19,316:INFO:Declaring metric variables
2024-05-30 17:47:19,321:INFO:Importing untrained model
2024-05-30 17:47:19,333:INFO:MLP Classifier Imported successfully
2024-05-30 17:47:19,349:INFO:Starting cross validation
2024-05-30 17:47:19,888:INFO:Cross validating with StratifiedKFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2024-05-30 17:47:38,084:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:47:38,084:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:47:38,111:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:47:38,114:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:47:38,128:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:47:38,130:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:47:38,140:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:47:38,141:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:47:38,284:INFO:Calculating mean and std
2024-05-30 17:47:38,289:INFO:Creating metrics dataframe
2024-05-30 17:47:38,303:INFO:Uploading results into container
2024-05-30 17:47:38,304:INFO:Uploading model into container now
2024-05-30 17:47:38,384:INFO:_master_model_container: 7
2024-05-30 17:47:38,384:INFO:_display_container: 2
2024-05-30 17:47:38,391:INFO:MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,
              beta_2=0.999, early_stopping=False, epsilon=1e-08,
              hidden_layer_sizes=(100,), learning_rate='constant',
              learning_rate_init=0.001, max_fun=15000, max_iter=500,
              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,
              power_t=0.5, random_state=43, shuffle=True, solver='adam',
              tol=0.0001, validation_fraction=0.1, verbose=False,
              warm_start=False)
2024-05-30 17:47:38,391:INFO:create_model() successfully completed......................................
2024-05-30 17:47:57,428:INFO:SubProcess create_model() end ==================================
2024-05-30 17:47:57,428:INFO:Creating metrics dataframe
2024-05-30 17:47:57,456:INFO:Initializing Ridge Classifier
2024-05-30 17:47:57,456:INFO:Total runtime is 2.296874153614044 minutes
2024-05-30 17:47:57,462:INFO:SubProcess create_model() called ==================================
2024-05-30 17:47:57,463:INFO:Initializing create_model()
2024-05-30 17:47:57,463:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2397b0d3c0>, estimator=ridge, fold=StratifiedKFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f23c52b9bd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-30 17:47:57,463:INFO:Checking exceptions
2024-05-30 17:47:57,463:INFO:Importing libraries
2024-05-30 17:47:57,464:INFO:Copying training dataset
2024-05-30 17:47:57,481:INFO:Defining folds
2024-05-30 17:47:57,482:INFO:Declaring metric variables
2024-05-30 17:47:57,488:INFO:Importing untrained model
2024-05-30 17:47:57,494:INFO:Ridge Classifier Imported successfully
2024-05-30 17:47:57,506:INFO:Starting cross validation
2024-05-30 17:47:57,513:INFO:Cross validating with StratifiedKFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2024-05-30 17:47:59,233:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:47:59,233:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:47:59,246:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:47:59,247:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:47:59,297:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:47:59,297:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:47:59,328:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:47:59,330:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:47:59,348:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:47:59,353:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:47:59,435:INFO:Calculating mean and std
2024-05-30 17:47:59,437:INFO:Creating metrics dataframe
2024-05-30 17:47:59,441:INFO:Uploading results into container
2024-05-30 17:47:59,442:INFO:Uploading model into container now
2024-05-30 17:47:59,442:INFO:_master_model_container: 8
2024-05-30 17:47:59,443:INFO:_display_container: 2
2024-05-30 17:47:59,443:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=43, solver='auto',
                tol=0.0001)
2024-05-30 17:47:59,443:INFO:create_model() successfully completed......................................
2024-05-30 17:47:59,728:INFO:SubProcess create_model() end ==================================
2024-05-30 17:47:59,728:INFO:Creating metrics dataframe
2024-05-30 17:48:00,003:INFO:Initializing Random Forest Classifier
2024-05-30 17:48:00,004:INFO:Total runtime is 2.339339562257131 minutes
2024-05-30 17:48:00,012:INFO:SubProcess create_model() called ==================================
2024-05-30 17:48:00,013:INFO:Initializing create_model()
2024-05-30 17:48:00,013:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2397b0d3c0>, estimator=rf, fold=StratifiedKFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f23c52b9bd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-30 17:48:00,014:INFO:Checking exceptions
2024-05-30 17:48:00,014:INFO:Importing libraries
2024-05-30 17:48:00,014:INFO:Copying training dataset
2024-05-30 17:48:00,019:INFO:Defining folds
2024-05-30 17:48:00,020:INFO:Declaring metric variables
2024-05-30 17:48:00,026:INFO:Importing untrained model
2024-05-30 17:48:00,030:INFO:Random Forest Classifier Imported successfully
2024-05-30 17:48:00,036:INFO:Starting cross validation
2024-05-30 17:48:00,037:INFO:Cross validating with StratifiedKFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2024-05-30 17:48:03,233:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:48:03,241:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:48:03,270:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:48:03,279:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:48:03,288:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:48:03,299:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:48:03,301:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:48:03,313:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:48:03,358:INFO:Calculating mean and std
2024-05-30 17:48:03,360:INFO:Creating metrics dataframe
2024-05-30 17:48:03,362:INFO:Uploading results into container
2024-05-30 17:48:03,363:INFO:Uploading model into container now
2024-05-30 17:48:03,364:INFO:_master_model_container: 9
2024-05-30 17:48:03,364:INFO:_display_container: 2
2024-05-30 17:48:03,365:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=43, verbose=0,
                       warm_start=False)
2024-05-30 17:48:03,365:INFO:create_model() successfully completed......................................
2024-05-30 17:48:03,517:INFO:SubProcess create_model() end ==================================
2024-05-30 17:48:03,517:INFO:Creating metrics dataframe
2024-05-30 17:48:03,531:INFO:Initializing Quadratic Discriminant Analysis
2024-05-30 17:48:03,531:INFO:Total runtime is 2.3981210271517437 minutes
2024-05-30 17:48:03,535:INFO:SubProcess create_model() called ==================================
2024-05-30 17:48:03,535:INFO:Initializing create_model()
2024-05-30 17:48:03,535:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2397b0d3c0>, estimator=qda, fold=StratifiedKFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f23c52b9bd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-30 17:48:03,536:INFO:Checking exceptions
2024-05-30 17:48:03,536:INFO:Importing libraries
2024-05-30 17:48:03,536:INFO:Copying training dataset
2024-05-30 17:48:03,542:INFO:Defining folds
2024-05-30 17:48:03,542:INFO:Declaring metric variables
2024-05-30 17:48:03,547:INFO:Importing untrained model
2024-05-30 17:48:03,551:INFO:Quadratic Discriminant Analysis Imported successfully
2024-05-30 17:48:03,561:INFO:Starting cross validation
2024-05-30 17:48:03,563:INFO:Cross validating with StratifiedKFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2024-05-30 17:48:05,261:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-05-30 17:48:05,286:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:48:05,287:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:48:05,300:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:48:05,301:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:48:05,331:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:48:05,331:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:48:05,348:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:48:05,351:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:48:05,371:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:48:05,372:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:48:05,427:INFO:Calculating mean and std
2024-05-30 17:48:05,429:INFO:Creating metrics dataframe
2024-05-30 17:48:05,431:INFO:Uploading results into container
2024-05-30 17:48:05,432:INFO:Uploading model into container now
2024-05-30 17:48:05,433:INFO:_master_model_container: 10
2024-05-30 17:48:05,433:INFO:_display_container: 2
2024-05-30 17:48:05,433:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-05-30 17:48:05,433:INFO:create_model() successfully completed......................................
2024-05-30 17:48:05,565:INFO:SubProcess create_model() end ==================================
2024-05-30 17:48:05,566:INFO:Creating metrics dataframe
2024-05-30 17:48:05,577:INFO:Initializing Ada Boost Classifier
2024-05-30 17:48:05,578:INFO:Total runtime is 2.4322389920552574 minutes
2024-05-30 17:48:05,581:INFO:SubProcess create_model() called ==================================
2024-05-30 17:48:05,582:INFO:Initializing create_model()
2024-05-30 17:48:05,582:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2397b0d3c0>, estimator=ada, fold=StratifiedKFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f23c52b9bd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-30 17:48:05,582:INFO:Checking exceptions
2024-05-30 17:48:05,582:INFO:Importing libraries
2024-05-30 17:48:05,582:INFO:Copying training dataset
2024-05-30 17:48:05,586:INFO:Defining folds
2024-05-30 17:48:05,587:INFO:Declaring metric variables
2024-05-30 17:48:05,591:INFO:Importing untrained model
2024-05-30 17:48:05,596:INFO:Ada Boost Classifier Imported successfully
2024-05-30 17:48:05,605:INFO:Starting cross validation
2024-05-30 17:48:05,607:INFO:Cross validating with StratifiedKFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2024-05-30 17:48:05,694:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-30 17:48:05,703:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-05-30 17:48:05,941:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:48:05,946:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:48:05,957:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:48:05,959:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:48:05,988:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:48:05,991:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:48:06,006:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:48:06,008:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:48:06,019:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:48:06,025:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:48:06,073:INFO:Calculating mean and std
2024-05-30 17:48:06,075:INFO:Creating metrics dataframe
2024-05-30 17:48:06,077:INFO:Uploading results into container
2024-05-30 17:48:06,077:INFO:Uploading model into container now
2024-05-30 17:48:06,077:INFO:_master_model_container: 11
2024-05-30 17:48:06,078:INFO:_display_container: 2
2024-05-30 17:48:06,078:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=43)
2024-05-30 17:48:06,078:INFO:create_model() successfully completed......................................
2024-05-30 17:48:06,240:INFO:SubProcess create_model() end ==================================
2024-05-30 17:48:06,241:INFO:Creating metrics dataframe
2024-05-30 17:48:06,272:INFO:Initializing Gradient Boosting Classifier
2024-05-30 17:48:06,272:INFO:Total runtime is 2.4438099106152853 minutes
2024-05-30 17:48:06,282:INFO:SubProcess create_model() called ==================================
2024-05-30 17:48:06,282:INFO:Initializing create_model()
2024-05-30 17:48:06,283:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2397b0d3c0>, estimator=gbc, fold=StratifiedKFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f23c52b9bd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-30 17:48:06,283:INFO:Checking exceptions
2024-05-30 17:48:06,283:INFO:Importing libraries
2024-05-30 17:48:06,283:INFO:Copying training dataset
2024-05-30 17:48:06,289:INFO:Defining folds
2024-05-30 17:48:06,290:INFO:Declaring metric variables
2024-05-30 17:48:06,295:INFO:Importing untrained model
2024-05-30 17:48:06,302:INFO:Gradient Boosting Classifier Imported successfully
2024-05-30 17:48:06,311:INFO:Starting cross validation
2024-05-30 17:48:06,313:INFO:Cross validating with StratifiedKFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2024-05-30 17:48:07,926:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:48:07,942:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:48:07,959:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:48:07,977:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:48:07,984:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:48:08,001:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:48:08,009:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:48:08,019:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:48:08,039:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:48:08,057:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:48:08,099:INFO:Calculating mean and std
2024-05-30 17:48:08,100:INFO:Creating metrics dataframe
2024-05-30 17:48:08,102:INFO:Uploading results into container
2024-05-30 17:48:08,103:INFO:Uploading model into container now
2024-05-30 17:48:08,104:INFO:_master_model_container: 12
2024-05-30 17:48:08,104:INFO:_display_container: 2
2024-05-30 17:48:08,105:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=43, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-05-30 17:48:08,105:INFO:create_model() successfully completed......................................
2024-05-30 17:48:08,257:INFO:SubProcess create_model() end ==================================
2024-05-30 17:48:08,257:INFO:Creating metrics dataframe
2024-05-30 17:48:08,266:INFO:Initializing Linear Discriminant Analysis
2024-05-30 17:48:08,267:INFO:Total runtime is 2.4770511190096536 minutes
2024-05-30 17:48:08,270:INFO:SubProcess create_model() called ==================================
2024-05-30 17:48:08,270:INFO:Initializing create_model()
2024-05-30 17:48:08,270:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2397b0d3c0>, estimator=lda, fold=StratifiedKFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f23c52b9bd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-30 17:48:08,271:INFO:Checking exceptions
2024-05-30 17:48:08,271:INFO:Importing libraries
2024-05-30 17:48:08,271:INFO:Copying training dataset
2024-05-30 17:48:08,275:INFO:Defining folds
2024-05-30 17:48:08,276:INFO:Declaring metric variables
2024-05-30 17:48:08,339:INFO:Importing untrained model
2024-05-30 17:48:08,344:INFO:Linear Discriminant Analysis Imported successfully
2024-05-30 17:48:08,357:INFO:Starting cross validation
2024-05-30 17:48:08,359:INFO:Cross validating with StratifiedKFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2024-05-30 17:48:08,647:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:48:08,649:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-05-30 17:48:08,666:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:48:08,666:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:48:08,699:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:48:08,702:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:48:08,723:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:48:08,727:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:48:08,744:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:48:08,748:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:48:08,820:INFO:Calculating mean and std
2024-05-30 17:48:08,822:INFO:Creating metrics dataframe
2024-05-30 17:48:08,825:INFO:Uploading results into container
2024-05-30 17:48:08,826:INFO:Uploading model into container now
2024-05-30 17:48:08,827:INFO:_master_model_container: 13
2024-05-30 17:48:08,827:INFO:_display_container: 2
2024-05-30 17:48:08,828:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-05-30 17:48:08,828:INFO:create_model() successfully completed......................................
2024-05-30 17:48:08,969:INFO:SubProcess create_model() end ==================================
2024-05-30 17:48:08,969:INFO:Creating metrics dataframe
2024-05-30 17:48:08,981:INFO:Initializing Extra Trees Classifier
2024-05-30 17:48:08,981:INFO:Total runtime is 2.4889603734016417 minutes
2024-05-30 17:48:08,984:INFO:SubProcess create_model() called ==================================
2024-05-30 17:48:08,985:INFO:Initializing create_model()
2024-05-30 17:48:08,985:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2397b0d3c0>, estimator=et, fold=StratifiedKFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f23c52b9bd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-30 17:48:08,985:INFO:Checking exceptions
2024-05-30 17:48:08,985:INFO:Importing libraries
2024-05-30 17:48:08,985:INFO:Copying training dataset
2024-05-30 17:48:08,991:INFO:Defining folds
2024-05-30 17:48:08,991:INFO:Declaring metric variables
2024-05-30 17:48:08,995:INFO:Importing untrained model
2024-05-30 17:48:08,998:INFO:Extra Trees Classifier Imported successfully
2024-05-30 17:48:09,006:INFO:Starting cross validation
2024-05-30 17:48:09,007:INFO:Cross validating with StratifiedKFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2024-05-30 17:48:09,570:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:48:09,589:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:48:09,613:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:48:09,628:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:48:09,639:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:48:09,647:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:48:09,654:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:48:09,663:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:48:09,718:INFO:Calculating mean and std
2024-05-30 17:48:09,719:INFO:Creating metrics dataframe
2024-05-30 17:48:09,722:INFO:Uploading results into container
2024-05-30 17:48:09,722:INFO:Uploading model into container now
2024-05-30 17:48:09,723:INFO:_master_model_container: 14
2024-05-30 17:48:09,723:INFO:_display_container: 2
2024-05-30 17:48:09,724:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=43, verbose=0,
                     warm_start=False)
2024-05-30 17:48:09,724:INFO:create_model() successfully completed......................................
2024-05-30 17:48:09,868:INFO:SubProcess create_model() end ==================================
2024-05-30 17:48:09,868:INFO:Creating metrics dataframe
2024-05-30 17:48:09,886:INFO:Initializing Light Gradient Boosting Machine
2024-05-30 17:48:09,886:INFO:Total runtime is 2.504041266441345 minutes
2024-05-30 17:48:09,893:INFO:SubProcess create_model() called ==================================
2024-05-30 17:48:09,893:INFO:Initializing create_model()
2024-05-30 17:48:09,893:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2397b0d3c0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f23c52b9bd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-30 17:48:09,893:INFO:Checking exceptions
2024-05-30 17:48:09,893:INFO:Importing libraries
2024-05-30 17:48:09,894:INFO:Copying training dataset
2024-05-30 17:48:09,900:INFO:Defining folds
2024-05-30 17:48:09,900:INFO:Declaring metric variables
2024-05-30 17:48:09,904:INFO:Importing untrained model
2024-05-30 17:48:09,910:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-30 17:48:09,923:INFO:Starting cross validation
2024-05-30 17:48:09,924:INFO:Cross validating with StratifiedKFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2024-05-30 17:49:04,879:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:49:04,938:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:49:04,977:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:49:05,001:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:49:06,055:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:49:06,098:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:49:06,123:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:49:06,141:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:49:06,219:INFO:Calculating mean and std
2024-05-30 17:49:06,220:INFO:Creating metrics dataframe
2024-05-30 17:49:06,224:INFO:Uploading results into container
2024-05-30 17:49:06,225:INFO:Uploading model into container now
2024-05-30 17:49:06,226:INFO:_master_model_container: 15
2024-05-30 17:49:06,226:INFO:_display_container: 2
2024-05-30 17:49:06,227:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=43, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-05-30 17:49:06,227:INFO:create_model() successfully completed......................................
2024-05-30 17:49:06,408:INFO:SubProcess create_model() end ==================================
2024-05-30 17:49:06,409:INFO:Creating metrics dataframe
2024-05-30 17:49:06,425:INFO:Initializing Dummy Classifier
2024-05-30 17:49:06,425:INFO:Total runtime is 3.4463586648305253 minutes
2024-05-30 17:49:06,431:INFO:SubProcess create_model() called ==================================
2024-05-30 17:49:06,432:INFO:Initializing create_model()
2024-05-30 17:49:06,432:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2397b0d3c0>, estimator=dummy, fold=StratifiedKFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f23c52b9bd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-30 17:49:06,432:INFO:Checking exceptions
2024-05-30 17:49:06,432:INFO:Importing libraries
2024-05-30 17:49:06,433:INFO:Copying training dataset
2024-05-30 17:49:06,440:INFO:Defining folds
2024-05-30 17:49:06,441:INFO:Declaring metric variables
2024-05-30 17:49:06,447:INFO:Importing untrained model
2024-05-30 17:49:06,454:INFO:Dummy Classifier Imported successfully
2024-05-30 17:49:06,470:INFO:Starting cross validation
2024-05-30 17:49:06,473:INFO:Cross validating with StratifiedKFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2024-05-30 17:49:06,656:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:49:06,656:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:49:06,722:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:49:06,727:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:49:06,754:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:49:06,757:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-05-30 17:49:06,778:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:49:06,781:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'surprise') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-05-30 17:49:06,863:INFO:Calculating mean and std
2024-05-30 17:49:06,865:INFO:Creating metrics dataframe
2024-05-30 17:49:06,869:INFO:Uploading results into container
2024-05-30 17:49:06,870:INFO:Uploading model into container now
2024-05-30 17:49:06,871:INFO:_master_model_container: 16
2024-05-30 17:49:06,871:INFO:_display_container: 2
2024-05-30 17:49:06,871:INFO:DummyClassifier(constant=None, random_state=43, strategy='prior')
2024-05-30 17:49:06,872:INFO:create_model() successfully completed......................................
2024-05-30 17:49:07,031:INFO:SubProcess create_model() end ==================================
2024-05-30 17:49:07,032:INFO:Creating metrics dataframe
2024-05-30 17:49:07,044:WARNING:/home/julienrm/.pyenv/versions/3.10.0/envs/ml-in-the-cloud-V2/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-30 17:49:07,055:INFO:Initializing create_model()
2024-05-30 17:49:07,055:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2397b0d3c0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=43, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-30 17:49:07,055:INFO:Checking exceptions
2024-05-30 17:49:07,060:INFO:Importing libraries
2024-05-30 17:49:07,060:INFO:Copying training dataset
2024-05-30 17:49:07,065:INFO:Defining folds
2024-05-30 17:49:07,065:INFO:Declaring metric variables
2024-05-30 17:49:07,066:INFO:Importing untrained model
2024-05-30 17:49:07,066:INFO:Declaring custom model
2024-05-30 17:49:07,067:INFO:Logistic Regression Imported successfully
2024-05-30 17:49:07,068:INFO:Cross validation set to False
2024-05-30 17:49:07,068:INFO:Fitting Model
2024-05-30 17:49:09,041:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=43, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-30 17:49:09,042:INFO:create_model() successfully completed......................................
2024-05-30 17:49:09,293:INFO:_master_model_container: 16
2024-05-30 17:49:09,293:INFO:_display_container: 2
2024-05-30 17:49:09,294:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=43, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-05-30 17:49:09,294:INFO:compare_models() successfully completed......................................
